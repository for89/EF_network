---
title: "Mapping the Structure of Executive Function in Early Childhood: A Network Analysis Approach" 
shorttitle: "Mapping Executive Function"

author:
- name: "Fionnuala O'Reilly" 
  orcid: 0000-0002-4355-9088 
  affiliations: 
    - ref: stanford
  email: foreilly@stanford.edu
  corresponding: true

- name: "Jelena Sucevic" 
  orcid: 0000-0001-5091-5434 
  affiliations: 
    - ref: oxford
    
- name: "Caylee Cook"
  orcid: 0000-0001-9718-8887
  affiliations:
    - ref: witwatersrand
    
- name: "Catherine Draper"
  orcid: 0000-0002-2885-437X
  affiliations:
    - ref: witwatersrand

- name: "Steven Howard" 
  orcid: 0000-0002-1258-3210 
  affiliations: 
    - ref: oxford

- name: "Gaia Scerif" 
  orcid: 0000-0002-6371-8874 
  affiliations: 
    - ref: oxford

affiliations: 
  - id: stanford 
    name: "Stanford University" 
  - id: oxford 
    name: "University of Oxford" 
  - id: witwatersrand 
    name: "University of the Witwatersrand"

author-note: 
  disclosures: 
    financial-support: "This work was supported by X." 
    conflict-of-interest: "The author has no conflict of interest to declare."

abstract: TO BE ADDED.

keywords: ["executive function"] 
word-count: true

project:
  type: default
  
bibliography: library.bib

floatsintext: true
numbered-lines: true
# draft: false
mask: false

# figurelist: no
# tablelist: no
# footnotelist: no

format:
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
    include-in-header: preamble.tex
    fig-format: png
    # fig-pos: H        
    # tbl-pos: H

knitr:
  opts_chunk:
    ft.arraystretch: 1.25

execute:
  echo: false 
  message: false 
  warning: false 
  error: true 
  cache: true
---

```{r setup}
#| label: packages
#| include: false
#| cache: false

library(tidyverse)
library(here)
library(glue)
library(purrr)
library(viridis)
library(flextable)
library(lavaan)
library(broom.mixed)
library(lmerTest)
library(png)
library(emmeans)
library(dplyr)
library(ggplot2)
library(stringr)
library(psych) 
library(tibble)
library(haven)
library(BGGM)
library(networktools)  
library(qgraph)
library(haven)
library(readxl)
library(tidyr)
library(readr)


if (requireNamespace("conflicted", quietly = TRUE)) {
  conflicted::conflicts_prefer(
    dplyr::select,
    dplyr::filter,
    dplyr::lag,
    dplyr::rename,
    tidyr::extract
  )
  options(conflicted.policy = "strict") 
}

```

```{r}
#| label: load-aus-data
#| include: false
#| cache: false

aus_data <- read_sav("REDACTED")
colnames(aus_data)
view(aus_data)

```

```{r}
#| label: load-sa-data
#| include: false
#| cache: false

# sa_data <- read_csv("REDACTED")

# Caylee's do file as text file
path <- "REDACTED"
system2("open", path)

do_lines <- read_lines("REDACTED")

idx <- which(str_detect(do_lines, "^\\s*import\\s+delimited\\b"))[1]
stopifnot(!is.na(idx))

line <- do_lines[idx]

# remove "import delimited", then keep the varlist (everything before " using ")
tmp <- line |>
  str_remove("^\\s*import\\s+delimited\\s+") |>
  str_split("\\s+using\\s+", n = 2, simplify = TRUE)

varlist <- tmp[1]  # everything before "using"

cols <- str_split(str_squish(varlist), "\\s+")[[1]]

sa_data <- read_csv(
  "REDACTED",
  col_names = FALSE
)

stopifnot(length(cols) == ncol(sa_data))
names(sa_data) <- cols

# checks
length(cols)
ncol(sa_data)

colnames(sa_data)
```

```{r}
#| label: create-dataframe
#| include: false
#| cache: false

eyt_vars <- c(
  "date_of_eyt", "eyt_child_age_at_testing", "eyt2_ageinmonths", "time_btwn_testing",
  "ef_inhibition", "ef_cogflex", "ef_workingmem",
  "refuse_missing_eyt", "notes_eyt", "early_years_toolbox_complete"
)

ses_vars <- c(
  "nids_income_1", "nids_income_2", "nids_income_3",
  "nids_income_4", "nids_income_5", "nids_income_6",
  "income_range", "monthly_income_given",
  "marital_status", "education_school", "education_post_school", "education_post_school_b",
  "children_in_house", "adults_in_house", "total_in_household"
)

id_vars <- c(
  "caregiver_child_studyid", "redcap_event_name", "interview_date",
  "ra", "child_id", "caregiver_id",
  "child_sex", "child_dob", "child_age", "child_birthweight",
  "caregiver_dob", "caregiver_age", "relationship_child",
  "child_education", "child_education_specific", "child_education_frequency"
)

sa_subset <- sa_data %>%
  select(any_of(c(id_vars, ses_vars, eyt_vars)))
colnames(sa_subset)

# create long format
sa_subset_long <- sa_subset %>%
  distinct(caregiver_child_studyid, redcap_event_name, .keep_all = TRUE)

```

```{r}
#| label: check-ef-sample-size-sa
#| include: false
#| cache: false

ef <- c("ef_inhibition", "ef_cogflex", "ef_workingmem")

ef_counts_by_tp <- sa_subset_long %>%
  group_by(redcap_event_name) %>%
  summarise(
    n_children = n_distinct(caregiver_child_studyid),
    across(all_of(ef),
           ~ sum(!is.na(.)),
           .names = "n_nonmiss_{.col}"),
    .groups = "drop"
  ) %>%
  arrange(redcap_event_name)

ef_counts_by_tp

# complete ef

ef_complete_by_tp <- sa_subset_long %>%
  group_by(redcap_event_name) %>%
  summarise(
    n_children = n_distinct(caregiver_child_studyid),
    n_complete_ef = sum(if_all(all_of(ef), ~ !is.na(.))),
    pct_complete_ef = round(100 * mean(if_all(all_of(ef), ~ !is.na(.))), 1),
    .groups = "drop"
  ) %>%
  arrange(redcap_event_name)

ef_complete_by_tp

# tag children with complete ef
sa_subset_long <- sa_subset_long %>%
  mutate(ef_complete = if_all(all_of(ef), ~ !is.na(.)))
colnames(sa_subset_long)
```

```{r}
age_by_tp <- sa_subset_long %>%
  mutate(child_age = as.numeric(child_age)) %>%   # change to your age var if needed
  group_by(redcap_event_name) %>%
  summarise(
    n       = sum(!is.na(child_age)),
    mean    = mean(child_age, na.rm = TRUE),
    sd      = sd(child_age, na.rm = TRUE),
    min     = min(child_age, na.rm = TRUE),
    max     = max(child_age, na.rm = TRUE),
    median  = median(child_age, na.rm = TRUE),
    iqr     = IQR(child_age, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(redcap_event_name)
age_by_tp

```

```{r}
#| label: aus-ef-longitudinal-sample
#| include: false
#| cache: false

table(table(aus_data$CID))

id_var <- if ("CID" %in% names(aus_data)) "CID" else "ServiceID"

t1_vars <- c("MrAnt_Pt_T1","GNG_IC_T1","CS_SwAcc_T1")
t2_vars <- c("MrAnt_Pt_T2","GNG_IC_T2","CS_SwAcc_T2")
t3_vars <- c("MrAnt_Pt_T3","GNG_IC_T3","CS_SwAcc_T3")

ef_any_counts <- aus_data %>%
  mutate(
    child = .data[[id_var]],
    ef_t1 = if_any(all_of(t1_vars), ~ !is.na(.x)),
    ef_t2 = if_any(all_of(t2_vars), ~ !is.na(.x)),
    ef_t3 = if_any(all_of(t3_vars), ~ !is.na(.x))
  ) %>%
  filter(!is.na(child)) %>%
  distinct(child, .keep_all = TRUE) %>%  # safety: one row per child
  summarise(
    n_children = n(),
    n_t1 = sum(ef_t1),
    n_t2 = sum(ef_t2),
    n_t3 = sum(ef_t3),
    n_2_timepoints = sum(ef_t1 & ef_t2),
    n_all3_timepoints = sum(ef_t1 & ef_t2 & ef_t3)
  )

ef_any_counts # 217 with two time points, 103 with all three time points

```

```{r}
#| label: aus-explore-data
#| include: true
#| cache: false

ef_vars_aus <- c(
  "MrAnt_Pt_T1","GNG_IC_T1","CS_SwAcc_T1",
  "MrAnt_Pt_T2","GNG_IC_T2","CS_SwAcc_T2",
  "MrAnt_Pt_T3","GNG_IC_T3","CS_SwAcc_T3"
)

age_vars_aus <- c("Age_T1", "Age_T2", "Age_T3")

# Missingness (EF)
miss_var_aus <- aus_data |>
  summarise(across(
    all_of(ef_vars_aus),
    list(
      n_miss    = ~ sum(is.na(.)),
      pct_miss  = ~ mean(is.na(.)) * 100,
      n_nonmiss = ~ sum(!is.na(.))
    ),
    .names = "{.col}__{.fn}"
  )) |>
  pivot_longer(
    everything(),
    names_to  = c("variable", "metric"),
    names_sep = "__",
    values_to = "value"
  ) |>
  pivot_wider(names_from = metric, values_from = value) |>
  arrange(desc(pct_miss))

miss_var_aus
```

```{r}
# Long version of EF variables (with timepoint + measure labels)
ef_long_aus <- aus_data %>%
  select(all_of(age_vars_aus), all_of(ef_vars_aus)) %>%
  pivot_longer(cols = all_of(ef_vars_aus), names_to = "var", values_to = "value") %>%
  mutate(
    timepoint = str_extract(var, "T[123]"),
    measure = case_when(
      str_starts(var, "MrAnt") ~ "Mr Ant (points)",
      str_starts(var, "GNG")   ~ "Go/No-Go (IC)",
      str_starts(var, "CS_")   ~ "Card Sort (switch acc)",
      TRUE ~ var
    )
  )

# EF summary (per measure x timepoint)
ef_summary_aus <- ef_long_aus %>%
  group_by(measure, timepoint) %>%
  summarise(
    n_nonmiss = sum(!is.na(value)),
    miss_pct  = round(100 * mean(is.na(value)), 1),
    mean      = mean(value, na.rm = TRUE),
    sd        = sd(value, na.rm = TRUE),
    median    = median(value, na.rm = TRUE),
    q25       = quantile(value, 0.25, na.rm = TRUE),
    q75       = quantile(value, 0.75, na.rm = TRUE),
    .groups   = "drop"
  ) %>%
  mutate(
    mean_sd    = ifelse(n_nonmiss > 0, sprintf("%.2f (%.2f)", mean, sd), NA_character_),
    median_iqr = ifelse(n_nonmiss > 0, sprintf("%.2f [%.2f, %.2f]", median, q25, q75), NA_character_)
  ) %>%
  select(measure, timepoint, n_nonmiss, miss_pct, mean_sd, median_iqr) %>%
  pivot_wider(
    names_from  = timepoint,
    values_from = c(n_nonmiss, miss_pct, mean_sd, median_iqr),
    names_glue  = "{.value}_{timepoint}"
  )

# Age summary (months; one decimal)
fmt_months <- function(x, d = 1) sprintf(paste0("%.", d, "f"), x)

age_row_aus <- aus_data %>%
  select(all_of(age_vars_aus)) %>%
  pivot_longer(cols = all_of(age_vars_aus), names_to = "age_var", values_to = "age") %>%
  mutate(
    timepoint = str_extract(age_var, "T[123]"),
    age = suppressWarnings(as.numeric(age))
  ) %>%
  group_by(timepoint) %>%
  summarise(
    n_nonmiss = sum(!is.na(age)),
    miss_pct  = round(100 * mean(is.na(age)), 1),
    mean      = mean(age, na.rm = TRUE),
    sd        = sd(age, na.rm = TRUE),
    median    = median(age, na.rm = TRUE),
    q25       = quantile(age, 0.25, na.rm = TRUE),
    q75       = quantile(age, 0.75, na.rm = TRUE),
    .groups   = "drop"
  ) %>%
  mutate(
    mean_sd = ifelse(
      n_nonmiss > 0,
      paste0(fmt_months(mean, 1), " (", fmt_months(sd, 1), ")"),
      NA_character_
    ),
    median_iqr = ifelse(
      n_nonmiss > 0,
      paste0(fmt_months(median, 1), " [", fmt_months(q25, 1), ", ", fmt_months(q75, 1), "]"),
      NA_character_
    )
  ) %>%
  select(timepoint, n_nonmiss, miss_pct, mean_sd, median_iqr) %>%
  pivot_wider(
    names_from  = timepoint,
    values_from = c(n_nonmiss, miss_pct, mean_sd, median_iqr),
    names_glue  = "{.value}_{timepoint}"
  ) %>%
  mutate(measure = "Age (months)") %>%
  select(measure, everything())

# Final table
desc_table_aus <- bind_rows(age_row_aus, ef_summary_aus) %>%
  select(
    Measure = measure,
    `N (T1)` = n_nonmiss_T1, `Missing % (T1)` = miss_pct_T1, `Mean (SD) (T1)` = mean_sd_T1, `Median [IQR] (T1)` = median_iqr_T1,
    `N (T2)` = n_nonmiss_T2, `Missing % (T2)` = miss_pct_T2, `Mean (SD) (T2)` = mean_sd_T2, `Median [IQR] (T2)` = median_iqr_T2,
    `N (T3)` = n_nonmiss_T3, `Missing % (T3)` = miss_pct_T3, `Mean (SD) (T3)` = mean_sd_T3, `Median [IQR] (T3)` = median_iqr_T3
  )

desc_table_aus %>%
  gt::gt() %>%
  gt::tab_header(title = gt::md("**Australia: Descriptives for EF Measures and Age**")) %>%
  gt::cols_align(align = "left", columns = Measure) %>%
  gt::cols_align(align = "center", columns = -Measure) %>%
  gt::tab_options(
    table.font.size = gt::px(12),
    data_row.padding = gt::px(3),
    heading.title.font.size = gt::px(14)
  )

```

### Developmental change in tasks across age

```{r age trends}
#| cache: false

ef_long_aus_age_aligned <- aus_data %>%
  select(all_of(age_vars_aus), all_of(ef_vars_aus)) %>%
  pivot_longer(cols = all_of(ef_vars_aus), names_to = "var", values_to = "score") %>%
  extract(var, into = c("task", "metric", "tp"),
          regex = "^([^_]+)_([^_]+)_(T\\d+)$", remove = FALSE) %>%
  mutate(
    tp = factor(tp, levels = c("T1", "T2", "T3")),
    age_months = case_when(
      tp == "T1" ~ Age_T1,
      tp == "T2" ~ Age_T2,
      tp == "T3" ~ Age_T3,
      TRUE ~ NA_real_
    ),
    # Nice task labels (updated)
    task = recode(task,
      "MrAnt" = "Working Memory",
      "GNG"   = "Inhibition",
      "CS"    = "Cognitive Flexibility"
    )
  ) %>%
  filter(is.finite(age_months), is.finite(score))

p1 <- ggplot(ef_long_aus_age_aligned, aes(x = age_months, y = score, colour = tp)) +
  geom_point(alpha = 0.25, size = 1) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x, linewidth = 1) +
  facet_wrap(~ task, scales = "free_y") +
  labs(
    x = "Age (months)",
    y = "Score",
    colour = "Time point",
    title = "Developmental change in EF tasks across age",
    subtitle = "Each panel shows one task; LOESS trend per time point"
  ) +
  theme_minimal(base_size = 12)
p1

# z-score within measure (i.e., within each task x metric combo)
ef_long_aus_z <- ef_long_aus_age_aligned %>%
  group_by(var) %>%               # var is the original name like MrAnt_Pt_T1
  mutate(score_z = as.numeric(scale(score))) %>%
  ungroup()

p2 <- ggplot(ef_long_aus_z, aes(x = age_months, y = score_z, colour = tp)) +
  geom_point(alpha = 0.25, size = 1) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x, linewidth = 1) +
  facet_wrap(~ task) +
  labs(
    x = "Age (months)",
    y = "Standardised score (z within measure)",
    colour = "Time point",
    title = "Age trends in EF (z-scored within measure)",
    subtitle = "Faceted by EF domain; z-scoring makes panels comparable"
  ) +
  theme_minimal(base_size = 12)
p2

```
# START HERE JAN 15TH
### Within child trajectories (raw scores)

```{r within child trajectories}
#| cache: false

id_col <- "CID"   # change if your ID column is named differently

ef_long <- aus_data %>%
  select(all_of(id_col), Age, all_of(ef_vars)) %>%
  pivot_longer(cols = all_of(ef_vars), names_to = "measure", values_to = "score") %>%
  # Split e.g., "MrAnt_Pt_T1" -> task = MrAnt, metric = Pt, tp = T1
  extract(measure, into = c("task","metric","tp"),
          regex = "^([^_]+)_([^_]+)_(T\\d+)$", remove = FALSE) %>%
  mutate(
    tp     = factor(tp, levels = c("T1","T2","T3")),
    task_l = recode(task,
                    "MrAnt" = "Memory Game (MrAnt)",
                    "GNG"   = "Go/No-Go (GNG)",
                    "CS"    = "Hearts & Flowers (CS)")
  )

# Compute T2–T1, T3–T2, T3–T1 per child and per measure
change_wide <- ef_long %>%
  select(all_of(id_col), measure, tp, score) %>%
  pivot_wider(names_from = tp, values_from = score) %>%
  mutate(
    d12 = T2 - T1,
    d23 = T3 - T2,
    d13 = T3 - T1
  )

# Per-measure summaries: n pairs, mean change, SD, 95% CI
paired_change_summary <- change_wide %>%
  pivot_longer(c(d12, d23, d13), names_to = "contrast", values_to = "delta") %>%
  group_by(measure, contrast) %>%
  summarise(
    n_pairs = sum(!is.na(delta)),
    mean    = mean(delta, na.rm = TRUE),
    sd      = sd(delta,  na.rm = TRUE),
    se      = sd / sqrt(n_pairs),
    ci95_l  = mean - 1.96 * se,
    ci95_u  = mean + 1.96 * se,
    .groups = "drop"
  ) %>%
  arrange(measure, factor(contrast, levels = c("d12","d23","d13")))
paired_change_summary

# Spaghetti plot per task (raw scores)
ggplot(
  ef_long,
  aes(x = tp, y = score,
      group  = .data[[id_col]],
      colour = factor(.data[[id_col]]))
) +
  geom_line(alpha = 0.35, linewidth = 0.4) +
  geom_point(alpha = 0.6, size = 0.8) +
  facet_wrap(~ task_l, scales = "free_y") +
  guides(colour = "none") +
  labs(x = "Time point", y = "Raw score",
       title = "Within-child trajectories across time (raw scores)")
```

### EF change over time (raw scores)

```{r mean change over time within task, raw scores}
#| cache: false

summary_ci <- ef_long %>%
  group_by(task_l, tp) %>%
  summarise(
    n   = sum(!is.na(score)),
    mean = mean(score, na.rm = TRUE),
    sd   = sd(score,   na.rm = TRUE),
    se   = sd / sqrt(n),
    ci_l = mean - 1.96*se,
    ci_u = mean + 1.96*se,
    .groups = "drop"
  )

y_lims <- range(summary_ci$ci_l, summary_ci$ci_u, na.rm = TRUE)
pad    <- diff(y_lims) * 0.05
y_lims <- c(y_lims[1] - pad, y_lims[2] + pad)

p <- ggplot(summary_ci, aes(x = tp, y = mean, group = 1)) +
  geom_ribbon(aes(ymin = ci_l, ymax = ci_u), alpha = 0.15) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 1.8) +
  facet_wrap(~ task_l, scales = "fixed") +
  coord_cartesian(ylim = y_lims, expand = FALSE) +
  labs(
    x = "Time point",
    y = "Raw score",
    title = "EF change over time (means with 95% CIs)"
  )
print(p)
```
### Box plots (raw scores)

```{r boxplots}
ggplot(ef_long, aes(x = tp, y = score)) +
  geom_boxplot(outlier.alpha = 0.25, width = 0.6) +
  facet_wrap(~ task_l, scales = "free_y") +
  labs(x = "Time point", y = "Raw score",
       title = "EF distributions across time") +
  theme_minimal(base_size = 12)

```

### EF change over time standardised to each task’s T1 standard deviation

```{r mean change over time within task, standardised scores}
#| cache: false

# task-level T1 mean/SD
t1_stats <- ef_long %>%
  filter(tp == "T1") %>%
  group_by(task_l) %>%
  summarise(mu_T1 = mean(score, na.rm = TRUE),
            sd_T1 = sd(score, na.rm = TRUE),
            .groups = "drop")

ef_long_zT1 <- ef_long %>%
  left_join(t1_stats, by = "task_l") %>%
  mutate(score_zT1 = (score - mu_T1) / sd_T1)

# Means + 95% CIs on the z(T1) scale
summary_ci_z <- ef_long_zT1 %>%
  group_by(task_l, tp) %>%
  summarise(
    n = sum(!is.na(score_zT1)),
    mean = mean(score_zT1, na.rm = TRUE),
    sd   = sd(score_zT1,   na.rm = TRUE),
    se   = sd / sqrt(n),
    ci_l = mean - 1.96 * se,
    ci_u = mean + 1.96 * se,
    .groups = "drop"
  )

ggplot(summary_ci_z, aes(tp, mean, group = 1)) +
  geom_ribbon(aes(ymin = ci_l, ymax = ci_u), alpha = 0.15) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 1.8) +
  facet_wrap(~ task_l, scales = "fixed") +
  labs(x = "Time point", y = "Change in SD units (z vs T1)",
       title = "EF change over time (standardised to each task’s T1 SD)")
```

### Mixed effects model to test if change from T1 to T2 is statistically significant

```{r mixed effects}
#| cache: false

# Ensure time is ordered and add a "measure root" without the T1/T2/T3 suffix
ef_long2 <- ef_long %>%
  mutate(
    tp = factor(tp, levels = c("T1","T2","T3")),
    meas_root = str_remove(measure, "_T[123]$")
  )

fit_time_tests <- function(dat, id_col = "CID") {
  # Give lmer() a concrete ID column name
  dat2 <- dat %>% rename(.id = all_of(id_col))

  fit <- lmerTest::lmer(score ~ tp + (1 | .id), data = dat2, REML = FALSE)
  emm <- emmeans(fit, ~ tp)

  cont <- contrast(emm, method = list(
    "T2 - T1" = c(-1, 1, 0),
    "T3 - T1" = c(-1, 0, 1),
    "T3 - T2" = c( 0,-1, 1)
  ))

  cont_df <- as.data.frame(summary(cont, infer = TRUE)) %>%
    transmute(
      contrast, estimate, SE, df, t = t.ratio,
      p = `p.value`, lower.CL, upper.CL
    )

  an <- anova(fit)
  cont_df %>%
    mutate(
      anova_F  = unname(an["tp","F value"]),
      anova_df1 = unname(an["tp","NumDF"]),
      anova_df2 = unname(an["tp","DenDF"]),
      anova_p  = unname(an["tp","Pr(>F)"])
    )
}

# Run one model per measure root (e.g., "GNG_IC", "CS_SwAcc", "MrAnt_Pt")
results <- ef_long2 %>%
  group_by(meas_root) %>%
  group_modify(~ fit_time_tests(.x)) %>%
  ungroup() %>%
  group_by(contrast) %>%
  mutate(p_adj = p.adjust(p, method = "BH")) %>%
  ungroup()

results


# (optional) pretty names for each measure root
pretty_names <- c(
  "GNG_IC"   = "Go/No-Go (GNG)",
  "CS_SwAcc" = "Hearts & Flowers (CS)",
  "MrAnt_Pt" = "Memory Game (MrAnt)"
)

t12_tbl <- results %>%
  filter(contrast == "T2 - T1") %>%
  transmute(
    Task     = recode(meas_root, !!!pretty_names, .default = meas_root),
    Estimate = estimate,                                   # raw-score change
    `95% CI` = sprintf("[%.2f, %.2f]", lower.CL, upper.CL),
    p        = pvalue(p),                                  # unadjusted p
    `p (BH)` = pvalue(p_adj),                              # FDR-adjusted p
    `Omnibus F (time)` = sprintf("%.2f (df %d, %.1f), p=%s",
                                 anova_F, anova_df1, anova_df2, pvalue(anova_p))
  ) %>%
  arrange(Task)

knitr::kable(t12_tbl, digits = 2, col.names = c("Task", "Δ (T2−T1)", "95% CI", "p", "p (BH)", "Omnibus F (time)")) %>% kableExtra::kable_styling(full_width = FALSE)
```

Histograms indicated that all executive-function task scores were approximately symmetric and unimodal. Mean performance increased and variability decreased across time, consistent with developmental improvements. No evidence of severe skewness, kurtosis, or ceiling/floor effects was observed, so raw scores were retained for analysis.

## Network analysis (rough work)

```{r split by wave}
#| cache: false

ef_map <- list(
  T1 = c("MrAnt_Pt_T1","GNG_IC_T1","CS_SwAcc_T1"),
  T2 = c("MrAnt_Pt_T2","GNG_IC_T2","CS_SwAcc_T2"),
  T3 = c("MrAnt_Pt_T3","GNG_IC_T3","CS_SwAcc_T3")
)

extract_wave <- function(df, vars) {
  stopifnot(length(vars) == 3, all(vars %in% names(df)))
  out <- dplyr::select(df, dplyr::all_of(vars))
  colnames(out) <- c("mr_ant", "gng", "cs")
  out
}

# now this works
Y_t1 <- extract_wave(aus_data, ef_map$T1)
Y_t2 <- extract_wave(aus_data, ef_map$T2)
Y_t3 <- extract_wave(aus_data, ef_map$T3)

Z_t1 <- as.data.frame(scale(Y_t1))
Z_t2 <- as.data.frame(scale(Y_t2))
Z_t3 <- as.data.frame(scale(Y_t3))
```

```{r estimate BGGM networks per wave}
#| cache: false

set.seed(42)
# estimate() gives posterior for every partial correlation (edge)
fit_t1 <- BGGM::estimate(Z_t1, type = "continuous", iter = 10000, impute = TRUE)
fit_t2 <- BGGM::estimate(Z_t2, type = "continuous", iter = 10000, impute = TRUE)
fit_t3 <- BGGM::estimate(Z_t3, type = "continuous", iter = 10000, impute = TRUE)
```

```{r Extract posterior mean partial correlation matrices (pcor) and weighted adjacency (pcor with tiny edges set to 0, depending on class)}
pc_t1 <- BGGM::pcor_mat(fit_t1)
pc_t2 <- BGGM::pcor_mat(fit_t2)
pc_t3 <- BGGM::pcor_mat(fit_t3)
```

```{r expected influence and global strength}
# Expected Influence (EI)
ei_t1 <- networktools::expectedInf(pc_t1)$step1
ei_t2 <- networktools::expectedInf(pc_t2)$step1
ei_t3 <- networktools::expectedInf(pc_t3)$step1

# Strength centrality (sum of edges). Drop diagonals.
strength <- function(M){
  diag(M) <- 0
  rowSums(abs(M))
}
str_t1 <- strength(pc_t1)
str_t2 <- strength(pc_t2)
str_t3 <- strength(pc_t3)
```

```{r Global strength}
global_strength <- function(M){
  sum(abs(M[upper.tri(M)]))
}
gs_t1 <- global_strength(pc_t1)
gs_t2 <- global_strength(pc_t2)
gs_t3 <- global_strength(pc_t3)

print(gs_t1)
print(gs_t2)
print(gs_t3)
```

```{r pairwise Bayesian comparisons of networks}

cmp_t1_t2 <- BGGM::ggm_compare_estimate(Z_t1, Z_t2, type = "continuous", iter = 10000, impute = TRUE)
cmp_t1_t3 <- BGGM::ggm_compare_estimate(Z_t1, Z_t3, type = "continuous", iter = 10000, impute = TRUE)
cmp_t2_t3 <- BGGM::ggm_compare_estimate(Z_t2, Z_t3, type = "continuous", iter = 10000, impute = TRUE)

summary(cmp_t1_t2)  # posterior summaries of edge differences
summary(cmp_t2_t3)
plot(summary(cmp_t1_t2))   #visual of credible intervals
plot(summary(cmp_t2_t3)) # note label is wrong
```

```{r plots}
labs <- c("Mr Ant","Go/No-Go","Card Sort")
qgraph(pc_t1, layout = "spring", labels = labs, title = "T1 (BGGM posterior mean)")
qgraph(pc_t2, layout = "spring", labels = labs, title = "T2 (BGGM posterior mean)")
qgraph(pc_t3, layout = "spring", labels = labs, title = "T3 (BGGM posterior mean)")
```
























