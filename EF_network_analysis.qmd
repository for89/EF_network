---
title: "Mapping the Structure of Executive Function in Early Childhood using Network Analysis" 
shorttitle: "Mapping Executive Function"

author:
- name: "A" 
  affiliations: 
    - ref: stanford
    - ref: oxford
  email: f@psy.ox.ac.uk
  corresponding: true

- name: "B" 
  affiliations: 
    - ref: oxford
    
- name: "C"
  affiliations:
    - ref: witwatersrand
    
- name: "D"
  affiliations:
    - ref: kentucky
    
- name: "E"
  affiliations:
    - ref: ucdavis
    
- name: "F*"
  affiliations:
    - ref: witwatersrand

- name: "G*" 
  affiliations: 
    - ref: oxford

- name: "H*" 
  affiliations: 
    - ref: oxford

affiliations: 
  - id: stanford 
    name: "Stanford University" 
  - id: oxford 
    name: "University of Oxford" 
  - id: witwatersrand 
    name: "University of the Witwatersrand"
  - id: kentucky
    name: "University of Kentucky"
  - id: ucdavis
    name: "University of California, Davis"

author-note: 
  disclosures: 
    financial-support: "This work was supported by X." 
    conflict-of-interest: "The author has no conflict of interest to declare."

abstract: TO BE ADDED.

keywords: ["executive function"] 
word-count: true

project:
  type: default
  
bibliography: library.bib

floatsintext: true
numbered-lines: true
# draft: false
mask: false

# figurelist: no
# tablelist: no
# footnotelist: no

format:
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
    include-in-header: preamble.tex
    fig-format: png
    pdf-engine: xelatex
   
knitr:
  opts_chunk:
    ft.arraystretch: 1.25

execute:
  echo: false 
  message: false 
  warning: false 
  error: true 
  cache: true
---

# Introduction

## Research Questions

**Research Question 1 (Primary): EF Network Structure Within Cohorts**  
Within each cohort and wave, what is the age-adjusted EF network—defined by partial correlations among working memory, inhibition, and cognitive flexibility—and what do global strength and expected influence indicate about overall connectivity and node centrality?

**Research Question 2 (Primary): Developmental Change Within Cohorts**  
Within each cohort, do the EF conditional associations (partial correlations) change across adjacent waves (AU: T1→T2→T3; SA: T1→T2), and if so, which specific edges strengthen or weaken over time?

**Research Question 3 (Secondary): Cross-Cohort Comparisons**  
At matched waves (T1 and T2), do AU and SA differ in EF conditional associations, and do the cohorts show divergent developmental trajectories from T1 to T2 (difference-in-differences)?

**Research Question 4 (Exploratory): Socioeconomic Moderation of Network Structure**  
Within each cohort, does EF network structure differ between children from high versus low baseline (T1) household income and home learning environments? Specifically, are edges systematically stronger or weaker in high-SES groups across waves?

\clearpage

# Methods

## Participants 
To be added.

## Measures
To be added.

## Statistical Analysis

### Network Estimation

We estimated EF network structure using Bayesian Gaussian Graphical Models (BGGM) [@williams2020bayesian; @williams2020bggm] implemented in the BGGM R package [@BGGM]. For each cohort×wave combination, we fit a separate network model to capture the conditional relationships between the three EF components (inhibition, cognitive flexibility, and working memory) after controlling for age. We used default priors and ran MCMC sampling for 5,050 iterations (5,000 posterior samples after 50 burn-in iterations).

### Edge Weights

Edges represent the conditional associations between pairs of EF components. Technically, edge weights are partial correlations: the correlation between two components after controlling for all other components in the network and age. A positive edge indicates that two EF components tend to covary (e.g., children with higher working memory also tend to have higher inhibition, beyond what age would predict), while a negative edge would indicate an inverse relationship. Edge weights range from −1 to +1, with values closer to 0 indicating weaker associations.

For each edge, we report the posterior median (a point estimate of the edge strength) and the 95% credible interval (CrI), which contains the true edge weight with 95% probability given the data and model. Unlike frequentist confidence intervals, credible intervals can be directly interpreted as probability statements about the parameter.

### Meaningfulness Threshold

To distinguish meaningful edges from those that are small or negligible, we adopted a Region of Practical Equivalence (ROPE) approach [@kruschke2018rejecting]. We defined the ROPE as |r| ≤ 0.10, such that edge weights falling within ±0.10 were considered practically equivalent to zero. For each edge, we computed P(|r| > 0.10): the posterior probability that the edge weight exceeds the ROPE threshold in absolute value. Values close to 1 (e.g., P > 0.90) indicate strong evidence that the edge is meaningfully different from zero, while values close to 0.5 indicate substantial uncertainty.

This approach differs from traditional null hypothesis significance testing in two ways. First, it focuses on practical significance (is the effect large enough to matter?) rather than statistical significance (is the effect different from exactly zero?). Second, it quantifies evidence on a continuous scale rather than using a binary reject/fail-to-reject decision rule.

### Global Strength

Global strength summarizes overall network connectivity by summing the absolute values of all unique edge weights. Higher global strength indicates a more densely connected network where EF components are more strongly coupled. We computed global strength for each posterior sample, yielding a posterior distribution that captures uncertainty in this summary metric.

Formally, for a network with *p* nodes, global strength is:

$$
GS = \sum_{i<j} |r_{ij}|
$$

where *r~ij~* is the partial correlation between nodes *i* and *j*. For our three-node networks, global strength is simply |r~inhib-cogflex~| + |r~inhib-WM~| + |r~cogflex-WM~|.

### Centrality (Expected Influence)

Expected Influence [@robinaugh2016identifying] quantifies the centrality of each node in the network—that is, how strongly connected it is to other nodes. Expected influence is computed as the sum of a node's edge weights to all other nodes (without taking absolute values), preserving the sign of the relationships. Nodes with higher expected influence are more central to the network and may play a more important role in the overall system.

Formally, for node *i*:

$$
EI_i = \sum_{j \neq i} r_{ij}
$$

Unlike older centrality metrics (e.g., betweenness, closeness), expected influence is appropriate for networks estimated from partial correlations and does not require thresholding edges or converting the network to a binary graph. We chose expected influence over strength (which uses absolute values) because it preserves directional information: a node can have high expected influence by being positively connected to many nodes, whereas strength would treat positive and negative edges equivalently. In EF networks where edges are predominantly positive, the two metrics converge, but expected influence provides a more nuanced picture if any negative edges emerge.

### Change and Comparison Analyses

To test for developmental change within cohorts (RQ2), we computed difference scores between adjacent waves (e.g., Δr = r~T2~ − r~T1~) by subtracting posterior samples pairwise. This yields a posterior distribution of the change, from which we derived 95% credible intervals and ROPE probabilities for the difference (P(|Δr| > 0.10)).

For cross-cohort comparisons (RQ3), we computed cohort difference scores (e.g., r~AU~ − r~SA~) at matched waves. To account for the bounded nature of correlations, we also report differences on the Fisher z-scale (z = atanh(r)), which transforms correlations to an unbounded scale where differences are more symmetric. Results on both scales were substantively similar, indicating our findings are not artifacts of scale constraints.

For difference-in-differences (DiD) contrasts, we tested whether cohorts showed divergent developmental trajectories by computing (Δr~T2-T1~)~AU~ − (Δr~T2-T1~)~SA~. A meaningful DiD would indicate that one cohort changed more than the other over time.

### Moderation Analyses

To test whether socioeconomic factors moderate network structure (RQ4), we adopted a stratified approach. Within each cohort, we split children into High vs. Low groups based on median splits of baseline (T1) income and home learning environment (HLE), then fit separate BGGM models for each group at each wave. We computed moderation effects as High − Low edge differences, with ROPE probabilities indicating the strength of evidence for moderation (P(|High − Low| > 0.10)). This stratified approach is more robust than including SES as a continuous covariate in a single model, as it allows network structure to differ nonlinearly across SES groups and does not assume constant effects across the SES distribution.

### Measurement Invariance

We tested measurement invariance using multi-group confirmatory factor analysis (CFA) in the lavaan R package [@rosseel2012lavaan]. Because cognitive flexibility exhibited pronounced floor effects in Australian children (see @fig-ef-boxplots-by-wave) at T1 (32.5% scoring zero), we treated all three EF indicators as ordinal variables, segmenting them into tertiles (Low/Medium/High) based on pooled distributions. We fit a single-factor ordinal CFA model across four groups simultaneously (AU_T1, AU_T2, SA_T1, SA_T2), testing invariance across both cohorts and developmental timepoints using robust weighted least squares estimation (WLSMV). We tested three levels of invariance:

1. **Configural invariance**: The same factor structure (three indicators loading on one factor) holds across all groups
2. **Metric invariance**: Factor loadings are equal across groups (components relate to the latent EF construct equivalently)
3. **Scalar invariance**: Thresholds (category boundaries for ordinal indicators) are equal across groups

We evaluated invariance using chi-square difference tests (Δχ²) and changes in fit indices (ΔCFI), with ΔCFI < 0.01 supporting invariance [@cheung2002evaluating]. Metric invariance is a prerequisite for comparing network structures (relationships between EF components) across groups, while scalar invariance is required for comparing mean levels.

### Software

All analyses were conducted in R (version 4.5.0). Network models were fit using BGGM (version 2.1.5), measurement invariance tests used lavaan (version 0.6.19), and visualizations used ggplot2 (version 4.0.0). Analysis code is available at [include github url].

\clearpage

# Results

```{r}
#| label: packages
#| include: false
#| cache: false

library(tidyverse)
library(here)
library(glue)
library(purrr)
library(viridis)
library(flextable)
library(lavaan)
library(broom.mixed)
library(lmerTest)
library(png)
library(emmeans)
library(dplyr)
library(ggplot2)
library(stringr)
library(psych) 
library(tibble)
library(haven)
library(BGGM)
library(networktools)  
library(qgraph)
library(haven)
library(readxl)
library(tidyr)
library(readr)
library(gt)


if (requireNamespace("conflicted", quietly = TRUE)) {
  conflicted::conflicts_prefer(
    dplyr::select,
    dplyr::filter,
    dplyr::lag,
    dplyr::rename,
    tidyr::extract
  )
  options(conflicted.policy = "strict") 
}
```

```{r}
#| label: plot-helper
#| include: false

source(here::here("ef_network_plotting_helper.R"))
```

```{r}
#| label: load-aus-data
#| include: false
#| cache: false

aus_data <- read_sav("REDACTED")
colnames(aus_data)
# view(aus_data)
```

```{r}
#| label: load-sa-data
#| include: false
#| cache: false

# sa_data <- read_csv("REDACTED")

# Caylee's do file as text file
path <- "REDACTED"
system2("open", path)

do_lines <- read_lines("REDACTED")

idx <- which(str_detect(do_lines, "^\\s*import\\s+delimited\\b"))[1]
stopifnot(!is.na(idx))

line <- do_lines[idx]

# remove "import delimited", then keep the varlist (everything before " using ")
tmp <- line |>
  str_remove("^\\s*import\\s+delimited\\s+") |>
  str_split("\\s+using\\s+", n = 2, simplify = TRUE)

varlist <- tmp[1]  # everything before "using"

cols <- str_split(str_squish(varlist), "\\s+")[[1]]

sa_data <- read_csv(
  "REDACTED",
  col_names = FALSE
)

stopifnot(length(cols) == ncol(sa_data))
names(sa_data) <- cols

# checks
length(cols)
ncol(sa_data)

colnames(sa_data)
colnames(aus_data)

```

```{r}
#| label: derive-hle-vars
#| include: false

to_num <- function(x) suppressWarnings(as.numeric(as.character(x)))

# (1) HLA frequency (8 items: 0/1/2)
hla_freq_vars <- c(
  "hle_read_books", "hle_stories", "hle_songs", "hle_outside",
  "hle_play", "hle_names", "hle_count", "hle_draw"
)

# (2) Unique caregiver types across any activity (codes 1-6)
activities <- c("read", "stories", "songs", "outside", "play", "names", "count", "draw")
caregiver_codes <- 1:6

# (3) Books/toys total (4 items: 0/1)
books_toys_vars <- c(
  "hle_books_home", "hle_homemade_toys", "hle_toys_shop", "hle_household_objects"
)

# (4) Time total: week + weekend (each 1..3) 
time_vars <- c("hle_time_week", "hle_time_weekend")

# derive 1, 3 and 4 (NA only if all items missing; otherwise sum observed)
sa_data <- sa_data %>%
  dplyr::mutate(
    hla_frequency1 = dplyr::if_else(
      dplyr::if_all(dplyr::all_of(hla_freq_vars), is.na),
      NA_real_,
      rowSums(dplyr::across(dplyr::all_of(hla_freq_vars), to_num), na.rm = TRUE)
    ),
    books_toys_total1 = dplyr::if_else(
      dplyr::if_all(dplyr::all_of(books_toys_vars), is.na),
      NA_real_,
      rowSums(dplyr::across(dplyr::all_of(books_toys_vars), to_num), na.rm = TRUE)
    ),
    time_total1 = dplyr::if_else(
      dplyr::if_all(dplyr::all_of(time_vars), is.na),
      NA_real_,
      rowSums(dplyr::across(dplyr::all_of(time_vars), to_num), na.rm = TRUE)
    )
  )

# derive 2: num_caregivers
who_all <- as.vector(sapply(
  activities,
  function(a) paste0("hle_", a, "_who___", caregiver_codes)
))

who_mat <- sa_data %>% dplyr::select(dplyr::any_of(who_all)) %>% as.matrix()

all_missing_who <- if (ncol(who_mat) == 0) {
  rep(TRUE, nrow(sa_data))
} else {
  rowSums(!is.na(who_mat)) == 0
}

present_mat <- sapply(caregiver_codes, function(k) {
  cols_k <- paste0("hle_", activities, "_who___", k)
  X <- sa_data %>% dplyr::select(dplyr::any_of(cols_k)) %>% as.matrix()
  if (ncol(X) == 0) return(rep(FALSE, nrow(sa_data)))
  X[is.na(X)] <- 0
  rowSums(X) > 0
})

sa_data$num_caregivers <- rowSums(present_mat)
sa_data$num_caregivers[all_missing_who] <- NA_integer_

# # checks
# summary(sa_data$hla_frequency1)
# summary(sa_data$num_caregivers)
# summary(sa_data$books_toys_total1)
# summary(sa_data$time_total1)
# 
# # distributions
# table(sa_data$hla_frequency1, useNA = "ifany")
# table(sa_data$num_caregivers, useNA = "ifany")
# table(sa_data$books_toys_total1, useNA = "ifany")
# table(sa_data$time_total1, useNA = "ifany")
# 
# check: activities reported but "0 caregivers"
if (interactive()) {
  with(sa_data, table(num_caregivers > 0, hla_frequency1 == 0, useNA = "ifany"))
  with(sa_data, table(num_caregivers > 0, is.na(hla_frequency1), useNA = "ifany"))
}

sa_data <- sa_data %>%
  dplyr::mutate(
    num_caregivers_clean = dplyr::if_else(
      !is.na(hla_frequency1) & hla_frequency1 > 0 & num_caregivers == 0,
      NA_integer_,
      num_caregivers
    )
  )

sum(sa_data$hla_frequency1 > 0 & sa_data$num_caregivers == 0, na.rm = TRUE)
sum(sa_data$hla_frequency1 > 0 & is.na(sa_data$num_caregivers_clean), na.rm = TRUE) # n=84 with no caregiver info. reported.

```

```{r}
#| label: derive-nids-assets-score
#| include: false

asset_vars <- paste0("nids_items_", 1:26)

sa_data <- sa_data %>%
  dplyr::mutate(
    # re-code asset items: set refuse/don't know (3/4) to NA, otherwise keep integer
    dplyr::across(
      dplyr::all_of(asset_vars),
      ~ dplyr::if_else(.x %in% c(3L, 4L), NA_integer_, as.integer(.x))
    ),

    # number answered (non-missing) across the 26 items
    n_assets_answered = rowSums(!is.na(as.matrix(dplyr::pick(dplyr::all_of(asset_vars))))),

    # count "Yes" (== 1) across items, but only if >= 20 answered
    household_items_score_repl = dplyr::if_else(
      n_assets_answered < 20,
      NA_real_,
      rowSums(as.matrix(dplyr::pick(dplyr::all_of(asset_vars)) == 1L), na.rm = TRUE)
    )
  )

cor(sa_data$household_items_score, sa_data$household_items_score_repl,
    use = "pairwise.complete.obs")

sum(!is.na(sa_data$household_items_score) & !is.na(sa_data$household_items_score_repl) &
      sa_data$household_items_score != sa_data$household_items_score_repl)

# optional: inspect threshold behavior
table(sa_data$n_assets_answered < 20, useNA = "ifany")
summary(sa_data$household_items_score_repl)


```

```{r}
#| label: setup-helpers
#| include: false

library(gt)
# formatting helpers
fmt_mean_sd <- function(mean, sd, digits = 2) {
  ifelse(
    is.na(mean) | is.na(sd),
    NA_character_,
    sprintf(paste0("%.", digits, "f (%.", digits, "f)"), mean, sd)
  )
}

fmt_med_rng <- function(median, min, max, digits = 2) {
  ifelse(
    is.na(median) | is.na(min) | is.na(max),
    NA_character_,
    sprintf(paste0("%.", digits, "f [%.", digits, "f, %.", digits, "f]"),
            median, min, max)
  )
}

# Continuous descriptives within EF-anchored sample
summ_cont_tp <- function(df, var, any_ids, variable_label) {
  stopifnot(all(c("country","timepoint","id") %in% names(df)))
  stopifnot(all(c("country","timepoint","id") %in% names(any_ids)))
  stopifnot(var %in% names(df))

  df %>%
    inner_join(distinct(any_ids, country, timepoint, id),
               by = c("country","timepoint","id")) %>%
    transmute(country, timepoint, id, x = as.numeric(.data[[var]])) %>%
    group_by(country, timepoint) %>%
    summarise(
      n      = sum(!is.na(x)),
      mean   = ifelse(all(is.na(x)), NA_real_, mean(x, na.rm = TRUE)),
      sd     = ifelse(sum(!is.na(x)) > 1, sd(x, na.rm = TRUE), NA_real_),
      median = ifelse(all(is.na(x)), NA_real_, median(x, na.rm = TRUE)),
      min    = ifelse(all(is.na(x)), NA_real_, min(x, na.rm = TRUE)),
      max    = ifelse(all(is.na(x)), NA_real_, max(x, na.rm = TRUE)),
      .groups = "drop"
    ) %>%
    mutate(variable = variable_label)
}

# Table helper 
# EF descriptives
# ef_long: country, timepoint, id, variable, value
# any_ids: country, timepoint, id
summ_ef_desc <- function(ef_long, any_ids) {
  stopifnot(all(c("country","timepoint","id","variable","value") %in% names(ef_long)))
  stopifnot(all(c("country","timepoint","id") %in% names(any_ids)))

  ef_long %>%
    inner_join(distinct(any_ids, country, timepoint, id),
               by = c("country","timepoint","id")) %>%
    group_by(country, timepoint, variable) %>%
    summarise(
      n      = sum(!is.na(value)),
      mean   = ifelse(all(is.na(value)), NA_real_, mean(value, na.rm = TRUE)),
      sd     = ifelse(sum(!is.na(value)) > 1, sd(value, na.rm = TRUE), NA_real_),
      median = ifelse(all(is.na(value)), NA_real_, median(value, na.rm = TRUE)),
      min    = ifelse(all(is.na(value)), NA_real_, min(value, na.rm = TRUE)),
      max    = ifelse(all(is.na(value)), NA_real_, max(value, na.rm = TRUE)),
      .groups = "drop"
    )
}

# Sample sizes + EF completeness within EF-anchored sample
summ_sizes <- function(ef_long, any_ids, n_measures_complete = 3) {
  stopifnot(all(c("country","timepoint","id") %in% names(any_ids)))
  stopifnot(all(c("country","timepoint","id","variable","value") %in% names(ef_long)))

  ef_long_anch <- ef_long %>%
    inner_join(distinct(any_ids, country, timepoint, id),
               by = c("country","timepoint","id"))

  complete_by_child <- ef_long_anch %>%
    distinct(country, timepoint, id, variable, .keep_all = TRUE) %>%
    group_by(country, timepoint, id) %>%
    summarise(n_nonmiss_measures = sum(!is.na(value)), .groups = "drop")

  complete_by_child %>%
    group_by(country, timepoint) %>%
    summarise(
      n_children_any_ef = n_distinct(id),
      n_complete_ef     = sum(n_nonmiss_measures >= n_measures_complete),
      pct_complete_ef   = round(100 * mean(n_nonmiss_measures >= n_measures_complete), 1),
      .groups = "drop"
    )
}

# age descriptives within EF-anchored sample
summ_age_long <- function(age_long, any_ids) {
  stopifnot(all(c("country","timepoint","id") %in% names(any_ids)))
  stopifnot(all(c("country","timepoint","id","age") %in% names(age_long)))

  age_long %>%
    inner_join(distinct(any_ids, country, timepoint, id),
               by = c("country","timepoint","id")) %>%
    mutate(age = as.numeric(age)) %>%
    group_by(country, timepoint) %>%
    summarise(
      age_n      = sum(!is.na(age)),
      age_mean   = ifelse(age_n > 0, mean(age, na.rm = TRUE), NA_real_),
      age_sd     = ifelse(age_n > 1, sd(age, na.rm = TRUE), NA_real_),
      age_median = ifelse(age_n > 0, median(age, na.rm = TRUE), NA_real_),
      age_min    = ifelse(age_n > 0, min(age, na.rm = TRUE), NA_real_),
      age_max    = ifelse(age_n > 0, max(age, na.rm = TRUE), NA_real_),
      .groups = "drop"
    )
}

# categorical descriptives by timepoint (EF-anchored)
desc_cat_tp <- function(df, var, any_ids, variable_label) {
  stopifnot(all(c("country","timepoint","id") %in% names(df)))
  stopifnot(all(c("country","timepoint","id") %in% names(any_ids)))
  stopifnot(var %in% names(df))

  df %>%
    inner_join(distinct(any_ids, country, timepoint, id),
               by = c("country","timepoint","id")) %>%
    distinct(country, timepoint, id, .data[[var]]) %>%
    count(country, timepoint, .data[[var]], name = "n") %>%
    group_by(country, timepoint) %>%
    mutate(pct = 100 * n / sum(n)) %>%
    ungroup() %>%
    transmute(
      country,
      timepoint,
      variable = variable_label,
      level    = as.character(.data[[var]]),
      cell     = paste0(n, " (", sprintf("%.1f", pct), "%)")
    )
}

# Sex
harmonise_sex_sa <- function(x) {
  x <- as.character(x)
  out <- dplyr::case_when(
    is.na(x) | x == "" ~ "Missing",
    x == "0" ~ "Female",   # swap if codebook says 0=Male
    x == "1" ~ "Male",
    TRUE ~ "Other/Unknown"
  )
  factor(out, levels = c("Female","Male","Other/Unknown","Missing"))
}

harmonise_sex_aus <- function(x) {
  x <- as.character(x)
  out <- dplyr::case_when(
    is.na(x) | x == "" ~ "Missing",
    x == "1" ~ "Male",     # swap if codebook says 1=Female
    x == "2" ~ "Female",
    TRUE ~ "Other/Unknown"
  )
  factor(out, levels = c("Female","Male","Other/Unknown","Missing"))
}

```

```{r}
#| label: build-sa-aus-objects
#| include: false

eyt_vars <- c(
  "date_of_eyt", "eyt_child_age_at_testing", "eyt2_ageinmonths", "time_btwn_testing",
  "ef_inhibition", "ef_cogflex", "ef_workingmem",
  "refuse_missing_eyt", "notes_eyt", "early_years_toolbox_complete"
)

ses_vars <- c(
  # NIDS & income range
  "nids_income_1", "nids_income_2", "nids_income_3",
  "nids_income_4", "nids_income_5", "nids_income_6",
  "income_range", "monthly_income_given",

  # NIDS assets-derived score
  "household_items_score_repl",

  # education etc.
  "marital_status", "education_school", "education_post_school", "education_post_school_b",
  "children_in_house", "adults_in_house", "total_in_household",

  # HLE derived vars
  "hla_frequency1", "num_caregivers_clean", "books_toys_total1", "time_total1"
)

id_vars <- c(
  "caregiver_child_studyid", "redcap_event_name", "interview_date",
  "ra", "child_id", "caregiver_id",
  "child_sex", "child_dob", "child_age", "child_birthweight",
  "caregiver_dob", "caregiver_age", "relationship_child",
  "child_education", "child_education_specific", "child_education_frequency"
)

sa_subset_long <- sa_data %>%
  dplyr::select(dplyr::any_of(c(id_vars, ses_vars, eyt_vars))) %>%
  dplyr::distinct(caregiver_child_studyid, redcap_event_name, .keep_all = TRUE)

ef_sa <- c("ef_inhibition", "ef_cogflex", "ef_workingmem")

# child×event where any EF node observed
sa_any_ef_ids_by_tp <- sa_subset_long %>%
  dplyr::filter(dplyr::if_any(dplyr::all_of(ef_sa), ~ !is.na(.x))) %>%
  dplyr::distinct(redcap_event_name, caregiver_child_studyid)

sa_tp_map <- sa_subset_long %>%
  dplyr::distinct(redcap_event_name) %>%
  dplyr::mutate(
    timepoint = dplyr::case_when(
      redcap_event_name == "data_collection_20_arm_1"  ~ "T1",
      redcap_event_name == "data_collection_20_arm_1b" ~ "T2",
      TRUE ~ NA_character_
    )
  ) %>%
  dplyr::filter(!is.na(timepoint)) %>%
  dplyr::select(redcap_event_name, timepoint)

# exactly 2 timepoints
stopifnot(nrow(sa_tp_map) == 2)
stopifnot(all(c("T1","T2") %in% sa_tp_map$timepoint))

# Sex long (wave-level)
sa_sex_long <- sa_subset_long %>%
  dplyr::left_join(sa_tp_map, by = "redcap_event_name") %>%
  dplyr::transmute(
    country   = "SA",
    timepoint = timepoint,
    id        = caregiver_child_studyid,
    sex       = harmonise_sex_sa(child_sex)
  )

# standardized anchor ids: country,timepoint,id (EF-anchored)
sa_any_ids <- sa_any_ef_ids_by_tp %>%
  dplyr::left_join(sa_tp_map, by = "redcap_event_name") %>%
  dplyr::transmute(country = "SA", timepoint, id = caregiver_child_studyid)

# SA EF long (standard; EF-anchored)
sa_ef_long <- sa_subset_long %>%
  dplyr::inner_join(sa_any_ef_ids_by_tp, by = c("redcap_event_name","caregiver_child_studyid")) %>%
  dplyr::left_join(sa_tp_map, by = "redcap_event_name") %>%
  dplyr::transmute(
    country   = "SA",
    timepoint = timepoint,
    id        = caregiver_child_studyid,
    dplyr::across(dplyr::all_of(ef_sa), as.numeric)
  ) %>%
  tidyr::pivot_longer(cols = dplyr::all_of(ef_sa), names_to = "variable", values_to = "value") %>%
  dplyr::select(country, timepoint, id, variable, value)

# SA age long (standard, not EF-anchored here)
sa_age_long <- sa_subset_long %>%
  dplyr::left_join(sa_tp_map, by = "redcap_event_name") %>%
  dplyr::transmute(
    country   = "SA",
    timepoint = timepoint,
    id        = caregiver_child_studyid,
    age       = as.numeric(child_age)
  )

# SA SES long (standard; not EF-anchored here)
sa_ses <- sa_subset_long %>%
  dplyr::left_join(sa_tp_map, by = "redcap_event_name") %>%
  dplyr::transmute(
    country   = "SA",
    timepoint = timepoint,
    id        = caregiver_child_studyid,

    edu_sa = dplyr::if_else(
      education_post_school == 1,
      as.integer(education_post_school_b),
      NA_integer_
    ),

    nids_assets_sa = as.numeric(household_items_score_repl),
    income_range         = as.numeric(income_range),
    hla_frequency1       = as.numeric(hla_frequency1),
    num_caregivers_clean = as.numeric(num_caregivers_clean),
    books_toys_total1    = as.numeric(books_toys_total1),
    time_total1          = as.numeric(time_total1)
  )

# AU: wide -> standard EF long + anchors + age + SES
id_var <- if ("CID" %in% names(aus_data)) "CID" else "ServiceID"

t1_vars <- c("MrAnt_Pt_T1","GNG_IC_T1","CS_SwAcc_T1")
t2_vars <- c("MrAnt_Pt_T2","GNG_IC_T2","CS_SwAcc_T2")
t3_vars <- c("MrAnt_Pt_T3","GNG_IC_T3","CS_SwAcc_T3")
ef_vars <- c(t1_vars, t2_vars, t3_vars)

stopifnot(all(ef_vars %in% names(aus_data)))

aus_ef_long <- aus_data %>%
  dplyr::mutate(id = as.character(.data[[id_var]])) %>%
  dplyr::filter(!is.na(id)) %>%
  dplyr::select(id, dplyr::all_of(ef_vars)) %>%
  tidyr::pivot_longer(
    cols = -id,
    names_to = c("measure", "wave"),
    names_pattern = "^(.*)_T([123])$",
    values_to = "value"
  ) %>%
  dplyr::mutate(
    country   = "AU",
    timepoint = paste0("T", wave),
    variable  = dplyr::recode(measure,
      "MrAnt_Pt" = "ef_workingmem",
      "GNG_IC"   = "ef_inhibition",
      "CS_SwAcc" = "ef_cogflex"
    ),
    value = as.numeric(value)
  ) %>%
  dplyr::select(country, timepoint, id, variable, value)

aus_any_ids <- aus_ef_long %>%
  dplyr::group_by(country, timepoint, id) %>%
  dplyr::summarise(any_ef = any(!is.na(value)), .groups = "drop") %>%
  dplyr::filter(any_ef) %>%
  dplyr::select(country, timepoint, id)

stopifnot(all(c("Age_T1","Age_T2","Age_T3") %in% names(aus_data)))

aus_age_long <- aus_data %>%
  dplyr::mutate(id = as.character(.data[[id_var]])) %>%
  dplyr::filter(!is.na(id)) %>%
  dplyr::select(id, Age_T1, Age_T2, Age_T3) %>%
  tidyr::pivot_longer(cols = dplyr::starts_with("Age_T"), names_to = "timepoint", values_to = "age") %>%
  dplyr::mutate(
    country   = "AU",
    timepoint = gsub("^Age_", "", timepoint),
    age       = as.numeric(age)
  ) %>%
  dplyr::select(country, timepoint, id, age)

# Sex
sex_var_aus <- if ("Sex" %in% names(aus_data)) {
  "Sex"
} else if ("sex" %in% names(aus_data)) {
  "sex"
} else {
  stop("Couldn't find sex variable in aus_data (expected sex or Sex).")
}

aus_sex_child <- aus_data %>%
  dplyr::mutate(id = as.character(.data[[id_var]])) %>%
  dplyr::filter(!is.na(id)) %>%
  dplyr::distinct(id, .keep_all = TRUE) %>%
  dplyr::transmute(
    country = "AU",
    id,
    sex = harmonise_sex_aus(.data[[sex_var_aus]])
  )

table(sa_data$child_sex, useNA="ifany")
table(harmonise_sex_sa(sa_data$child_sex), useNA="ifany")

table(aus_data[[sex_var_aus]], useNA="ifany")
table(harmonise_sex_aus(aus_data[[sex_var_aus]]), useNA="ifany")

aus_sex_tp <- aus_any_ids %>%
  dplyr::left_join(aus_sex_child, by = c("country","id"))

# child-level SES + HLE
stopifnot(all(c("A2_MatEdu","A3_FamIncome") %in% names(aus_data)))

aus_ses_child <- aus_data %>%
  dplyr::mutate(id = as.character(.data[[id_var]])) %>%
  dplyr::filter(!is.na(id)) %>%
  dplyr::distinct(id, .keep_all = TRUE) %>%
  dplyr::transmute(
    country    = "AU",
    id,
    edu_aus    = as.integer(A2_MatEdu),
    income_aus = as.character(A3_FamIncome),
    hle_aus    = as.numeric(HLE_Index)
  )

# expand across EF-anchored timepoints
aus_ses_tp <- aus_any_ids %>%
  dplyr::left_join(aus_ses_child, by = c("country","id"))
table(aus_data$A3_FamIncome, useNA = "ifany")
class(aus_data$A3_FamIncome)
```

```{r}
#| label: build-ef-age-objects
#| include: false

stopifnot(exists("sa_ef_long"), exists("aus_ef_long"))
stopifnot(exists("sa_age_long"), exists("aus_age_long"))
# stopifnot(exists("sa_sex_long"), exists("aus_sex_tp"))

time_levels <- c("T1","T2","T3")
nodes <- c("ef_inhibition","ef_cogflex","ef_workingmem")

# helper: keep timepoints by country (SA only T1/T2; AU T1/T2/T3)
keep_ct_tp <- function(country, timepoint) {
  (country == "SA" & timepoint %in% c("T1","T2")) |
  (country == "AU" & timepoint %in% c("T1","T2","T3"))
}

# EF long combined
ef_all <- dplyr::bind_rows(
  sa_ef_long  %>% dplyr::mutate(id = as.character(id)),
  aus_ef_long %>% dplyr::mutate(id = as.character(id))
) %>%
  dplyr::mutate(
    timepoint = factor(as.character(timepoint), levels = time_levels, ordered = TRUE),
    variable  = factor(as.character(variable),  levels = nodes)
  )

# Age long combined
age_all <- dplyr::bind_rows(
  sa_age_long  %>% dplyr::mutate(id = as.character(id)),
  aus_age_long %>% dplyr::mutate(id = as.character(id))
) %>%
  dplyr::mutate(
    timepoint = factor(as.character(timepoint), levels = time_levels, ordered = TRUE),
    age       = as.numeric(age)
  )

# sex combined (already wave-level in pipeline)
# sex_all_tp <- dplyr::bind_rows(
#   sa_sex_long %>% dplyr::select(country, timepoint, id, sex),
#   aus_sex_tp  %>% dplyr::select(country, timepoint, id, sex)
# ) %>%
#   dplyr::mutate(
#     timepoint = factor(as.character(timepoint), levels = time_levels, ordered = TRUE),
#     id        = as.character(id)
#   )

# apply country-specific timepoint rule
ef_all_keep <- ef_all %>%
  dplyr::filter(keep_ct_tp(country, timepoint))

age_all_keep <- age_all %>%
  dplyr::filter(keep_ct_tp(country, timepoint))

# sex_all_tp_keep <- sex_all_tp %>%
#   dplyr::filter(keep_ct_tp(country, timepoint))

#  check
stopifnot(all(levels(ef_all_keep$variable) == nodes))

```

```{r}
#| label: ef-data-diagnostics
#| include: false

# Verify that ef_all_keep exists from build-ef-age-objects
stopifnot(exists("ef_all_keep"), exists("age_all_keep"))

cat("=== COMBINED EF DATA ===\n")
print(ef_all_keep %>% count(country, timepoint))

# Descriptive statistics
cat("\n=== DESCRIPTIVE STATISTICS ===\n\n")

descriptives <- ef_all_keep %>%
  group_by(country, timepoint, variable) %>%
  summarise(
    n = sum(!is.na(value)),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    min = min(value, na.rm = TRUE),
    q25 = quantile(value, 0.25, na.rm = TRUE),
    median = median(value, na.rm = TRUE),
    q75 = quantile(value, 0.75, na.rm = TRUE),
    max = max(value, na.rm = TRUE),
    .groups = "drop"
  )

print(descriptives)

# Missingness patterns
cat("\n=== MISSINGNESS PATTERNS ===\n\n")

# Need wide format for missingness analysis
ef_wide_temp <- ef_all_keep %>%
  pivot_wider(
    id_cols = c(country, timepoint, id),
    names_from = variable,
    values_from = value
  )

missingness <- ef_wide_temp %>%
  group_by(country, timepoint) %>%
  summarise(
    n_total = n(),
    n_inhibition = sum(!is.na(ef_inhibition)),
    n_cogflex = sum(!is.na(ef_cogflex)),
    n_workingmem = sum(!is.na(ef_workingmem)),
    n_all_ef = sum(!is.na(ef_inhibition) & !is.na(ef_cogflex) & !is.na(ef_workingmem)),
    n_any_ef = sum(!is.na(ef_inhibition) | !is.na(ef_cogflex) | !is.na(ef_workingmem)),
    pct_complete = 100 * n_all_ef / n_total,
    .groups = "drop"
  )

print(missingness)

# Floor/ceiling effects
cat("\n=== FLOOR/CEILING EFFECTS ===\n\n")

floor_ceiling <- ef_all_keep %>%
  filter(!is.na(value)) %>%
  group_by(country, timepoint, variable) %>%
  summarise(
    n = n(),
    n_at_min = sum(value == min(value)),
    n_at_max = sum(value == max(value)),
    pct_at_min = 100 * n_at_min / n,
    pct_at_max = 100 * n_at_max / n,
    .groups = "drop"
  )

print(floor_ceiling)

# Create plot-ready version with human-readable labels
cat("\n=== CREATING DISTRIBUTION PLOTS ===\n")

ef_long_plot <- ef_all_keep %>%
  mutate(
    measure = recode(variable,
      "ef_inhibition" = "Inhibition",
      "ef_cogflex" = "Cognitive Flexibility",
      "ef_workingmem" = "Working Memory"
    ),
    wave = as.character(timepoint)  # for plot labels
  )

# Histograms
p1 <- ggplot(ef_long_plot, aes(x = value, fill = country)) +
  geom_histogram(alpha = 0.6, position = "identity", bins = 30) +
  facet_grid(wave ~ measure, scales = "free") +
  theme_bw() +
  labs(title = "Distribution of EF Scores",
       x = "Score", y = "Count")

print(p1)

# Normality tests
cat("\n=== NORMALITY TESTS (Shapiro-Wilk) ===\n")
cat("(Only testing if n < 5000; otherwise skipping)\n\n")

normality_tests <- ef_long_plot %>%
  filter(!is.na(value)) %>%
  group_by(country, wave, measure) %>%
  summarise(
    n = n(),
    shapiro_p = if_else(
      n >= 3 & n < 5000,
      shapiro.test(value)$p.value,
      NA_real_
    ),
    .groups = "drop"
  )

print(normality_tests)

# Correlations within wave
cat("\n=== CORRELATIONS BETWEEN EF MEASURES (within wave) ===\n\n")

# Need wide format for correlations
correlations <- ef_wide_temp %>%
  group_by(country, timepoint) %>%
  summarise(
    n = sum(!is.na(ef_inhibition) & !is.na(ef_cogflex) & !is.na(ef_workingmem)),
    inh_cog = cor(ef_inhibition, ef_cogflex, use = "pairwise.complete"),
    inh_wm = cor(ef_inhibition, ef_workingmem, use = "pairwise.complete"),
    cog_wm = cor(ef_cogflex, ef_workingmem, use = "pairwise.complete"),
    .groups = "drop"
  )

print(correlations)

cat("\nObjects created:\n")
cat("- descriptives: summary statistics by cohort×wave×measure\n")
cat("- missingness: missingness patterns by cohort×wave\n")
cat("- floor_ceiling: floor/ceiling effects by cohort×wave×measure\n")
cat("- correlations: within-wave correlations between EF measures\n")
cat("- ef_long_plot: plot-ready long-format data with human-readable labels\n")

```

```{r}
#| label: invariance-data-prep
#| include: false

# Multi-group CFA invariance with all three vars treated as ordinal

# Start with ef_all_keep (long format)
# Convert to wide format for lavaan
df_mi_wide <- ef_all_keep %>%
  filter(timepoint %in% c("T1", "T2")) %>%  # Only T1 and T2 (SA has no T3)
  pivot_wider(
    id_cols = c(country, timepoint, id),
    names_from = variable,
    values_from = value
  ) %>%
  mutate(group = paste(country, timepoint, sep = "_")) %>%
  filter(group %in% c("AU_T1", "AU_T2", "SA_T1", "SA_T2"))

# Define tertile binning function
qcut3 <- function(x) {
  qs <- quantile(x, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE, names = FALSE)
  qs <- unique(qs)
  if (length(qs) < 4) return(ordered(NA))
  cut(x, breaks = qs, include.lowest = TRUE,
      labels = c("L","M","H"), ordered_result = TRUE)
}

# Create ordinal categories (pooled tertiles)
df_mi <- df_mi_wide %>%
  mutate(
    inh_cat = qcut3(ef_inhibition),
    wm_cat  = qcut3(ef_workingmem),
    cf_cat  = qcut3(ef_cogflex)
  )

# Check no empty categories
cat("=== CATEGORY DISTRIBUTIONS ===\n\n")
print(with(df_mi, table(group, inh_cat, useNA="no")))
print(with(df_mi, table(group, wm_cat,  useNA="no")))
print(with(df_mi, table(group, cf_cat,  useNA="no")))
```

```{r}
#| label: invariance-models
#| include: false

# Define EF factor model
model_ef <- "
EF =~ inh_cat + wm_cat + cf_cat
"

# Fit configural model (same structure across groups)
fit_config <- cfa(
  model_ef,
  data = df_mi,
  group = "group",
  ordered = c("inh_cat","wm_cat","cf_cat"),
  estimator = "WLSMV"
)

# Fit metric model (equal loadings)
fit_metric <- cfa(
  model_ef,
  data = df_mi,
  group = "group",
  ordered = c("inh_cat","wm_cat","cf_cat"),
  estimator = "WLSMV",
  group.equal = "loadings"
)

# Fit scalar model (equal loadings + thresholds)
fit_scalar <- cfa(
  model_ef,
  data = df_mi,
  group = "group",
  ordered = c("inh_cat","wm_cat","cf_cat"),
  estimator = "WLSMV",
  group.equal = c("loadings","thresholds")
)

# Compare models
cmp_metric <- lavTestLRT(fit_config, fit_metric)
cmp_scalar <- lavTestLRT(fit_metric, fit_scalar)

cat("=== MODEL COMPARISONS ===\n\n")
print(cmp_metric)
print(cmp_scalar)

cat("\n=== FIT SUMMARIES ===\n\n")
cat("Configural:\n")
print(fitMeasures(fit_config, c("cfi","tli","rmsea","srmr")))
cat("\nMetric:\n")
print(fitMeasures(fit_metric, c("cfi","tli","rmsea","srmr")))
cat("\nScalar:\n")
print(fitMeasures(fit_scalar, c("cfi","tli","rmsea","srmr")))
```

```{r}
#| label: mi-extract
#| include: false

# helper: pull the "diff test" row from lavTestLRT output
extract_lrt <- function(lrt_obj) {
  # lavTestLRT returns a data.frame-like object with two rows:
  # row 1 = less constrained model, row 2 = more constrained model
  df <- as.data.frame(lrt_obj)
  out <- df[nrow(df), , drop = FALSE]

  list(
    chisq = unname(out$`Chisq diff`),
    df    = unname(out$`Df diff`),
    p     = unname(out$`Pr(>Chisq)`)
  )
}

lrt_metric <- extract_lrt(cmp_metric)  # configural -> metric
lrt_scalar <- extract_lrt(cmp_scalar)  # metric -> scalar

# Grab fit indices 
fit_conf <- fitMeasures(fit_config, c("cfi","tli","rmsea","srmr"))
fit_met  <- fitMeasures(fit_metric, c("cfi","tli","rmsea","srmr"))
fit_sca  <- fitMeasures(fit_scalar, c("cfi","tli","rmsea","srmr"))

dCFI_metric <- unname(fit_met["cfi"] - fit_conf["cfi"])
dCFI_scalar <- unname(fit_sca["cfi"] - fit_met["cfi"])
```
### Measurement Invariance

To evaluate cross-cohort comparability of EF indicators, we conducted multi-group confirmatory factor analyses (CFA) across four cohort×wave groups (AU_T1, AU_T2, SA_T1, SA_T2), thereby testing invariance simultaneously across countries and developmental timepoints. Because cognitive flexibility exhibited pronounced floor effects in Australian children at T1 (32.5% scoring zero), all three EF indicators were treated as ordinal variables using robust weighted least squares estimation (WLSMV). Indicators were segmented into tertiles based on pooled distributions to ensure adequate category representation.

In ordinal CFA, each observed categorical indicator reflects an underlying continuous latent response variable partitioned by thresholds. Factor loadings capture the strength of association between the latent EF construct and each indicator, while thresholds capture distributional placement of categories. This allows floor effect severity to be represented through threshold parameters without distorting factor loadings.

We estimated a one-factor model in a sequence of increasingly constrained models. Configural invariance was supported. Constraining factor loadings equal across groups (metric invariance) did not significantly reduce fit (Δχ²(`r lrt_metric$df`) = `r round(lrt_metric$chisq, 2)`, *p* = `r signif(lrt_metric$p, 3)`; ΔCFI = `r round(dCFI_metric, 3)`), indicating comparable strength of association between the EF factor and its indicators. However, constraining thresholds (scalar invariance) significantly worsened fit (Δχ²(`r lrt_scalar$df`) = `r round(lrt_scalar$chisq, 2)`, *p* < .001; ΔCFI = `r round(dCFI_scalar, 3)`), with CFI declining from `r round(fit_met["cfi"], 3)` to `r round(fit_sca["cfi"], 3)`, indicating systematic threshold differences across groups. Metric invariance supports comparison of network structures (relationships between EF components) across cohorts, though absolute performance levels cannot be compared (see @tbl-invariance) .

```{r}
#| label: tbl-invariance
#| tbl-cap: "Measurement Invariance Testing: Fit Indices and Model Comparisons"

# Create combined table with fit indices AND tests
inv_table <- tibble::tibble(
  Model = c("Configural", "Metric", "Scalar"),
  CFI = c(fit_conf["cfi"], fit_met["cfi"], fit_sca["cfi"]),
  TLI = c(fit_conf["tli"], fit_met["tli"], fit_sca["tli"]),
  RMSEA = c(fit_conf["rmsea"], fit_met["rmsea"], fit_sca["rmsea"]),
  SRMR = c(fit_conf["srmr"], fit_met["srmr"], fit_sca["srmr"]),
  `Δχ²` = c(NA, lrt_metric$chisq, lrt_scalar$chisq),
  `Δdf` = c(NA, lrt_metric$df, lrt_scalar$df),
  `p` = c(NA, lrt_metric$p, lrt_scalar$p),
  ΔCFI = c(NA, dCFI_metric, dCFI_scalar)
) %>%
  mutate(
    Decision = case_when(
      is.na(p) ~ "—",
      abs(ΔCFI) < 0.01 & p > 0.05 ~ "Supported",
      TRUE ~ "Not supported"
    )
  )

inv_table %>%
  gt() %>%
  opt_css(
    css = "
    #tbl-invariance {
      margin-top: 30px;
    }
    "
  ) %>%
  fmt_number(columns = c(CFI, TLI, RMSEA, SRMR, ΔCFI), decimals = 3) %>%
  fmt_number(columns = `Δχ²`, decimals = 2) %>%
  fmt_number(columns = p, decimals = 3) %>%
  sub_missing(missing_text = "—") %>%
  tab_style(
    style = cell_fill(color = "#E8F5E9"),
    locations = cells_body(rows = Decision == "Supported")
  ) %>%
  tab_style(
    style = cell_fill(color = "#FFEBEE"),
    locations = cells_body(rows = Decision == "Not supported")
  ) %>%
  tab_footnote(
    footnote = "ΔCFI < 0.01 indicates invariance is supported (Cheung & Rensvold, 2002)",
    locations = cells_column_labels(columns = ΔCFI)
  ) %>%
  tab_footnote(
    footnote = "Ordinal CFA with WLSMV estimation; four groups: AU_T1, AU_T2, SA_T1, SA_T2",
    locations = cells_column_labels(columns = Model)
  )
```
\clearpage

```{r}
#| label: prepare-moderators
#| include: false

# SA moderators at T1
sa_mods_t1 <- sa_ses %>%
  dplyr::filter(timepoint == "T1") %>%
  dplyr::transmute(
    country,
    id,
    income_raw = as.numeric(income_range),
    hle_raw    = as.numeric(hla_frequency1)
  ) %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(
    income_z = scale(income_raw)[,1],
    hle_z    = scale(hle_raw)[,1]
  ) %>%
  dplyr::ungroup() %>%
  dplyr::select(country, id, income_z, hle_z)

# AU moderators at T1
au_mods_t1 <- aus_ses_tp %>%
  dplyr::filter(timepoint == "T1") %>%
  dplyr::transmute(
    country,
    id,
    income_raw = as.numeric(income_aus),
    hle_raw    = as.numeric(hle_aus)
  ) %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(
    income_z = scale(income_raw)[,1],
    hle_z    = scale(hle_raw)[,1]
  ) %>%
  dplyr::ungroup() %>%
  dplyr::select(country, id, income_z, hle_z)

# Combine T1 moderators
mods_t1 <- dplyr::bind_rows(sa_mods_t1, au_mods_t1)
```

```{r}
#| label: step0-data-prep
#| include: false

# Prepare EF node data for BGGM:
# - keep partial EF
# - drop cohort×wave IDs with all 3 nodes missing
# - residualize each node for age within cohort×wave
# - z-score residuals within cohort×wave×node
# - pivot wide for BGGM

stopifnot(exists("ef_all_keep"), exists("age_all_keep")) 
stopifnot(exists("nodes"))

# helper for within-group z-score
z_within <- function(x) {
  m <- mean(x, na.rm = TRUE)
  s <- stats::sd(x, na.rm = TRUE)
  if (is.na(s) || s == 0) return(rep(NA_real_, length(x)))
  (x - m) / s
}

# join covariate (age) + restrict to EF nodes
ef_net0 <- ef_all_keep %>%
  dplyr::filter(as.character(variable) %in% nodes) %>%
  dplyr::left_join(
    age_all_keep %>% dplyr::select(country, timepoint, id, age),
    by = c("country","timepoint","id")
  ) %>%
  dplyr::mutate(
    id    = as.character(id),
    age   = as.numeric(age),
    value = as.numeric(value)
  ) %>%
  dplyr::filter(!is.na(age)) # controlling for age only (not sex)

# check duplicates before pivot_wider 
dup_check <- ef_net0 %>%
  dplyr::count(country, timepoint, id, variable, name = "n") %>%
  dplyr::filter(n > 1)

stopifnot(nrow(dup_check) == 0)

# drop cohort×wave IDs with all three nodes missing
ef_any_ids <- ef_net0 %>%
  dplyr::group_by(country, timepoint, id) %>%
  dplyr::summarise(any_node_observed = any(!is.na(value)), .groups = "drop") %>%
  dplyr::filter(any_node_observed) %>%
  dplyr::select(country, timepoint, id)

ef_net0 <- ef_net0 %>%
  dplyr::inner_join(ef_any_ids, by = c("country","timepoint","id"))

# residualize within cohort×wave×node (observed values only), then z-score residuals
residise_one <- function(d) {
  d <- dplyr::mutate(d, .rid = dplyr::row_number())
  obs <- dplyr::filter(d, !is.na(value))

  if (nrow(obs) < 10) {
    d$resid <- NA_real_
    return(dplyr::select(d, -.rid))
  }

  fit <- stats::lm(value ~ age, data = obs)
  obs <- dplyr::mutate(obs, resid = stats::residuals(fit))

  d <- dplyr::left_join(d, dplyr::select(obs, .rid, resid), by = ".rid")
  dplyr::select(d, -.rid)
}

ef_net <- ef_net0 %>%
  dplyr::group_by(country, timepoint, variable) %>%
  dplyr::group_modify(~ residise_one(.x)) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(country, timepoint, variable) %>%
  dplyr::mutate(node = ifelse(is.na(resid), NA_real_, z_within(resid))) %>%
  dplyr::ungroup()

# check if residualization wiped an entire node within cohort×wave
node_obs_check <- ef_net %>%
  dplyr::group_by(country, timepoint, variable) %>%
  dplyr::summarise(n_obs = sum(!is.na(node)), .groups = "drop")

stopifnot(all(node_obs_check$n_obs > 0))

# wide matrix per cohort×wave for BGGM
ef_net_wide <- ef_net %>%
  dplyr::select(country, timepoint, id, variable, node) %>%
  tidyr::pivot_wider(
    names_from = variable,
    values_from = node
  ) %>%
  dplyr::filter(!dplyr::if_all(dplyr::all_of(nodes), ~ is.na(.)))

# within-wave missingness vs attrition diagnostics
missingness_ct <- ef_net_wide %>%
  dplyr::group_by(country, timepoint) %>%
  dplyr::summarise(
    n          = dplyr::n(),
    missing_cells = sum(is.na(as.matrix(dplyr::pick(dplyr::all_of(nodes))))),
    total_cells   = dplyr::n() * length(nodes),
    pct_missing   = 100 * missing_cells / total_cells,
    .groups = "drop"
  )

# align draws helper
align_draws <- function(x, y, keep = c("last","first")) {
  keep <- match.arg(keep)
  n <- min(length(x), length(y))
  if (keep == "last") list(x = tail(x, n), y = tail(y, n))
  else                list(x = head(x, n), y = head(y, n))
}
```

```{r}
#| label: step_1a-fit-bggm
#| include: false

stopifnot(exists("ef_net_wide"))
stopifnot(all(c("country","timepoint","id", nodes) %in% names(ef_net_wide)))

bggm_post   <- 5000
bggm_burnin <- 50
bggm_iter   <- bggm_post + bggm_burnin
bggm_chains <- 1

dat_split <- ef_net_wide %>%
  dplyr::select(country, timepoint, id, dplyr::all_of(nodes)) %>%
  dplyr::group_by(country, timepoint) %>%
  dplyr::group_split()

keys <- ef_net_wide %>%
  dplyr::select(country, timepoint, id, dplyr::all_of(nodes)) %>%
  dplyr::group_by(country, timepoint) %>%
  dplyr::group_keys() %>%
  dplyr::arrange(country, timepoint)

stopifnot(nrow(keys) == length(dat_split))

fit_one <- function(df) {

  Y <- df %>%
    dplyr::select(dplyr::all_of(nodes)) %>%
    dplyr::mutate(dplyr::across(dplyr::everything(), as.numeric)) %>%
    as.matrix()

  n <- nrow(Y)
  p <- ncol(Y)
  miss_cells <- sum(is.na(Y))
  total_cells <- length(Y)
  pct_missing <- 100 * miss_cells / total_cells

  # if too small for the model, return null fit but keep diagnostics
  if (n < 10) {
    return(list(
      fit = NULL,
      n = n,
      missing_cells = miss_cells,
      total_cells = total_cells,
      pct_missing = pct_missing
    ))
  }

  fit <- BGGM::estimate(
    Y,
    type   = "continuous",
    iter   = bggm_iter,
    burnin = bggm_burnin,
    chains = bggm_chains,
    impute = TRUE,
    save   = TRUE
  )

  list(
    fit = fit,
    n = n,
    missing_cells = miss_cells,
    total_cells = total_cells,
    pct_missing = pct_missing
  )
}

ggm_fits_step1 <- purrr::map(dat_split, fit_one)

fit_tbl <- keys %>%
  dplyr::mutate(res = ggm_fits_step1) %>%
  tidyr::unnest_wider(res)

# check fit
fit_tbl %>%
  dplyr::mutate(ok = !purrr::map_lgl(fit, is.null)) %>%
  dplyr::select(country, timepoint, n, missing_cells, total_cells, pct_missing, ok)
fit_tbl

```

```{r}
#| label: net-helpers
#| include: false

edge_draws_list <- function(fit, node_names = nodes) {
  A <- fit$post_samp$pcors  # [p x p x S]
  p <- dim(A)[1]
  stopifnot(length(node_names) == p)

  # enforce names
  dimnames(A) <- list(node_names, node_names, NULL)

  idx <- which(upper.tri(matrix(FALSE, p, p)), arr.ind = TRUE)

  out <- vector("list", nrow(idx))
  nms <- character(nrow(idx))

  for (i in seq_len(nrow(idx))) {
    a <- idx[i, 1]; b <- idx[i, 2]
    out[[i]] <- A[a, b, ]
    nms[i] <- paste0(node_names[a], " — ", node_names[b])
  }
  names(out) <- nms
  out
}

global_strength_draws <- function(fit, absolute = TRUE) {
  A <- fit$post_samp$pcors  # [p x p x S]
  p <- dim(A)[1]
  S <- dim(A)[3]
  ut <- upper.tri(matrix(FALSE, p, p))

  sapply(seq_len(S), function(s) {
    M <- A[, , s]
    if (absolute) M <- abs(M)
    sum(M[ut])
  })
}

expected_influence_draws <- function(fit, node_names = nodes) {
  A <- fit$post_samp$pcors   # [p x p x S]
  p <- dim(A)[1]
  S <- dim(A)[3]
  stopifnot(length(node_names) == p)

  # enforce node names
  dimnames(A) <- list(node_names, node_names, NULL)

  # EI per node per draw: S x p (signed sum of incident edges; excludes diagonal)
  EI <- vapply(seq_len(S), function(s) {
    M <- A[, , s]
    rowSums(M, na.rm = TRUE) - diag(M)
  }, FUN.VALUE = numeric(p))

  EI <- t(EI)              # S x p
  colnames(EI) <- node_names
  EI
}

ei_summaries <- function(fit, node_names = nodes, probs = c(.025, .5, .975)) {
  EI <- expected_influence_draws(fit, node_names = node_names)  # S x p
  tibble::tibble(
    node = colnames(EI),
    q025 = apply(EI, 2, stats::quantile, probs[1], na.rm = TRUE),
    q50  = apply(EI, 2, stats::quantile, probs[2], na.rm = TRUE),
    q975 = apply(EI, 2, stats::quantile, probs[3], na.rm = TRUE)
  )
}

```

```{r}
#| label: report-edge-summaries
#| include: false

edge_summaries <- function(fit, probs = c(.025, .5, .975), node_names = nodes) {
  A <- fit$post_samp$pcors  # [p x p x S]
  p <- dim(A)[1]

  # enforce node names 
  stopifnot(length(node_names) == p)
  dimnames(A) <- list(node_names, node_names, NULL)
  nm <- node_names

  # upper-triangle indices
  idx <- which(upper.tri(matrix(FALSE, p, p)), arr.ind = TRUE)

  purrr::map_dfr(seq_len(nrow(idx)), function(i) {
    a <- idx[i, 1]; b <- idx[i, 2]
    draws <- A[a, b, ]
    qs <- stats::quantile(draws, probs = probs, na.rm = TRUE)

    tibble::tibble(
      node1 = nm[a],
      node2 = nm[b],
      q025  = unname(qs[1]),
      q50   = unname(qs[2]),
      q975  = unname(qs[3]),
      ci_excludes_0 = !(unname(qs[1]) <= 0 & unname(qs[3]) >= 0)
    )
  })
}

edge_tbl <- fit_tbl %>%
  dplyr::filter(!purrr::map_lgl(fit, is.null)) %>%
  dplyr::mutate(edges = purrr::map(fit, edge_summaries)) %>%
  tidyr::unnest(edges) %>%
  dplyr::mutate(
    edge = vapply(
    Map(c, node1, node2),
    function(z) paste(sort(unlist(z)), collapse = " - "),
    character(1)
  )
)

```

```{r}
#| label: report-global-strength
#| include: false
#| 
gs_tbl <- fit_tbl %>%
  dplyr::filter(!purrr::map_lgl(fit, is.null)) %>%
  dplyr::mutate(
    gs_draws = purrr::map(fit, global_strength_draws),
    q025 = purrr::map_dbl(gs_draws, ~ stats::quantile(.x, .025, na.rm = TRUE)),
    q50  = purrr::map_dbl(gs_draws, ~ stats::quantile(.x, .50,  na.rm = TRUE)),
    q975 = purrr::map_dbl(gs_draws, ~ stats::quantile(.x, .975, na.rm = TRUE))
  ) %>%
  dplyr::select(country, timepoint, q025, q50, q975)

```

```{r}
#| label: report-posterior-difference-scores
#| include: false

edge_diff <- function(fit_A, fit_B) {
  A <- fit_A$post_samp$pcors
  B <- fit_B$post_samp$pcors

  # align draw counts 
  S <- min(dim(A)[3], dim(B)[3])
  A <- A[, , (dim(A)[3] - S + 1):dim(A)[3], drop = FALSE]
  B <- B[, , (dim(B)[3] - S + 1):dim(B)[3], drop = FALSE]

  D <- A - B # posterior draws of differences

  p <- dim(D)[1]
  edges <- which(upper.tri(matrix(NA, p, p)), arr.ind = TRUE)

  purrr::map_dfr(seq_len(nrow(edges)), function(i) {
    a <- edges[i, 1]; b <- edges[i, 2]
    draws <- D[a, b, ]
    qs <- quantile(draws, c(.025, .5, .975), na.rm = TRUE)
    tibble::tibble(
      node1 = dimnames(D)[[1]][a],
      node2 = dimnames(D)[[2]][b],
      diff_q025 = unname(qs[1]),
      diff_q50  = unname(qs[2]),
      diff_q975 = unname(qs[3]),
      diff_sig  = !(qs[1] <= 0 && qs[3] >= 0)  # CI excludes 0
    )
  })
}

fit_AU_T1 <- fit_tbl %>% dplyr::filter(country=="AU", timepoint=="T1") %>% dplyr::pull(fit) %>% .[[1]]
fit_SA_T1 <- fit_tbl %>% dplyr::filter(country=="SA", timepoint=="T1") %>% dplyr::pull(fit) %>% .[[1]]

edge_diff_AUvsSA_T1 <- edge_diff(fit_AU_T1, fit_SA_T1)
```

```{r}
#| label: report-global-strength-difference-scores
#| include: false

gs_diff <- function(fit_A, fit_B) {
  gsA <- global_strength_draws(fit_A)
  gsB <- global_strength_draws(fit_B)
  S <- min(length(gsA), length(gsB))
  gsA <- tail(gsA, S); gsB <- tail(gsB, S)
  d <- gsA - gsB
  tibble::tibble(
    diff_mean = mean(d),
    diff_q025 = quantile(d, .025),
    diff_q975 = quantile(d, .975),
    diff_sig  = !(quantile(d, .025) <= 0 && quantile(d, .975) >= 0)
  )
}
```

```{r}
#| label: report-missingness
#| include: false

missingness_ct <- purrr::map2_dfr(dat_split, keys$country, function(df, cc) {
   NULL
})

missingness_ct <- purrr::map2_dfr(dat_split, seq_len(nrow(keys)), function(df, i) {
  Y <- df %>%
    dplyr::select(dplyr::all_of(nodes)) %>%
    dplyr::mutate(dplyr::across(dplyr::everything(), as.numeric)) %>%
    as.matrix()

  tibble::tibble(
    country       = keys$country[i],
    timepoint     = keys$timepoint[i],
    n             = nrow(Y),
    missing_cells = sum(is.na(Y)),
    total_cells   = length(Y),
    pct_missing   = 100 * sum(is.na(Y)) / length(Y)
  )
})
missingness_ct
```

```{r}
#| label: rq1-tables
#| include: false

rope <- 0.10  

# helpers
fmt_ci <- function(m, lo, hi, digits = 2) {
  sprintf(paste0("%.", digits, "f [%.", digits, "f, %.", digits, "f]"), m, lo, hi)
}
fmt_p <- function(p, digits = 2) sprintf(paste0("%.", digits, "f"), p)

summ_draws <- function(draws, rope = 0.10) {
  qs <- stats::quantile(draws, c(.025, .5, .975), na.rm = TRUE)
  tibble::tibble(
    q025 = unname(qs[1]),
    q50  = unname(qs[2]),
    q975 = unname(qs[3]),
    p_outside_rope = mean(abs(draws) > rope, na.rm = TRUE)
  )
}

# checks
stopifnot(exists("edge_draws_list"))
stopifnot(exists("global_strength_draws"))
stopifnot(exists("ei_summaries"))
stopifnot(exists("fit_tbl"))
stopifnot(exists("nodes"))

# one row per cohort×wave
fit_tbl_uniq <- fit_tbl %>%
  dplyr::filter(!purrr::map_lgl(fit, is.null)) %>%
  dplyr::arrange(country, timepoint) %>%
  dplyr::group_by(country, timepoint) %>%
  dplyr::slice(1) %>%
  dplyr::ungroup()

# edges
rq1_edges <- fit_tbl_uniq %>%
  dplyr::transmute(country, timepoint, n, pct_missing, fit) %>%
  dplyr::mutate(edge_list = purrr::map(fit, ~ edge_draws_list(.x, node_names = nodes))) %>%
  dplyr::mutate(edge_df   = purrr::map(edge_list, ~ tibble::tibble(edge = names(.x), draws = unname(.x)))) %>%
  tidyr::unnest(edge_df) %>%
  dplyr::mutate(stats = purrr::map(draws, ~ summ_draws(.x, rope = rope))) %>%
  tidyr::unnest(stats) %>%
  dplyr::transmute(
    country, timepoint, n, pct_missing,
    edge,
    estimate = fmt_ci(q50, q025, q975, digits = 2),
    rope_p   = fmt_p(p_outside_rope, digits = 2)
  ) %>%
  # canonicalise edge names so ordering is consistent everywhere
  dplyr::mutate(
    edge = vapply(
      strsplit(edge, " — ", fixed = TRUE),
      function(z) paste(sort(z), collapse = " - "),
      character(1)
    )
  )

# global strength
rq1_gs <- fit_tbl_uniq %>%
  dplyr::transmute(country, timepoint, n, pct_missing, fit) %>%
  dplyr::mutate(gs_draws = purrr::map(fit, global_strength_draws)) %>%
  dplyr::mutate(stats = purrr::map(gs_draws, ~ {
    qs <- stats::quantile(.x, c(.025, .5, .975), na.rm = TRUE)
    tibble::tibble(q025 = unname(qs[1]), q50 = unname(qs[2]), q975 = unname(qs[3]))
  })) %>%
  tidyr::unnest(stats) %>%
  dplyr::transmute(
    country, timepoint, n, pct_missing,
    edge     = "Global strength",
    estimate = fmt_ci(q50, q025, q975, digits = 2),
    rope_p   = NA_character_
  )

rq1_table_A <- dplyr::bind_rows(rq1_gs, rq1_edges) %>%
  dplyr::mutate(
    rope_p = dplyr::if_else(edge == "Global strength", "", rope_p)
  ) %>%
  dplyr::arrange(country, timepoint, dplyr::desc(edge == "Global strength"), edge)

# check: 4 rows per cohort×wave (3 edges + global strength)
stopifnot(all((rq1_table_A %>% dplyr::count(country, timepoint) %>% dplyr::pull(n)) == 4))

# expected influence (node-level)
rq1_table_B <- fit_tbl_uniq %>%
  dplyr::transmute(country, timepoint, n, pct_missing, fit) %>%
  dplyr::mutate(ei = purrr::map(fit, ~ ei_summaries(.x, node_names = nodes))) %>%
  tidyr::unnest(ei) %>%
  dplyr::transmute(
    country, timepoint, n, pct_missing,
    node,
    estimate = fmt_ci(q50, q025, q975, digits = 2)
  ) %>%
  dplyr::arrange(country, timepoint, node)

# check: p rows per cohort×wave
stopifnot(all((rq1_table_B %>% dplyr::count(country, timepoint) %>% dplyr::pull(n)) == length(nodes)))

```

```{r}
#| label: rq1-inline-report-helpers
#| include: false

node_label_map <- c(
  "Inhibition"            = "ef_inhibition",
  "Cognitive flexibility" = "ef_cogflex",
  "Working memory"        = "ef_workingmem"
)

normalise_country <- function(x) {
  dplyr::case_when(
    x %in% c("Australia", "AU")    ~ "AU",
    x %in% c("South Africa", "SA") ~ "SA",
    TRUE ~ x
  )
}

canonical_edge_key <- function(edge_label) {
  # accept en dash or hyphen
  parts <- trimws(strsplit(edge_label, "–|-", perl = TRUE)[[1]])
  stopifnot(length(parts) == 2)

  vars <- unname(node_label_map[parts])
  if (any(is.na(vars))) {
    stop("Unknown node label in: ", edge_label,
         "\nExpected one of: ", paste(names(node_label_map), collapse = ", "))
  }

  paste(sort(vars), collapse = " - ")
}

edge_row <- function(country, tp, edge_label) {
  ctry <- normalise_country(country)
  key  <- canonical_edge_key(edge_label)

  out <- rq1_table_A %>%
    dplyr::filter(.data$country == ctry,
                  .data$timepoint == tp,
                  .data$edge == key)

  if (nrow(out) != 1) {
    stop("Could not uniquely match: ", country, ", ", tp, ", ", edge_label,
         "\nRows matched: ", nrow(out))
  }
  out
}

edge_report <- function(country, tp, edge_label) {
  edge_row(country, tp, edge_label)$estimate
}

edge_meaningful <- function(country, tp, edge_label) {
  r <- edge_row(country, tp, edge_label)
  paste0("P(|r|>0.1)=", r$rope_p)
}

global_strength_report <- function(country, tp) {
  ctry <- normalise_country(country)
  out <- rq1_table_A %>%
    dplyr::filter(.data$country == ctry,
                  .data$timepoint == tp,
                  .data$edge == "Global strength")

  if (nrow(out) != 1) stop("Could not uniquely match global strength: ", country, ", ", tp)
  out$estimate
}

# EI reporting helpers
ei_row <- function(country, tp, node_label) {
  ctry <- normalise_country(country)

  # same label set as elsewhere
  node_key <- unname(node_label_map[node_label])
  if (is.na(node_key)) {
    stop("Unknown node label: ", node_label,
         "\nExpected one of: ", paste(names(node_label_map), collapse = ", "))
  }

  out <- rq1_table_B %>%
    dplyr::filter(.data$country == ctry,
                  .data$timepoint == tp,
                  .data$node == node_key)

  if (nrow(out) != 1) {
    stop("Could not uniquely match expected influence: ", country, ", ", tp, ", ", node_label,
         "\nRows matched: ", nrow(out))
  }
  out
}

ei_report <- function(country, tp, node_label) {
  ei_row(country, tp, node_label)$estimate
}
```

### Research Question 1 (Primary): EF Network Structure Within Cohorts
Within each cohort and wave, what is the age-adjusted EF network—defined by partial correlations among working memory, inhibition, and cognitive flexibility—and what do global strength and expected influence indicate about overall connectivity and node centrality?

### Edges

Within-wave age-adjusted partial correlations are summarized in @tbl-rq1-gt-all and visualized in @fig-rq1-edge-forest.
In Australia, edges involving working memory showed the clearest evidence of coupling across waves. The inhibition–working memory edge was consistently positive (T1: `r edge_report("Australia", "T1", "Inhibition – Working memory")`; T2: `r edge_report("Australia", "T2", "Inhibition – Working memory")`; T3: `r edge_report("Australia", "T3", "Inhibition – Working memory")`) and reliably exceeded the meaningfulness threshold (T1: `r edge_meaningful("Australia", "T1", "Inhibition – Working memory")`; T2: `r edge_meaningful("Australia", "T2", "Inhibition – Working memory")`; T3: `r edge_meaningful("Australia", "T3", "Inhibition – Working memory")`). The cognitive flexibility–working memory edge was also positive across waves (T1: `r edge_report("Australia", "T1", "Cognitive flexibility – Working memory")`; T2: `r edge_report("Australia", "T2", "Cognitive flexibility – Working memory")`; T3: `r edge_report("Australia", "T3", "Cognitive flexibility – Working memory")`) and exceeded the meaningfulness threshold (meaningfulness: T1: `r edge_meaningful("Australia", "T1", "Cognitive flexibility – Working memory")`; T2: `r edge_meaningful("Australia", "T2", "Cognitive flexibility – Working memory")`; T3: `r edge_meaningful("Australia", "T3", "Cognitive flexibility – Working memory")`). In contrast, the cognitive flexibility–inhibition edge was weaker and more wave-dependent (T1: `r edge_report("Australia", "T1", "Cognitive flexibility – Inhibition")`; T2: `r edge_report("Australia", "T2", "Cognitive flexibility – Inhibition")`; T3: `r edge_report("Australia", "T3", "Cognitive flexibility – Inhibition")`), with less consistent evidence that it exceeded the meaningfulness threshold (T1: `r edge_meaningful("Australia", "T1", "Cognitive flexibility – Inhibition")`; T2: `r edge_meaningful("Australia", "T2", "Cognitive flexibility – Inhibition")`; T3: `r edge_meaningful("Australia", "T3", "Cognitive flexibility – Inhibition")`).

In South Africa, the inhibition–working memory edge remained positive across waves (T1: `r edge_report("South Africa", "T1", "Inhibition – Working memory")`; T2: `r edge_report("South Africa", "T2", "Inhibition – Working memory")`) and met the meaningfulness criterion more consistently than the other edges (T1: `r edge_meaningful("South Africa", "T1", "Inhibition – Working memory")`; T2: `r edge_meaningful("South Africa", "T2", "Inhibition – Working memory")`). The cognitive flexibility–inhibition edge was stronger at T1 (`r edge_report("South Africa", "T1", "Cognitive flexibility – Inhibition")`) but attenuated at T2 (`r edge_report("South Africa", "T2", "Cognitive flexibility – Inhibition")`) and did not reliably exceed the meaningfulness threshold at T2 (T1: `r edge_meaningful("South Africa", "T1", "Cognitive flexibility – Inhibition")`; T2: `r edge_meaningful("South Africa", "T2", "Cognitive flexibility – Inhibition")`). In contrast to the Australian results, he cognitive flexibility–working memory edge was comparatively weaker and uncertain across waves (T1: `r edge_report("South Africa", "T1", "Cognitive flexibility – Working memory")`; T2: `r edge_report("South Africa", "T2", "Cognitive flexibility – Working memory")`).

\clearpage

```{r}
#| label: tbl-rq1-gt-all 
#| tbl-cap: "Age-adjusted EF network summaries by cohort×wave. Panels show edges, global strength, and expected influence (posterior median [95% CrI]). For edges, cells also show $P(|r| > r\\text{ rope})$." 
#| include: true 

# labels for EI rows
node_to_label <- setNames(names(node_label_map), node_label_map)

# Build combined RQ1 table (edges, global strength and expected influence)
rq1_table_all <- dplyr::bind_rows(
  # Edges panel
  rq1_edges %>%
    dplyr::transmute(
      panel = "Edges",
      country, timepoint, n, pct_missing,
      term = edge,
      estimate,
      rope_p
    ),

  # Global strength panel
  rq1_gs %>%
    dplyr::transmute(
      panel = "Global strength",
      country, timepoint, n, pct_missing,
      term = edge,     
      estimate,
      rope_p = ""       
    ),

  # Expected influence panel
  rq1_table_B %>%
    dplyr::transmute(
      panel = "Expected influence",
      country, timepoint, n, pct_missing,
      term = unname(node_to_label[node]), 
      estimate,
      rope_p = ""                            
    )
) %>%
  dplyr::mutate(
    panel = factor(panel, levels = c("Edges", "Global strength", "Expected influence")),
    pct_missing = round(pct_missing, 1),
    n = as.integer(n)
  ) %>%
  dplyr::arrange(panel, country, timepoint, term)

# GT table
gt_rq1_all <- rq1_table_all %>%
  gt::gt(
    rowname_col = "term",
    groupname_col = "panel"
  ) %>%
  # add vertical space between caption and header in PDF
  gt::tab_header(title = gt::md("\\vspace{10pt}")) %>%
  gt::tab_stubhead(label = "Measure") %>%
  gt::cols_label(
    country = "Cohort",
    timepoint = "Wave",
    estimate = "Median [95% CrI]",
    rope_p = paste0("P(|r|>", rope, ")"),
    n = "N",
    pct_missing = "% missing cells"
  ) %>%
  gt::cols_align(
    align = "center",
    columns = c(country, timepoint, estimate, rope_p, n, pct_missing)
  ) %>%
  gt::sub_missing(columns = "rope_p", missing_text = "") %>%
  gt::tab_options(
    table.font.size        = gt::px(11),
    row_group.font.weight  = "bold",
    heading.title.font.size = gt::px(1)  # minimise spacer row height
  )

gt_rq1_all

```

```{r}
#| label: fig-rq1-edge-forest
#| fig-cap: |
#|   **Within-wave EF coupling (posterior partial correlations).** Points show posterior medians; bars show 95% credible intervals. Solid line = 0; dashed lines = ROPE (±0.10).
#| include: true

rope <- 0.10

edges_df2 <- edge_tbl %>%
  dplyr::mutate(
    timepoint = factor(timepoint, levels = c("T1","T2","T3")),
    country = factor(country, levels = c("AU","SA")),

    # canonical edge key from node columns
    edge_key = paste(pmin(node1, node2), pmax(node1, node2), sep = " — ")
  ) %>%
  # keep only the 3 EF edges
  dplyr::filter(edge_key %in% c(
    "ef_cogflex — ef_inhibition",
    "ef_cogflex — ef_workingmem",
    "ef_inhibition — ef_workingmem"
  )) %>%
  dplyr::mutate(
    edge_short = dplyr::recode(
      edge_key,
      "ef_cogflex — ef_inhibition"    = "CogFlex–Inhib",
      "ef_cogflex — ef_workingmem"    = "CogFlex–WM",
      "ef_inhibition — ef_workingmem" = "Inhib–WM"
    ),
    edge_short = factor(edge_short, levels = c("Inhib–WM","CogFlex–WM","CogFlex–Inhib"))
  )

stopifnot(nrow(edges_df2) > 0)
stopifnot(all(c("q025","q50","q975") %in% names(edges_df2)))
stopifnot(!anyNA(edges_df2$edge_short))

ggplot(edges_df2, aes(x = q50, y = edge_short, colour = edge_short)) +
  geom_rect(
    data = tibble::tibble(xmin = -rope, xmax = rope, ymin = -Inf, ymax = Inf),
    aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
    inherit.aes = FALSE,
    fill = "grey50",
    alpha = 0.08
  ) +
  geom_vline(xintercept = 0, linewidth = 0.6) +
  geom_vline(xintercept = c(-rope, rope), linetype = "dashed", linewidth = 0.5) +
  geom_errorbarh(aes(xmin = q025, xmax = q975), height = 0, linewidth = 0.7) +
  geom_point(size = 2.4) +
  facet_grid(timepoint ~ country, switch = "y") +
  guides(colour = "none") +
  labs(
    #title = "Within-wave EF coupling",  # <- plot title (optional)
    x = "Partial correlation (posterior median, 95% CrI)",
    y = NULL
  ) +
  theme_bw(base_size = 12) +
  theme(
    panel.grid.major.y = element_blank(),
    panel.grid.minor   = element_blank(),
    strip.placement    = "outside",
    strip.background   = element_blank(),
    strip.text.y.right = element_text(angle = 0)
  )
```
\clearpage

### Global strength

Global strength estimates (sum of absolute partial correlations over unique edges) are reported in @tbl-rq1-gt-all and visualized over time in @fig-rq1-global-strength-trend. Australia showed stable global strength across waves (T1: `r global_strength_report("Australia", "T1")`; T2: `r global_strength_report("Australia", "T2")`; T3: `r global_strength_report("Australia", "T3")`), whereas South Africa showed lower global strength and attenuation from T1 to T2 (T1: `r global_strength_report("South Africa", "T1")`;
T2: `r global_strength_report("South Africa", "T2")`).

```{r}
#| label: fig-rq1-global-strength-trend
#| fig-cap: "Global strength over time by cohort. Points show posterior median; whiskers show 95% credible intervals. Global strength is the sum of absolute partial correlations over unique edges."
#| fig-width: 6.2
#| fig-height: 4

library(dplyr)
library(ggplot2)

gs_df <- gs_tbl %>%
  mutate(
    country   = factor(country, levels = c("AU", "SA")),
    timepoint = factor(timepoint, levels = c("T1","T2","T3"))
  )

ggplot(gs_df, aes(x = timepoint, y = q50, group = country)) +
  geom_line(linewidth = 0.7) +
  geom_errorbar(aes(ymin = q025, ymax = q975), width = 0.08, linewidth = 0.7) +
  geom_point(size = 2.0) +
  facet_grid(. ~ country) +
  labs(
    x = "Wave",
    y = "Global strength (posterior median, 95% CrI)"
  ) +
  theme_bw(base_size = 11) +
  theme(
    panel.grid.minor = element_blank(),
    strip.background = element_blank()
  )
```
\clearpage

### Centrality (Expected influence)
Expected influence estimates (signed sum of incident partial correlations) are summarized in @tbl-rq1-gt-all and visualized over time by node in @fig-rq1-ei-trend-by-node-n. In Australia, expected influence was consistently positive across nodes and waves, with working memory showing the highest expected influence across waves (T1: `r ei_report("Australia", "T1", "Working memory")`; T2: `r ei_report("Australia", "T2", "Working memory")`; T3: `r ei_report("Australia", "T3", "Working memory")`). Inhibition showed comparatively high expected influence from T2 onward (T1: `r ei_report("Australia", "T1", "Inhibition")`; T2: `r ei_report("Australia", "T2", "Inhibition")`; T3: `r ei_report("Australia", "T3", "Inhibition")`), whereas cognitive flexibility was lower and more stable across waves (T1: `r ei_report("Australia", "T1", "Cognitive flexibility")`; T2: `r ei_report("Australia", "T2", "Cognitive flexibility")`; T3: `r ei_report("Australia", "T3", "Cognitive flexibility")`). These patterns are evident in @fig-rq1-ei-trend-by-node-n, which shows sustained positive centrality for all three nodes in the Australian cohort, with working memory and inhibition contributing most strongly to within-wave coupling across time.

In South Africa, expected influence was positive but generally lower, with attenuation from T1 to T2 for inhibition and cognitive flexibility (inhibition: T1: `r ei_report("South Africa", "T1", "Inhibition")`; T2: `r ei_report("South Africa", "T2", "Inhibition")`; cognitive flexibility: T1: `r ei_report("South Africa", "T1", "Cognitive flexibility")`; T2: `r ei_report("South Africa", "T2", "Cognitive flexibility")`). Working memory showed comparatively stable expected influence across waves (T1: `r ei_report("South Africa", "T1", "Working memory")`; T2: `r ei_report("South Africa", "T2", "Working memory")`). @fig-rq1-ei-trend-by-node-n shows a downward shift from T1 to T2 for inhibition and cognitive flexibility in South Africa, while working memory remains comparatively steady.
\clearpage

```{r}
#| label: fig-rq1-ei-trend-by-node-n
#| fig-cap: "Expected influence over time by cohort and node. Points show posterior median; whiskers show 95% credible intervals. N per wave is shown beneath the zero line within each panel."
#| fig-width: 7.8
#| fig-height: 6

library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)

stopifnot(exists("fit_tbl"), exists("nodes"), exists("ei_summaries"))

fit_tbl_uniq <- fit_tbl %>%
  filter(!purrr::map_lgl(fit, is.null)) %>%
  arrange(country, timepoint) %>%
  group_by(country, timepoint) %>%
  slice(1) %>%
  ungroup()

rq1_ei <- fit_tbl_uniq %>%
  transmute(country, timepoint, n, fit) %>%
  mutate(ei = purrr::map(fit, ~ ei_summaries(.x, node_names = nodes))) %>%
  unnest(ei) %>%
  mutate(
    country   = factor(country, levels = c("AU","SA")),
    timepoint = factor(timepoint, levels = c("T1","T2","T3")),
    node      = factor(node, levels = nodes)
  )

node_labels <- c(
  ef_inhibition = "Inhibition",
  ef_cogflex = "Cognitive flexibility",
  ef_workingmem = "Working memory"
)

# N labels replicated into each node panel
n_lab <- fit_tbl_uniq %>%
  transmute(
    country = factor(country, levels = c("AU","SA")),
    timepoint = factor(timepoint, levels = c("T1","T2","T3")),
    n
  ) %>%
  tidyr::crossing(node = factor(nodes, levels = nodes)) %>%
  mutate(label = paste0("n=", n))

# Choose a stable y-position *below* 0 for each (country × node) panel:
# - if 0 is within the panel range, put N slightly below 0
# - otherwise put it slightly above the panel minimum
panel_y <- rq1_ei %>%
  group_by(country, node) %>%
  summarise(
    y_min = min(q025, na.rm = TRUE),
    y_max = max(q975, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    span = y_max - y_min,
    y_n  = if_else(
      (y_min <= 0) & (0 <= y_max),
      0 - 0.08 * span,
      y_min + 0.06 * span
    )
  )

n_lab2 <- n_lab %>%
  left_join(panel_y, by = c("country","node"))

ggplot(rq1_ei, aes(x = timepoint, y = q50, group = 1)) +
  geom_hline(yintercept = 0, linewidth = 0.7) +
  geom_line(linewidth = 0.9) +
  geom_errorbar(aes(ymin = q025, ymax = q975), width = 0.10, linewidth = 0.9) +
  geom_point(size = 2.7) +

  # N labels: boxed, below the 0-line, not competing with points
  geom_label(
    data = n_lab2,
    aes(x = timepoint, y = y_n, label = label),
    inherit.aes = FALSE,
    size = 3.1,
    label.size = 0,        
    label.padding = unit(0.12, "lines"),
    fill = "white",
    colour = "black",
    alpha = 0.9
  ) +

  facet_grid(
    node ~ country,
    labeller = labeller(node = node_labels),
    switch = "y"
  ) +
  labs(
    x = "Wave",
    y = "Expected influence (posterior median, 95% CrI)"
  ) +
  theme_bw(base_size = 12) +
  theme(
    panel.grid.minor = element_blank(),
    strip.placement  = "outside",

    # put node strips on the LEFT
    strip.text.y.left  = element_text(angle = 90),
    strip.text.y.right = element_blank(),
    strip.background.y = element_blank()
  ) +
  coord_cartesian(clip = "off") +
  scale_y_continuous(expand = expansion(mult = c(0.12, 0.05)))
```
\clearpage

```{r}
#################### RQ2 - cross cultural comparisons #################### 
#| label: rq2-difference-helpers
#| include: false

rope_delta <- 0.10

summ_draws_delta <- function(draws, rope = rope_delta) {
  qs <- stats::quantile(draws, c(.025, .5, .975), na.rm = TRUE)
  tibble::tibble(
    q025 = unname(qs[1]),
    q50  = unname(qs[2]),
    q975 = unname(qs[3]),
    p_outside_rope = mean(abs(draws) > rope, na.rm = TRUE)
  )
}

# Get fit object for a specific country×timepoint
get_fit <- function(country, tp, fit_tbl_uniq) {
  out <- fit_tbl_uniq %>%
    dplyr::filter(country == !!country, timepoint == !!tp) %>%
    dplyr::pull(fit)
  if (length(out) != 1) stop("Could not uniquely match fit: ", country, " ", tp)
  out[[1]]
}

# Posterior draws of Δ edges (fit_B - fit_A), returned as a named list
edge_delta_draws <- function(fit_A, fit_B, node_names = nodes) {
  A <- fit_A$post_samp$pcors
  B <- fit_B$post_samp$pcors

  # enforce names
  dimnames(A) <- list(node_names, node_names, NULL)
  dimnames(B) <- list(node_names, node_names, NULL)

  # align draws
  S <- min(dim(A)[3], dim(B)[3])
  A <- A[, , (dim(A)[3] - S + 1):dim(A)[3], drop = FALSE]
  B <- B[, , (dim(B)[3] - S + 1):dim(B)[3], drop = FALSE]

  D <- B - A  # Δ = later - earlier

  p <- dim(D)[1]
  idx <- which(upper.tri(matrix(FALSE, p, p)), arr.ind = TRUE)

  out <- vector("list", nrow(idx))
  nms <- character(nrow(idx))

  for (i in seq_len(nrow(idx))) {
    a <- idx[i, 1]; b <- idx[i, 2]
    out[[i]] <- D[a, b, ]
    nms[i] <- paste(sort(c(node_names[a], node_names[b])), collapse = " - ")
  }
  names(out) <- nms
  out
}

# Posterior draws of Δ global strength (fit_B - fit_A)
gs_delta_draws <- function(fit_A, fit_B) {
  gsA <- global_strength_draws(fit_A)
  gsB <- global_strength_draws(fit_B)
  S <- min(length(gsA), length(gsB))
  tail(gsB, S) - tail(gsA, S)
}

# Posterior draws of Δ expected influence per node (fit_B - fit_A), S x p
ei_delta_draws <- function(fit_A, fit_B, node_names = nodes) {
  EI_A <- expected_influence_draws(fit_A, node_names = node_names) # S x p
  EI_B <- expected_influence_draws(fit_B, node_names = node_names)

  S <- min(nrow(EI_A), nrow(EI_B))
  EI_B[(nrow(EI_B) - S + 1):nrow(EI_B), , drop = FALSE] -
    EI_A[(nrow(EI_A) - S + 1):nrow(EI_A), , drop = FALSE]
}

fmt_ci_delta <- function(m, lo, hi, digits = 2) {
  sprintf(paste0("%.", digits, "f [%.", digits, "f, %.", digits, "f]"), m, lo, hi)
}
fmt_p <- function(p, digits = 2) sprintf(paste0("%.", digits, "f"), p)

```

```{r}


#| label: rq2-ei-delta-summaries
#| include: false

ei_delta_summaries <- function(fit_A, fit_B,
                               node_names = nodes,
                               probs = c(.025, .5, .975),
                               rope = NULL) {

  EI <- ei_delta_draws(fit_A, fit_B, node_names = node_names)  # S x p

  # enforce colnames
  if (is.null(colnames(EI))) colnames(EI) <- node_names

  out <- tibble::tibble(
    node = colnames(EI),
    q025 = apply(EI, 2, stats::quantile, probs[1], na.rm = TRUE),
    q50  = apply(EI, 2, stats::quantile, probs[2], na.rm = TRUE),
    q975 = apply(EI, 2, stats::quantile, probs[3], na.rm = TRUE)
  )

  if (!is.null(rope)) {
    out <- dplyr::mutate(
      out,
      p_outside_rope = apply(abs(EI) > rope, 2, mean, na.rm = TRUE)
    )
  }

  out
}
```

```{r}
#| label: rq2-build-delta-tables
#| include: false

# Use the samefit table as for RQ1
fit_tbl_uniq <- fit_tbl %>%
  dplyr::filter(!purrr::map_lgl(fit, is.null)) %>%
  dplyr::arrange(country, timepoint) %>%
  dplyr::group_by(country, timepoint) %>%
  dplyr::slice(1) %>%
  dplyr::ungroup()

# Define adjacent-wave comparisons per cohort
rq2_pairs <- tibble::tibble(
  country = c("AU","AU","SA"),
  tp1     = c("T1","T2","T1"),
  tp2     = c("T2","T3","T2")
)

# Edge deltas (Δr)
rq2_delta_edges <- rq2_pairs %>%
  dplyr::mutate(
    fit1 = purrr::pmap(list(country, tp1), ~ get_fit(..1, ..2, fit_tbl_uniq)),
    fit2 = purrr::pmap(list(country, tp2), ~ get_fit(..1, ..2, fit_tbl_uniq)),
    delta_list = purrr::map2(fit1, fit2, ~ edge_delta_draws(.x, .y, node_names = nodes))
  ) %>%
  dplyr::select(country, tp1, tp2, delta_list) %>%
  tidyr::unnest_longer(delta_list, values_to = "draws", indices_to = "edge") %>%
  dplyr::mutate(stats = purrr::map(draws, ~ summ_draws_delta(.x, rope = rope_delta))) %>%
  tidyr::unnest(stats) %>%
  dplyr::transmute(
    panel    = "Edges (Δr)",
    country,
    contrast = paste0(tp2, " \u2212 ", tp1),
    term     = edge,
    estimate = fmt_ci_delta(q50, q025, q975, digits = 2),
    rope_p   = fmt_p(p_outside_rope, digits = 2)
  )

# Global strength deltas (ΔGS)
rq2_delta_gs <- rq2_pairs %>%
  dplyr::mutate(
    fit1 = purrr::pmap(list(country, tp1), ~ get_fit(..1, ..2, fit_tbl_uniq)),
    fit2 = purrr::pmap(list(country, tp2), ~ get_fit(..1, ..2, fit_tbl_uniq)),
    draws = purrr::map2(fit1, fit2, ~ gs_delta_draws(.x, .y))
  ) %>%
  dplyr::mutate(stats = purrr::map(draws, ~ summ_draws_delta(.x, rope = rope_delta))) %>%
  tidyr::unnest(stats) %>%
  dplyr::transmute(
    panel    = "Global strength (Δ)",
    country,
    contrast = paste0(tp2, " \u2212 ", tp1),
    term     = "Global strength",
    estimate = fmt_ci_delta(q50, q025, q975, digits = 2),
    rope_p   = ""  # leave blank (ROPE less interpretable for GS unless you justify it)
  )

# Expected influence deltas (ΔEI)
rq2_delta_ei <- rq2_pairs %>%
  dplyr::mutate(
    fit1 = purrr::pmap(list(country, tp1), ~ get_fit(..1, ..2, fit_tbl_uniq)),
    fit2 = purrr::pmap(list(country, tp2), ~ get_fit(..1, ..2, fit_tbl_uniq)),
    ei   = purrr::map2(fit1, fit2, ~ ei_delta_summaries(.x, .y, node_names = nodes, rope = rope_delta))
  ) %>%
  tidyr::unnest(ei) %>%
  dplyr::transmute(
    panel    = "Expected influence (Δ)",
    country,
    contrast = paste0(tp2, " \u2212 ", tp1),
    term     = node,
    estimate = fmt_ci_delta(q50, q025, q975, digits = 2),
    rope_p   = fmt_p(p_outside_rope, digits = 2)   # <- keep if you want ROPE on ΔEI
  )

rq2_table_all <- dplyr::bind_rows(rq2_delta_gs, rq2_delta_edges, rq2_delta_ei) %>%
  dplyr::mutate(
    panel   = factor(panel, levels = c("Edges (Δr)", "Global strength (Δ)", "Expected influence (Δ)")),
    country = factor(country, levels = c("AU","SA"))
  ) %>%
  dplyr::arrange(panel, country, contrast, term)

rq2_table_all

```
### Research Question 2 (Primary): Developmental Change Within Cohorts 
Within each cohort, do the EF conditional associations (partial correlations) change across adjacent waves (AU: T1→T2→T3; SA: T1→T2), and if so, which specific edges strengthen or weaken over time?

Given metric invariance, we compared network structures across adjacent waves within each cohort. For each wave transition, we computed posterior distributions of change in edge weights (Δr = later wave − earlier 
wave), global strength (Δ), and expected influence (Δ). We evaluated whether changes exceeded a region of practical equivalence (ROPE; |Δr| > 0.10) to distinguish meaningful developmental change from negligible fluctuation.

We found little evidence for meaningful change in EF network summaries across adjacent waves within either cohort (see @tbl-rq2-gt-all). Posterior 95% CrIs for all Δs included 0, and probabilities that edge changes exceeded the ROPE (|Δr| > 0.10) were modest (≈0.3–0.6), indicating substantial uncertainty and 
no clear support for meaningful change.
```{r}
#| label: tbl-rq2-gt-all
#| tbl-cap: "Change in EF network summaries across adjacent waves within cohort. Cells show posterior median [95% CrI] for Δ (later − earlier). For edges, cells also show $P(|\\Delta r| > 0.10)$."
#| include: true

rq2_table_print <- rq2_table_all %>%
  dplyr::mutate(
    term = dplyr::recode(term, !!!node_to_label)
  )

gt_rq2_all <- rq2_table_print %>%
  gt::gt(
    rowname_col   = "term",
    groupname_col = "panel"
  ) %>%
  gt::tab_header(title = gt::md("\\vspace{10pt}")) %>%
  gt::tab_stubhead(label = "Measure") %>%
  gt::cols_label(
    country   = "Cohort",
    contrast  = "Contrast",
    estimate  = "Median [95% CrI]",
    rope_p    = paste0("P(|Δr|>", rope_delta, ")")
  ) %>%
  gt::cols_align(
    align = "center",
    columns = c(country, contrast, estimate, rope_p)
  ) %>%
  gt::sub_missing(columns = "rope_p", missing_text = "") %>%
  gt::tab_options(
    table.font.size = gt::px(11),
    row_group.font.weight = "bold",
    # ADDED: Minimizes the height of the spacer row so it doesn't look like a massive gap
    heading.title.font.size = gt::px(1)
  )

gt_rq2_all
```

```{r}
#| label: rq2-inline-report-helpers
#| include: false

rq2_contrast <- function(tp2, tp1) paste0(tp2, " \u2212 ", tp1)

# generic lookup in rq2_table_all
rq2_cell <- function(panel, country, tp2, tp1, term, col = c("estimate","rope_p")) {
  col <- match.arg(col)
  x <- rq2_table_all %>%
    dplyr::filter(
      panel == !!panel,
      country == !!country,
      contrast == rq2_contrast(tp2, tp1),
      term == !!term
    ) %>%
    dplyr::pull(!!rlang::sym(col))
  if (length(x) != 1) stop("No unique match for: ", panel, " / ", country, " / ", rq2_contrast(tp2, tp1), " / ", term)
  x[[1]]
}

# wrappers
rq2_edge_report      <- function(country, tp2, tp1, edge) rq2_cell("Edges (Δr)", country, tp2, tp1, edge, "estimate")
rq2_edge_meaningful  <- function(country, tp2, tp1, edge) rq2_cell("Edges (Δr)", country, tp2, tp1, edge, "rope_p")

rq2_gs_report        <- function(country, tp2, tp1)       rq2_cell("Global strength (Δ)", country, tp2, tp1, "Global strength", "estimate")

rq2_ei_report        <- function(country, tp2, tp1, node) rq2_cell("Expected influence (Δ)", country, tp2, tp1, node, "estimate")
rq2_ei_meaningful    <- function(country, tp2, tp1, node) rq2_cell("Expected influence (Δ)", country, tp2, tp1, node, "rope_p")

```
\clearpage

```{r}
#| label: rq3-fisher-helpers
#| include: false

rope_rq3 <- 0.10

clamp_r <- function(r, eps = 1e-6) pmin(pmax(r, -1 + eps), 1 - eps)
fisher_z <- function(r) atanh(clamp_r(r))

# Summaries for a vector of draws (generic)
summ_vec <- function(draws, probs = c(.025,.5,.975)) {
  qs <- stats::quantile(draws, probs, na.rm = TRUE)
  tibble::tibble(q025 = unname(qs[1]), q50 = unname(qs[2]), q975 = unname(qs[3]))
}

# Summaries for delta-r (incl ROPE) + delta-z (no ROPE)
summ_delta_rz <- function(dr, dz, rope = 0.10) {
  sr <- summ_vec(dr)
  sz <- summ_vec(dz)
  tibble::tibble(
    r_q025 = sr$q025, r_q50 = sr$q50, r_q975 = sr$q975,
    z_q025 = sz$q025, z_q50 = sz$q50, z_q975 = sz$q975,
    p_outside_rope_r = mean(abs(dr) > rope, na.rm = TRUE)
  )
}

fmt_ci <- function(m, lo, hi, digits = 2) {
  sprintf(paste0("%.", digits, "f [%.", digits, "f, %.", digits, "f]"), m, lo, hi)
}
fmt_p <- function(p, digits = 2) sprintf(paste0("%.", digits, "f"), p)

# Given two vectors of r draws, return aligned Δr and Δz
aligned_delta_rz <- function(rA, rB, keep = c("last","first")) {
  keep <- match.arg(keep)
  al <- align_draws(rA, rB, keep = keep)
  dr <- al$x - al$y
  dz <- fisher_z(al$x) - fisher_z(al$y)
  list(dr = dr, dz = dz)
}

# AU - SA at a given wave, for all edges: returns named list of lists {dr, dz}
edge_cohort_diff_draws_rz <- function(fit_AU, fit_SA, node_names = nodes, keep = "last") {
  # get r draws per edge for each cohort×wave
  AU_list <- edge_draws_list(fit_AU, node_names = node_names)
  SA_list <- edge_draws_list(fit_SA, node_names = node_names)

  stopifnot(identical(sort(names(AU_list)), sort(names(SA_list))))
  nms <- names(AU_list)

  out <- purrr::map(nms, \(k) aligned_delta_rz(AU_list[[k]], SA_list[[k]], keep = keep))
  names(out) <- nms
  out
}

# DiD = (T2-T1)_AU - (T2-T1)_SA on r and z scales
edge_did_draws_rz <- function(fit_AU_T1, fit_AU_T2, fit_SA_T1, fit_SA_T2,
                              node_names = nodes, keep = "last") {

  AU_T1 <- edge_draws_list(fit_AU_T1, node_names = node_names)
  AU_T2 <- edge_draws_list(fit_AU_T2, node_names = node_names)
  SA_T1 <- edge_draws_list(fit_SA_T1, node_names = node_names)
  SA_T2 <- edge_draws_list(fit_SA_T2, node_names = node_names)

  stopifnot(identical(sort(names(AU_T1)), sort(names(AU_T2))))
  stopifnot(identical(sort(names(SA_T1)), sort(names(SA_T2))))
  stopifnot(identical(sort(names(AU_T1)), sort(names(SA_T1))))

  nms <- names(AU_T1)

  out <- purrr::map(nms, function(k) {

    # align within-cohort deltas first (so T2 and T1 have same draw count)
    al_AU <- align_draws(AU_T2[[k]], AU_T1[[k]], keep = keep)
    al_SA <- align_draws(SA_T2[[k]], SA_T1[[k]], keep = keep)

    dAU_r <- al_AU$x - al_AU$y
    dSA_r <- al_SA$x - al_SA$y

    dAU_z <- fisher_z(al_AU$x) - fisher_z(al_AU$y)
    dSA_z <- fisher_z(al_SA$x) - fisher_z(al_SA$y)

    # align AU and SA delta vectors to same length
    al_dr <- align_draws(dAU_r, dSA_r, keep = keep)
    al_dz <- align_draws(dAU_z, dSA_z, keep = keep)

    list(
      dr = al_dr$x - al_dr$y,
      dz = al_dz$x - al_dz$y
    )
  })

  names(out) <- nms
  out
}

```

```{r}
#| label: rq3-sensitivity-networks-no-floor
#| include: false

# Cog flex floor exclusion
# Exclude from each wave only if scored 0 on COGFLEX (the problematic measure)
# This directly tests whether the cogflex floor effect contaminates networks

cat("=== SENSITIVITY ANALYSIS: EXCLUDING COGFLEX FLOOR PERFORMERS ===\n\n")

# Identify cogflex floor performers at each wave
floor_ids_by_wave <- ef_all_keep %>%
  filter(variable == "ef_cogflex", value == 0) %>%  # <- ONLY cogflex
  distinct(country, timepoint, id) %>%
  mutate(floor_at_wave = TRUE)

# Report who has cogflex floor effects by wave
cat("Cogflex floor performers by wave:\n")
floor_summary <- floor_ids_by_wave %>%
  count(country, timepoint, name = "n_floor")
print(floor_summary)

# Apply wave-specific cogflex exclusion
ef_net_wide_no_floor <- ef_net_wide %>%
  left_join(floor_ids_by_wave, by = c("country", "timepoint", "id")) %>%
  filter(is.na(floor_at_wave)) %>%
  select(-floor_at_wave)

# Report sample sizes
cat("\n=== SAMPLE SIZES ===\n\n")
cat("Original sample sizes:\n")
original_n <- ef_net_wide %>% count(country, timepoint)
print(original_n)

cat("\nAfter cogflex-specific floor exclusion:\n")
sensitivity_n <- ef_net_wide_no_floor %>% count(country, timepoint)
print(sensitivity_n)

cat("\nExcluded by cohort×wave:\n")
excluded_summary <- original_n %>%
  left_join(sensitivity_n, by = c("country", "timepoint"), suffix = c("_orig", "_sens")) %>%
  mutate(
    n_excluded = n_orig - n_sens,
    pct_excluded = round(100 * n_excluded / n_orig, 1)
  )
print(excluded_summary)

# Verify we have enough data to proceed
if (nrow(ef_net_wide_no_floor) == 0) {
  stop("No data remaining after floor exclusion!")
}

# Split by cohort×wave for network fitting
dat_split_no_floor <- ef_net_wide_no_floor %>%
  select(country, timepoint, id, all_of(nodes)) %>%
  group_by(country, timepoint) %>%
  group_split()

keys_no_floor <- ef_net_wide_no_floor %>%
  select(country, timepoint, id, all_of(nodes)) %>%
  group_by(country, timepoint) %>%
  group_keys() %>%
  arrange(country, timepoint)

stopifnot(nrow(keys_no_floor) == length(dat_split_no_floor))

# Refit networks using same BGGM settings as main analysis
cat("\n=== REFITTING NETWORKS ===\n")
cat("Using settings: iter =", bggm_iter, ", burnin =", bggm_burnin, ", chains =", bggm_chains, "\n\n")

fit_one_no_floor <- function(df) {
  Y <- df %>%
    select(all_of(nodes)) %>%
    mutate(across(everything(), as.numeric)) %>%
    as.matrix()
  
  n <- nrow(Y)
  p <- ncol(Y)
  miss_cells <- sum(is.na(Y))
  total_cells <- length(Y)
  pct_missing <- 100 * miss_cells / total_cells
  
  # Require at least 10 observations
  if (n < 10) {
    cat("Skipping fit (n < 10):", unique(df$country), unique(df$timepoint), "\n")
    return(list(
      fit = NULL,
      n = n,
      missing_cells = miss_cells,
      total_cells = total_cells,
      pct_missing = pct_missing
    ))
  }
  
  cat("Fitting:", unique(df$country), unique(df$timepoint), "- n =", n, "\n")
  
  fit <- BGGM::estimate(
    Y,
    type   = "continuous",
    iter   = bggm_iter,
    burnin = bggm_burnin,
    chains = bggm_chains,
    impute = TRUE,
    save   = TRUE
  )
  
  list(
    fit = fit,
    n = n,
    missing_cells = miss_cells,
    total_cells = total_cells,
    pct_missing = pct_missing
  )
}

# Fit all networks
ggm_fits_no_floor <- purrr::map(dat_split_no_floor, fit_one_no_floor)

# Create fit table
fit_tbl_no_floor <- keys_no_floor %>%
  mutate(res = ggm_fits_no_floor) %>%
  tidyr::unnest_wider(res)

# Check fits
cat("\n=== SENSITIVITY ANALYSIS NETWORKS FITTED ===\n")
fit_summary <- fit_tbl_no_floor %>%
  mutate(ok = !purrr::map_lgl(fit, is.null)) %>%
  select(country, timepoint, n, missing_cells, total_cells, pct_missing, ok)
print(fit_summary)

# Verify all fits succeeded
n_failed <- sum(!fit_summary$ok)
if (n_failed > 0) {
  warning("Some fits failed (n < 10). Results may be incomplete.")
}

cat("\nSensitivity analysis complete. Object 'fit_tbl_no_floor' created.\n")
```

```{r}
#| label: rq3-build-fisher-tables
#| include: false

# Unique fits table (ORIGINAL - includes floor performers)
fit_tbl_uniq <- fit_tbl %>%
  filter(!purrr::map_lgl(fit, is.null)) %>%
  arrange(country, timepoint) %>%
  group_by(country, timepoint) %>%
  slice(1) %>%
  ungroup()

# Unique fits table (SENSITIVITY - excludes floor performers)
fit_tbl_uniq_no_floor <- fit_tbl_no_floor %>%
  filter(!purrr::map_lgl(fit, is.null)) %>%
  arrange(country, timepoint) %>%
  group_by(country, timepoint) %>%
  slice(1) %>%
  ungroup()

# === ORIGINAL ANALYSIS (with floor) ===

# Pull required fits
fit_AU_T1 <- get_fit("AU", "T1", fit_tbl_uniq)
fit_AU_T2 <- get_fit("AU", "T2", fit_tbl_uniq)
fit_SA_T1 <- get_fit("SA", "T1", fit_tbl_uniq)
fit_SA_T2 <- get_fit("SA", "T2", fit_tbl_uniq)

# Cohort differences at matched waves (AU - SA)
rq3_wave_edges_rz <- tibble(wave = c("T1","T2")) %>%
  mutate(
    fit_AU   = purrr::map(wave, ~ get_fit("AU", .x, fit_tbl_uniq)),
    fit_SA   = purrr::map(wave, ~ get_fit("SA", .x, fit_tbl_uniq)),
    diff_rz  = purrr::map2(fit_AU, fit_SA, ~ edge_cohort_diff_draws_rz(.x, .y, node_names = nodes))
  ) %>%
  select(wave, diff_rz) %>%
  tidyr::unnest_longer(diff_rz, values_to = "rz", indices_to = "edge_raw") %>%
  mutate(
    term = vapply(
      strsplit(edge_raw, " — ", fixed = TRUE),
      function(z) paste(sort(z), collapse = " - "),
      character(1)
    ),
    stats = purrr::map(rz, ~ summ_delta_rz(.x$dr, .x$dz, rope = rope_rq3))
  ) %>%
  tidyr::unnest(stats) %>%
  transmute(
    panel = paste0("Cohort difference (AU − SA) at ", wave),
    term,
    estimate_r = fmt_ci(r_q50, r_q025, r_q975, digits = 2),
    estimate_z = fmt_ci(z_q50, z_q025, z_q975, digits = 2),
    rope_p_r   = fmt_p(p_outside_rope_r, digits = 2),
    analysis   = "Main analysis"
  )

# DiD
rq3_did_edges_rz <- tibble(panel = "Difference-in-differences (ΔAU − ΔSA)") %>%
  mutate(
    did_rz = list(edge_did_draws_rz(fit_AU_T1, fit_AU_T2, fit_SA_T1, fit_SA_T2, node_names = nodes))
  ) %>%
  tidyr::unnest_longer(did_rz, values_to = "rz", indices_to = "edge_raw") %>%
  mutate(
    # STANDARDISE term format to match the wave tables
    term = vapply(
      strsplit(edge_raw, " — ", fixed = TRUE),
      function(z) paste(sort(z), collapse = " - "),
      character(1)
    ),
    stats = purrr::map(rz, ~ summ_delta_rz(.x$dr, .x$dz, rope = rope_rq3))
  ) %>%
  tidyr::unnest(stats) %>%
  transmute(
    panel,
    term,
    estimate_r = fmt_ci(r_q50, r_q025, r_q975, digits = 2),
    estimate_z = fmt_ci(z_q50, z_q025, z_q975, digits = 2),
    rope_p_r   = fmt_p(p_outside_rope_r, digits = 2),
    analysis   = "Main analysis"
  )

rq3_edges_dual <- bind_rows(rq3_wave_edges_rz, rq3_did_edges_rz) %>%
  mutate(
    panel = factor(panel, levels = c(
      "Cohort difference (AU − SA) at T1",
      "Cohort difference (AU − SA) at T2",
      "Difference-in-differences (ΔAU − ΔSA)"
    ))
  ) %>%
  arrange(panel, term)

# === SENSITIVITY ANALYSIS (no floor) ===

# Pull required fits
fit_AU_T1_nf <- get_fit("AU", "T1", fit_tbl_uniq_no_floor)
fit_AU_T2_nf <- get_fit("AU", "T2", fit_tbl_uniq_no_floor)
fit_SA_T1_nf <- get_fit("SA", "T1", fit_tbl_uniq_no_floor)
fit_SA_T2_nf <- get_fit("SA", "T2", fit_tbl_uniq_no_floor)

# Cohort differences (sensitivity)
rq3_wave_edges_rz_sens <- tibble(wave = c("T1","T2")) %>%
  mutate(
    fit_AU   = purrr::map(wave, ~ get_fit("AU", .x, fit_tbl_uniq_no_floor)),
    fit_SA   = purrr::map(wave, ~ get_fit("SA", .x, fit_tbl_uniq_no_floor)),
    diff_rz  = purrr::map2(fit_AU, fit_SA, ~ edge_cohort_diff_draws_rz(.x, .y, node_names = nodes))
  ) %>%
  select(wave, diff_rz) %>%
  tidyr::unnest_longer(diff_rz, values_to = "rz", indices_to = "edge_raw") %>%
  mutate(
    term = vapply(
      strsplit(edge_raw, " — ", fixed = TRUE),
      function(z) paste(sort(z), collapse = " - "),
      character(1)
    ),
    stats = purrr::map(rz, ~ summ_delta_rz(.x$dr, .x$dz, rope = rope_rq3))
  ) %>%
  tidyr::unnest(stats) %>%
  transmute(
    panel = paste0("Cohort difference (AU − SA) at ", wave),
    term,
    estimate_r = fmt_ci(r_q50, r_q025, r_q975, digits = 2),
    estimate_z = fmt_ci(z_q50, z_q025, z_q975, digits = 2),
    rope_p_r   = fmt_p(p_outside_rope_r, digits = 2),
    analysis   = "Sensitivity (no floor)"
  )

# DiD (sensitivity)
rq3_did_edges_rz_sens <- tibble(panel = "Difference-in-differences (ΔAU − ΔSA)") %>%
  mutate(
    did_rz = list(edge_did_draws_rz(fit_AU_T1_nf, fit_AU_T2_nf, fit_SA_T1_nf, fit_SA_T2_nf, node_names = nodes))
  ) %>%
  tidyr::unnest_longer(did_rz, values_to = "rz", indices_to = "edge_raw") %>%
  mutate(
    term = vapply(
      strsplit(edge_raw, " — ", fixed = TRUE),
      function(z) paste(sort(z), collapse = " - "),
      character(1)
    ),
    stats = purrr::map(rz, ~ summ_delta_rz(.x$dr, .x$dz, rope = rope_rq3))
  ) %>%
  tidyr::unnest(stats) %>%
  transmute(
    panel,
    term,
    estimate_r = fmt_ci(r_q50, r_q025, r_q975, digits = 2),
    estimate_z = fmt_ci(z_q50, z_q025, z_q975, digits = 2),
    rope_p_r   = fmt_p(p_outside_rope_r, digits = 2),
    analysis   = "Sensitivity (no floor)"
  )

rq3_edges_dual_sens <- bind_rows(rq3_wave_edges_rz_sens, rq3_did_edges_rz_sens) %>%
  mutate(
    panel = factor(panel, levels = c(
      "Cohort difference (AU − SA) at T1",
      "Cohort difference (AU − SA) at T2",
      "Difference-in-differences (ΔAU − ΔSA)"
    ))
  ) %>%
  arrange(panel, term)

# Combine main + sensitivity
rq3_edges_dual_combined <- bind_rows(
  rq3_edges_dual,
  rq3_edges_dual_sens
)

```

```{r}
#| label: rq3-inline-helpers
#| include: false

library(dplyr)
library(stringr)

# Return the (unique) row for a given panel/term/analysis from your long table
rq3_row <- function(panel, term, analysis = "Main analysis") {
  out <- rq3_edges_dual_combined %>%
    dplyr::filter(panel == !!panel, term == !!term, analysis == !!analysis)
  if (nrow(out) != 1) stop("Expected 1 row; got ", nrow(out), " for: ", panel, " / ", term, " / ", analysis)
  out
}

# Parse "m [lo, hi]" from estimate_r
rq3_ci <- function(panel, term, analysis = "Main analysis") {
  est <- rq3_row(panel, term, analysis)$estimate_r
  m  <- as.numeric(str_match(est, "^\\s*([-0-9.]+)\\s*\\[")[,2])
  lo <- as.numeric(str_match(est, "\\[\\s*([-0-9.]+)\\s*,")[,2])
  hi <- as.numeric(str_match(est, ",\\s*([-0-9.]+)\\s*\\]")[,2])
  c(m = m, lo = lo, hi = hi)
}

rq3_rope <- function(panel, term, analysis = "Main analysis") {
  as.numeric(rq3_row(panel, term, analysis)$rope_p_r)
}

# Exclusion lookups from excluded_summary (created in rq3-sensitivity-networks-no-floor)
excl_n <- function(country, timepoint) {
  excluded_summary %>% filter(country == !!country, timepoint == !!timepoint) %>% pull(n_excluded) %>% as.integer()
}
orig_n <- function(country, timepoint) {
  excluded_summary %>% filter(country == !!country, timepoint == !!timepoint) %>% pull(n_orig) %>% as.integer()
}
excl_pct <- function(country, timepoint) {
  excluded_summary %>% filter(country == !!country, timepoint == !!timepoint) %>% pull(pct_excluded) %>% as.numeric()
}
```
### Research Question 3 (Secondary): Cross-Cohort Comparisons
At matched waves (T1 and T2), do AU and SA differ in EF conditional associations, and do the cohorts show divergent developmental trajectories from T1 to T2 (difference-in-differences)?

A substantial floor effect was observed in Australian T1 cognitive flexibility (32.5% scoring zero), raising potential concerns for cross-cohort network comparisons. Floor effects can induce artificial correlations through range restriction and may bias partial correlation estimates. To address this, we (1) Report cross-cohort comparisons using the full sample (primary analysis), and (2) Conduct sensitivity analyses excluding children who scored zero on cognitive flexibility at each wave. If results converge across analyses, this would suggest floor effects do not meaningfully distort cross-cohort comparisons. Divergence would indicate that apparent cohort differences partly reflect measurement artefacts.

**Main Analysis (Full Sample)**: At T1, posterior medians suggested modest AU–SA differences in several edges; however, all 95% credible intervals overlapped zero. At T2, cohort differences were smaller and predominantly positive, but again uncertain. In the difference-in-differences analysis, most edges were centered near zero. The largest deviation was observed for CogFlex–Inhibition (median = `r round(rq3_ci("Difference-in-differences (ΔAU − ΔSA)", "ef_cogflex - ef_inhibition", "Main analysis")["m"], 2)`; 95% CrI [`r round(rq3_ci("Difference-in-differences (ΔAU − ΔSA)", "ef_cogflex - ef_inhibition", "Main analysis")["lo"], 2)`, `r round(rq3_ci("Difference-in-differences (ΔAU − ΔSA)", "ef_cogflex - ef_inhibition", "Main analysis")["hi"], 2)`]; P(|Δr|>0.10) = `r round(rq3_rope("Difference-in-differences (ΔAU − ΔSA)", "ef_cogflex - ef_inhibition", "Main analysis"), 2)`), though its credible interval still included zero, indicating substantial uncertainty. Results were substantively unchanged when differences were summarized on the Fisher z (atanh) scale (@tbl-rq3-gt-edges-dual).

**Sensitivity Analysis (Excluding Cognitive Flexibility Floor Performers)**: Given the pronounced floor effect in Australian T1 cognitive flexibility (`r excl_n("AU","T1")`/`r orig_n("AU","T1")` excluded [`r excl_pct("AU","T1")`%]; AU T2: `r excl_n("AU","T2")`/`r orig_n("AU","T2")` [`r excl_pct("AU","T2")`%]; SA T1: `r excl_n("SA","T1")`/`r orig_n("SA","T1")` [`r excl_pct("SA","T1")`%]; SA T2: `r excl_n("SA","T2")`/`r orig_n("SA","T2")` [`r excl_pct("SA","T2")`%]), we refitted networks after wave-specific exclusion of children scoring zero on cognitive flexibility. Estimates were highly similar in direction and magnitude to the main analysis (see @tbl-rq3-sensitivity-comparison), with credible intervals widening due to reduced sample size. Patterns at T2 and in the difference-in-differences analysis were nearly identical.Together, these results indicate that cross-cohort differences in EF network structure are small and uncertain.
```{r}
#| label: tbl-rq3-sensitivity-comparison
#| tbl-cap: "Sensitivity analysis: Cross-cohort comparisons with vs without floor performers. Main analysis includes all children; sensitivity analysis uses wave-specific exclusion of children who scored 0 on any EF measure at that wave."
#| include: true

# Side-by-side comparison table
rq3_comparison <- rq3_edges_dual_combined %>%
  select(panel, term, analysis, estimate_r, rope_p_r) %>%
  pivot_wider(
    names_from = analysis,
    values_from = c(estimate_r, rope_p_r),
    names_glue = "{analysis}_{.value}"
  ) %>%
  select(
    panel, term,
    `Main analysis_estimate_r`,
    `Main analysis_rope_p_r`,
    `Sensitivity (no floor)_estimate_r`,
    `Sensitivity (no floor)_rope_p_r`
  )

gt_rq3_comparison <- rq3_comparison %>%
  gt(rowname_col = "term", groupname_col = "panel") %>%
  tab_header(title = md("\\vspace{10pt}")) %>%
  tab_stubhead(label = "Edge") %>%
  cols_label(
    `Main analysis_estimate_r` = "Δr [95% CrI]",
    `Main analysis_rope_p_r` = "P(|Δr|>0.10)",
    `Sensitivity (no floor)_estimate_r` = "Δr [95% CrI]",
    `Sensitivity (no floor)_rope_p_r` = "P(|Δr|>0.10)"
  ) %>%
  tab_spanner(
    label = "Main Analysis",
    columns = starts_with("Main analysis")
  ) %>%
  tab_spanner(
    label = "Sensitivity (No Floor)",
    columns = starts_with("Sensitivity")
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_options(
    table.font.size = px(10),
    row_group.font.weight = "bold",
    heading.title.font.size = px(1)
  ) %>%
  tab_footnote(
  footnote = "Main analysis: all children. Sensitivity: wave-specific exclusion of children who scored 0 on Cognitive Flexibility at that wave (AU T1: 75/232 excluded [32.3%]; AU T2: 42/217 excluded [19.4%]; SA T1: 0/217 excluded [0.0%]; SA T2: 7/189 excluded [3.7%]).",
  locations = cells_column_spanners(spanners = "Sensitivity (No Floor)")
)

gt_rq3_comparison
```
\clearpage

```{r}
#| label: rq4-stratified-approach
#| include: false

# Create high/low splits at median within cohort
ef_net_stratified <- ef_net %>%
  dplyr::left_join(mods_t1, by = c("country", "id")) %>%
  dplyr::filter(!is.na(income_z) & !is.na(hle_z)) %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(
    income_group = dplyr::if_else(income_z > median(income_z, na.rm = TRUE), "High", "Low"),
    hle_group    = dplyr::if_else(hle_z > median(hle_z, na.rm = TRUE), "High", "Low")
  ) %>%
  dplyr::ungroup()

# Prepare wide data for BGGM, split by country × wave × moderator group
ef_net_wide_strat <- ef_net_stratified %>%
  dplyr::select(country, timepoint, id, variable, node, income_group, hle_group) %>%
  tidyr::pivot_wider(
    names_from = variable,
    values_from = node
  ) %>%
  dplyr::filter(!dplyr::if_all(dplyr::all_of(nodes), ~ is.na(.)))

# Split by country × wave × income group
dat_split_income <- ef_net_wide_strat %>%
  dplyr::select(country, timepoint, income_group, id, dplyr::all_of(nodes)) %>%
  dplyr::group_by(country, timepoint, income_group) %>%
  dplyr::group_split()

keys_income <- ef_net_wide_strat %>%
  dplyr::select(country, timepoint, income_group, id, dplyr::all_of(nodes)) %>%
  dplyr::group_by(country, timepoint, income_group) %>%
  dplyr::group_keys() %>%
  dplyr::arrange(country, timepoint, income_group)

# Split by country × wave × HLE group  
dat_split_hle <- ef_net_wide_strat %>%
  dplyr::select(country, timepoint, hle_group, id, dplyr::all_of(nodes)) %>%
  dplyr::group_by(country, timepoint, hle_group) %>%
  dplyr::group_split()

keys_hle <- ef_net_wide_strat %>%
  dplyr::select(country, timepoint, hle_group, id, dplyr::all_of(nodes)) %>%
  dplyr::group_by(country, timepoint, hle_group) %>%
  dplyr::group_keys() %>%
  dplyr::arrange(country, timepoint, hle_group)

# Fit BGGM models for each stratum
fit_one_strat <- function(df) {
  Y <- df %>%
    dplyr::select(dplyr::all_of(nodes)) %>%
    dplyr::mutate(dplyr::across(dplyr::everything(), as.numeric)) %>%
    as.matrix()
  
  n <- nrow(Y)
  
  if (n < 20) {  # minimum sample size for stable estimation
    return(list(fit = NULL, n = n, reason = "insufficient_n"))
  }
  
  fit <- BGGM::estimate(
    Y,
    type   = "continuous",
    iter   = bggm_iter,
    burnin = bggm_burnin,
    chains = bggm_chains,
    impute = TRUE,
    save   = TRUE
  )
  
  list(fit = fit, n = n, reason = "success")
}

# fit income-stratified models
ggm_fits_income <- purrr::map(dat_split_income, fit_one_strat)

fit_tbl_income <- keys_income %>%
  dplyr::mutate(res = ggm_fits_income) %>%
  tidyr::unnest_wider(res)

# fit HLE-stratified models
ggm_fits_hle <- purrr::map(dat_split_hle, fit_one_strat)

fit_tbl_hle <- keys_hle %>%
  dplyr::mutate(res = ggm_fits_hle) %>%
  tidyr::unnest_wider(res)

# check which fits succeeded
fit_tbl_income %>%
  dplyr::mutate(ok = !purrr::map_lgl(fit, is.null)) %>%
  dplyr::select(country, timepoint, income_group, n, reason, ok)

fit_tbl_hle %>%
  dplyr::mutate(ok = !purrr::map_lgl(fit, is.null)) %>%
  dplyr::select(country, timepoint, hle_group, n, reason, ok)
```

```{r}
#| label: rq4-compute-moderation-effects
#| include: false

# Compute edge differences: High - Low for each moderator

# Helper: get edge draws difference between two groups
edge_group_diff <- function(fit_high, fit_low, node_names = nodes) {
  if (is.null(fit_high) || is.null(fit_low)) {
    return(NULL)
  }
  
  high_list <- edge_draws_list(fit_high, node_names = node_names)
  low_list  <- edge_draws_list(fit_low, node_names = node_names)
  
  # align and subtract
  purrr::map2(high_list, low_list, function(h, l) {
    al <- align_draws(h, l, keep = "last")
    al$x - al$y  # High - Low
  })
}

# income moderation: For each country × wave, compute High - Low
income_mod_effects <- fit_tbl_income %>%
  dplyr::filter(!purrr::map_lgl(fit, is.null)) %>%
  dplyr::arrange(country, timepoint, income_group) %>%
  dplyr::group_by(country, timepoint) %>%
  dplyr::filter(n() == 2) %>%  # need both High and Low
  dplyr::summarise(
    fit_high = list(fit[income_group == "High"][[1]]),
    fit_low  = list(fit[income_group == "Low"][[1]]),
    n_high   = n[income_group == "High"],
    n_low    = n[income_group == "Low"],
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    diff_draws = purrr::map2(fit_high, fit_low, ~ edge_group_diff(.x, .y, node_names = nodes))
  )

# HLE moderation: For each country × wave, compute High - Low
hle_mod_effects <- fit_tbl_hle %>%
  dplyr::filter(!purrr::map_lgl(fit, is.null)) %>%
  dplyr::arrange(country, timepoint, hle_group) %>%
  dplyr::group_by(country, timepoint) %>%
  dplyr::filter(n() == 2) %>%
  dplyr::summarise(
    fit_high = list(fit[hle_group == "High"][[1]]),
    fit_low  = list(fit[hle_group == "Low"][[1]]),
    n_high   = n[hle_group == "High"],
    n_low    = n[hle_group == "Low"],
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    diff_draws = purrr::map2(fit_high, fit_low, ~ edge_group_diff(.x, .y, node_names = nodes))
  )
```

```{r}
#| label: rq4-moderation-tables
#| include: false

rope_mod <- 0.10

# Summarize income moderation effects
rq4_income_mods <- income_mod_effects %>%
  dplyr::select(country, timepoint, n_high, n_low, diff_draws) %>%
  tidyr::unnest_longer(diff_draws, values_to = "draws", indices_to = "edge") %>%
  dplyr::filter(!purrr::map_lgl(draws, is.null)) %>%
  dplyr::mutate(stats = purrr::map(draws, ~ summ_draws_delta(.x, rope = rope_mod))) %>%
  tidyr::unnest(stats) %>%
  dplyr::transmute(
    moderator = "Income",
    country, timepoint, n_high, n_low,
    edge,
    estimate = fmt_ci_delta(q50, q025, q975, digits = 2),
    rope_p   = fmt_p(p_outside_rope, digits = 2)
  )

# Summarize HLE moderation effects
rq4_hle_mods <- hle_mod_effects %>%
  dplyr::select(country, timepoint, n_high, n_low, diff_draws) %>%
  tidyr::unnest_longer(diff_draws, values_to = "draws", indices_to = "edge") %>%
  dplyr::filter(!purrr::map_lgl(draws, is.null)) %>%
  dplyr::mutate(stats = purrr::map(draws, ~ summ_draws_delta(.x, rope = rope_mod))) %>%
  tidyr::unnest(stats) %>%
  dplyr::transmute(
    moderator = "HLE",
    country, timepoint, n_high, n_low,
    edge,
    estimate = fmt_ci_delta(q50, q025, q975, digits = 2),
    rope_p   = fmt_p(p_outside_rope, digits = 2)
  )

# Combine
rq4_table <- dplyr::bind_rows(rq4_income_mods, rq4_hle_mods) %>%
  dplyr::mutate(
    moderator = factor(moderator, levels = c("Income", "HLE")),
    country   = factor(country, levels = c("AU", "SA"))
  ) %>%
  dplyr::arrange(moderator, country, timepoint, edge)

rq4_table

```
### RQ4 (Exploratory): Socioeconomic Moderation of Network Structure
Within each cohort, does EF network structure differ between children from high versus low baseline (T1) household income and home learning environments? Specifically, are edges systematically stronger or weaker in high-SES groups across waves?

Exploratory moderation analyses revealed little consistent evidence that baseline income or HLE systematically altered EF network structure within cohorts. However, in Australia at T2, the cognitive flexibility–working memory edge was substantially weaker among children from high-income families (High−Low: −0.46 [−0.80, −0.11], P(|Δ|>0.1)=0.98), suggesting that socioeconomic advantage may be associated with more differentiated EF development. Conversely, HLE showed tentative positive moderation patterns (stronger coupling in enriched home environments), though credible intervals crossed zero.

```{r}
#| label: tbl-rq4-moderation
#| tbl-cap: "Within-cohort moderation of EF edges by baseline (T1) income and HLE. Cells show posterior median [95% CrI] for the difference in edge strength between high vs low moderator groups (High − Low). ROPE probability indicates P(|difference| > 0.10)."
#| include: true

gt_rq4 <- rq4_table %>%
  gt::gt(
    rowname_col   = "edge",
    groupname_col = "moderator"
  ) %>%
  gt::tab_header(title = gt::md("\\vspace{10pt}")) %>%
  gt::tab_stubhead(label = "Edge") %>%
  gt::cols_label(
    country   = "Cohort",
    timepoint = "Wave",
    n_high    = "n (High)",
    n_low     = "n (Low)",
    estimate  = "Median [95% CrI]",
    rope_p    = paste0("P(|Δ|>", rope_mod, ")")
  ) %>%
  gt::cols_align(
    align = "center",
    columns = c(country, timepoint, n_high, n_low, estimate, rope_p)
  ) %>%
  gt::tab_options(
    table.font.size         = gt::px(11),
    row_group.font.weight   = "bold",
    heading.title.font.size = gt::px(1)
  )

gt_rq4
```

```{r}
#| label: rq4-inline-helpers
#| include: false

rq4_mod_row <- function(moderator, country, wave, edge_label) {
  # Normalize moderator input (accept "income", "Income", "hle", "HLE")
  mod_val <- dplyr::case_when(
    tolower(moderator) == "income" ~ "Income",
    tolower(moderator) == "hle" ~ "HLE",
    TRUE ~ stop("Unknown moderator: ", moderator, ". Use 'income' or 'hle'")
  )
  
  ctry <- normalise_country(country)
  key  <- canonical_edge_key(edge_label)
  
  out <- rq4_table %>%
    dplyr::filter(
      moderator == mod_val,
      country == ctry,
      timepoint == wave,
      edge == key
    )
  
  if (nrow(out) != 1) {
    stop("Could not uniquely match: ", moderator, ", ", country, ", ", wave, ", ", edge_label,
         "\nRows matched: ", nrow(out))
  }
  out
}

rq4_mod_report <- function(moderator, country, wave, edge_label) {
  rq4_mod_row(moderator, country, wave, edge_label)$estimate
}

rq4_mod_meaningful <- function(moderator, country, wave, edge_label) {
  r <- rq4_mod_row(moderator, country, wave, edge_label)
  paste0("P(|Δ|>0.1)=", r$rope_p)
}
```
\clearpage

# References

::: {#refs}
:::

```{r}
#| label: demographics-table-setup
#| include: false

# labels + formatting helpers
ef_labels <- c(
  ef_inhibition = "Inhibition",
  ef_cogflex    = "Cognitive flexibility",
  ef_workingmem = "Working memory"
)

fmt_mean_sd <- function(mean, sd, digits = 2) {
  ifelse(
    is.na(mean) | is.na(sd),
    NA_character_,
    sprintf(paste0("%.", digits, "f (%.", digits, "f)"), mean, sd)
  )
}

fmt_med_rng <- function(median, min, max, digits = 2) {
  ifelse(
    is.na(median) | is.na(min) | is.na(max),
    NA_character_,
    sprintf(paste0("%.", digits, "f [%.", digits, "f, %.", digits, "f]"),
            median, min, max)
  )
}

# standardize country labels for tables
country_for_table <- function(x) {
  dplyr::case_when(
    x == "AU" ~ "Australia",
    x == "SA" ~ "SA",
    TRUE ~ as.character(x)
  )
}

# build tp_* inputs used in Table 1
stopifnot(exists("ef_all_keep"), exists("age_all_keep"))
stopifnot(all(c("country","timepoint","id","variable","value") %in% names(ef_all_keep)))
stopifnot(all(c("country","timepoint","id","age") %in% names(age_all_keep)))

tp_ef_desc <- ef_all_keep %>%
  filter(!is.na(timepoint)) %>%
  mutate(
    country   = country_for_table(country),
    timepoint = as.character(timepoint),
    variable  = as.character(variable)
  ) %>%
  group_by(country, timepoint, variable) %>%
  summarise(
    n    = sum(!is.na(value)),
    mean = ifelse(all(is.na(value)), NA_real_, mean(value, na.rm = TRUE)),
    sd   = ifelse(sum(!is.na(value)) > 1, sd(value, na.rm = TRUE), NA_real_),
    .groups = "drop"
  )

tp_age <- age_all_keep %>%
  filter(!is.na(timepoint)) %>%
  mutate(
    country   = country_for_table(country),
    timepoint = as.character(timepoint)
  ) %>%
  group_by(country, timepoint) %>%
  summarise(
    age_n      = sum(!is.na(age)),
    age_mean   = ifelse(age_n > 0, mean(age, na.rm = TRUE), NA_real_),
    age_sd     = ifelse(age_n > 1, sd(age, na.rm = TRUE), NA_real_),
    age_median = ifelse(age_n > 0, median(age, na.rm = TRUE), NA_real_),
    age_min    = ifelse(age_n > 0, min(age, na.rm = TRUE), NA_real_),
    age_max    = ifelse(age_n > 0, max(age, na.rm = TRUE), NA_real_),
    .groups = "drop"
  )

if (!exists("sa_sex_long") || !exists("aus_sex_tp")) {
  stop("Need sa_sex_long and aus_sex_tp (or rebuild your sex objects earlier).")
}

tp_sex <- bind_rows(
  sa_sex_long %>% select(country, timepoint, id, sex),
  aus_sex_tp  %>% select(country, timepoint, id, sex)
) %>%
  mutate(
    country   = country_for_table(country),
    timepoint = as.character(timepoint),
    sex       = as.character(sex)
  ) %>%
  count(country, timepoint, sex, name = "n") %>%
  group_by(country, timepoint) %>%
  mutate(pct = 100 * n / sum(n)) %>%
  ungroup() %>%
  transmute(
    country,
    timepoint,
    level = sex,
    cell  = paste0(n, " (", sprintf("%.1f", pct), "%)")
  )

stopifnot(nrow(tp_ef_desc) > 0, nrow(tp_age) > 0, nrow(tp_sex) > 0)

add_group <- function(df) {
  df %>%
    mutate(
      country   = country_for_table(country),
      timepoint = as.character(timepoint),
      group     = paste(country, timepoint, sep = " — ")
    )
}

make_group_levels <- function(...) {
  bind_rows(...) %>%
    distinct(country, timepoint) %>%
    mutate(
      country   = country_for_table(country),
      timepoint = factor(as.character(timepoint), levels = paste0("T", 1:10)),
      group     = paste(country, timepoint, sep = " — ")
    ) %>%
    arrange(match(country, c("Australia","SA")), timepoint) %>%
    pull(group)
}

cont_block_long <- function(tp_df, section_title) {
  add_group(tp_df) %>%
    transmute(
      section = section_title,
      variable,
      group,
      n   = as.character(n),
      msd = fmt_mean_sd(mean, sd, digits = 2)
    ) %>%
    pivot_longer(cols = c(n, msd), names_to = "stat", values_to = "value") %>%
    mutate(
      row = case_when(
        stat == "n"   ~ paste0(variable, ", n"),
        stat == "msd" ~ paste0(variable, ", Mean (SD)")
      )
    ) %>%
    select(section, row, group, value)
}

to_wide <- function(long_df, group_levels) {
  long_df %>%
    mutate(group = factor(group, levels = group_levels)) %>%
    select(section, row, group, value) %>%
    pivot_wider(names_from = group, values_from = value) %>%
    arrange(section, row)
}

```

# Demographics {.appendix #render-table1}
::: {.landscape}
```{r}
#| label: render-table1
#| tbl-cap: "Age and executive function by country and timepoint. All summaries are anchored to children with any EF observed at that timepoint (partial EF allowed)."
#| include: true
#| ft.arraystretch: 1

group_levels <- make_group_levels(
  tp_age %>% distinct(country, timepoint),
  tp_ef_desc %>% distinct(country, timepoint),
  tp_sex %>% distinct(country, timepoint)
)

# EF block: do n and mean(sd) in one pass
ef_long <- add_group(tp_ef_desc) %>%
  mutate(domain = unname(ef_labels[as.character(variable)])) %>%
  transmute(
    section = "Executive function",
    domain,
    group,
    n   = as.character(n),
    msd = fmt_mean_sd(mean, sd, digits = 2)
  ) %>%
  pivot_longer(cols = c(n, msd), names_to = "stat", values_to = "value") %>%
  mutate(row = case_when(
    stat == "n"   ~ paste0(domain, ", n"),
    stat == "msd" ~ paste0(domain, ", Mean (SD)")
  )) %>%
  select(section, row, group, value)

# Age block
age_long <- add_group(tp_age) %>%
  transmute(
    section = "Age",
    group,
    row_mean = "Age (years), Mean (SD)",
    val_mean = fmt_mean_sd(age_mean, age_sd, digits = 2),
    row_med  = "Age (years), Median [min, max]",
    val_med  = fmt_med_rng(age_median, age_min, age_max, digits = 2)
  ) %>%
  pivot_longer(
    cols = c(val_mean, val_med),
    names_to = "which",
    values_to = "value"
  ) %>%
  mutate(row = ifelse(which == "val_mean", row_mean, row_med)) %>%
  select(section, row, group, value)

# Sex block
sex_long <- add_group(tp_sex) %>%
  transmute(
    section = "Sex",
    row = paste0(level, ", n (%)"),
    group,
    value = cell
  )

metrics1_long <- bind_rows(ef_long, age_long, sex_long) %>%
  mutate(section = factor(section, levels = c("Executive function", "Age", "Sex")))

paper_table1 <- to_wide(metrics1_long, group_levels)

gt1 <- paper_table1 %>%
  gt(groupname_col = "section", rowname_col = "row") %>%
  cols_align(align = "center") %>%
  tab_options(
    table.width = pct(100),
    row_group.as_column = TRUE,
    table.font.size = px(11)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  )

gt1
```
:::

```{r}
#| label: summarise-table2-components
#| include: false

sa_edu_tp     <- desc_cat_tp(sa_ses,     "edu_sa",     sa_any_ids,  "Caregiver education (SA)")
aus_edu_tp    <- desc_cat_tp(aus_ses_tp, "edu_aus",    aus_any_ids, "Caregiver education (AUS)")
aus_income_tp <- desc_cat_tp(aus_ses_tp, "income_aus", aus_any_ids, "Household income (AUS)")

ses_tp_long2 <- bind_rows(sa_edu_tp, aus_edu_tp, aus_income_tp) %>%
  mutate(country = country_for_table(country)) %>%
  arrange(country, timepoint, variable, level)

tp_income_sa <- summ_cont_tp(sa_ses, "nids_assets_sa", sa_any_ids, "Household income (SA)") %>%
  mutate(country = country_for_table(country))

tp_hle_sa <- bind_rows(
  summ_cont_tp(sa_ses, "hla_frequency1",       sa_any_ids, "HLE activity frequency (sum)"),
  summ_cont_tp(sa_ses, "num_caregivers_clean", sa_any_ids, "HLE: unique caregiver types involved"),
  summ_cont_tp(sa_ses, "books_toys_total1",    sa_any_ids, "HLE: books/toys total"),
  summ_cont_tp(sa_ses, "time_total1",          sa_any_ids, "HLE: time total")
) %>%
  mutate(country = country_for_table(country)) %>%
  arrange(country, timepoint, variable)

tp_hle_aus <- summ_cont_tp(
  aus_ses_tp, "hle_aus", aus_any_ids,
  "Home learning environment (AUS; HLE Index)"
) %>%
  mutate(country = country_for_table(country))
```

::: {.landscape}
```{r}
#| label: render-table2
#| tbl-cap: "Socioeconomic status and home learning environment by country and timepoint."
#| include: true

group_levels <- bind_rows(
  ses_tp_long2 %>% distinct(country, timepoint),
  tp_income_sa %>% distinct(country, timepoint),
  tp_hle_sa %>% distinct(country, timepoint),
  tp_hle_aus %>% distinct(country, timepoint)
) %>%
  distinct(country, timepoint) %>%
  mutate(
    timepoint = factor(timepoint, levels = paste0("T", 1:10)),
    group = paste(country, timepoint, sep = " — ")
  ) %>%
  arrange(match(country, c("Australia","SA")), timepoint) %>%  # <-- Australia first
  pull(group)

# SA income (continuous)
income2_long <- bind_rows(
  tp_income_sa %>%
    mutate(group = paste(country, timepoint, sep = " — ")) %>%
    transmute(section = "Household income (SA)",
              row = paste0(variable, ", n"),
              group, value = as.character(n)),
  tp_income_sa %>%
    mutate(group = paste(country, timepoint, sep = " — ")) %>%
    transmute(section = "Household income (SA)",
              row = paste0(variable, ", Mean (SD)"),
              group, value = fmt_mean_sd(mean, sd, digits = 2))
)

income2_wide <- income2_long %>%
  mutate(group = factor(group, levels = group_levels)) %>%
  select(section, row, group, value) %>%
  tidyr::pivot_wider(names_from = group, values_from = value) %>%
  arrange(section, row)

# SA HLE (continuous)
hle_sa_long <- bind_rows(
  tp_hle_sa %>%
    mutate(group = paste(country, timepoint, sep = " — ")) %>%
    transmute(section = "Home learning environment (SA)",
              row = paste0(variable, ", n"),
              group, value = as.character(n)),
  tp_hle_sa %>%
    mutate(group = paste(country, timepoint, sep = " — ")) %>%
    transmute(section = "Home learning environment (SA)",
              row = paste0(variable, ", Mean (SD)"),
              group, value = fmt_mean_sd(mean, sd, digits = 2))
)

hle_sa_wide <- hle_sa_long %>%
  mutate(group = factor(group, levels = group_levels)) %>%
  select(section, row, group, value) %>%
  tidyr::pivot_wider(names_from = group, values_from = value) %>%
  arrange(section, row)

# AUS HLE index (continuous) 
hle_aus_long <- bind_rows(
  tp_hle_aus %>%
    mutate(group = paste(country, timepoint, sep = " — ")) %>%
    transmute(section = "Home learning environment (AUS)",
              row = paste0(variable, ", n"),
              group, value = as.character(n)),
  tp_hle_aus %>%
    mutate(group = paste(country, timepoint, sep = " — ")) %>%
    transmute(section = "Home learning environment (AUS)",
              row = paste0(variable, ", Mean (SD)"),
              group, value = fmt_mean_sd(mean, sd, digits = 2))
)

hle_aus_wide <- hle_aus_long %>%
  mutate(group = factor(group, levels = group_levels)) %>%
  select(section, row, group, value) %>%
  tidyr::pivot_wider(names_from = group, values_from = value) %>%
  arrange(section, row)

# Categorical block (education SA/AUS + income AUS)
ses2_wide <- ses_tp_long2 %>%
  mutate(group = paste(country, timepoint, sep = " — "),
         group = factor(group, levels = group_levels)) %>%
  transmute(section = variable, row = level, group, value = cell) %>%
  tidyr::pivot_wider(names_from = group, values_from = value) %>%
  arrange(section, row)

paper_table2 <- bind_rows(ses2_wide, income2_wide, hle_aus_wide, hle_sa_wide) %>%
  mutate(section = factor(section, levels = c(
    "Caregiver education (AUS)",
    "Caregiver education (SA)",
    "Household income (AUS)",
    "Household income (SA)",
    "Home learning environment (AUS)",
    "Home learning environment (SA)"
  ))) %>%
  arrange(section, row)

gt2 <- paper_table2 %>%
  gt(groupname_col = "section", rowname_col = "row") %>%
  tab_source_note(
    source_note = md("**Note.** Summaries are restricted to children with any EF data at each wave (partial EF allowed). In Australia, caregiver education, household income, and the HLE Index are measured once per child and carried across waves; *n* and summary statistics may still differ across T1–T3 because the EF-available sample varies by wave (attrition/partial EF). In South Africa, caregiver education, income, and HLE measures are recorded by wave and summarised only where collected (later-wave cells are NA if not assessed).")
  ) %>%
  cols_align(align = "center") %>%
  tab_options(
    table.width = pct(100),
    row_group.as_column = TRUE,
    table.font.size = px(11)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  )

gt2
```
:::

```{r}
#| label: standardize
#| include: false

stopifnot(exists("sa_ef_long"), exists("aus_ef_long"))
stopifnot(exists("sa_age_long"), exists("aus_age_long"))

time_levels <- c("T1","T2","T3")
nodes <- c("ef_inhibition","ef_cogflex","ef_workingmem")

ef_labels <- c(
  ef_inhibition = "Inhibition",
  ef_cogflex    = "Cognitive flexibility",
  ef_workingmem = "Working memory"
)

ef_std <- ef_all %>%
  dplyr::group_by(variable) %>%
  dplyr::mutate(value_z = as.numeric(scale(value))) %>%
  dplyr::ungroup() %>%
  dplyr::left_join(
    age_all %>% dplyr::select(country, timepoint, id, age),
    by = c("country", "timepoint", "id")
  ) %>%
  dplyr::mutate(
    # enforce canonical codes (do NOT recode to names here)
    country = as.character(country),
    country = dplyr::case_when(
      country %in% c("AU", "Australia")      ~ "AU",
      country %in% c("SA", "South Africa")   ~ "SA",
      TRUE ~ country
    ),
    country  = factor(country, levels = c("AU", "SA")),
    timepoint = factor(as.character(timepoint), levels = time_levels, ordered = TRUE),
    id       = as.character(id),

    # derive task from VARIABLE (not from the existing label)
    task = factor(
      as.character(variable),
      levels = nodes,
      labels = unname(ef_labels[nodes])
    )
  )
```

```{r}
#| label: test-re-test
#| include: false

# keep only children who have >1 wave for a given task (within country)
# (ef_std already enforces canonical country codes AU/SA in the standardize chunk)

ef_retest_scores <- ef_std %>%
  dplyr::mutate(
    country   = factor(as.character(country), levels = c("AU","SA")),
    timepoint = factor(as.character(timepoint), levels = c("T1","T2","T3"), ordered = TRUE),
    id        = as.character(id)
  ) %>%
  dplyr::group_by(country, id, task) %>%
  dplyr::arrange(country, id, task, timepoint) %>%
  dplyr::filter(dplyr::n_distinct(timepoint) > 1) %>%
  dplyr::ungroup()

# wide format: one row per child × task (within country), columns per wave
# (also widens age so we can compute age gaps)
retest_wide <- ef_retest_scores %>%
  # if you *ever* have duplicates within a wave, this collapses safely
  dplyr::group_by(country, id, task, timepoint) %>%
  dplyr::summarise(
    value_z = mean(value_z, na.rm = TRUE),
    age     = mean(age,     na.rm = TRUE),
    .groups = "drop"
  ) %>%
  tidyr::pivot_wider(
    id_cols     = c(country, id, task),
    names_from  = timepoint,
    values_from = c(value_z, age),
    names_sep   = "_"
  ) %>%
  dplyr::mutate(
    mean_age      = rowMeans(dplyr::select(., dplyr::starts_with("age_")), na.rm = TRUE),
    age_gap_T12_y = age_T2 - age_T1,
    age_gap_T23_y = age_T3 - age_T2
  ) %>%
  dplyr::select(
    country, id, task,
    mean_age,
    age_gap_T12_y, age_gap_T23_y,
    value_z_T1, value_z_T2, value_z_T3
  )

# helper: only compute r if there are enough complete pairs
safe_cor <- function(a, b, min_n = 3) {
  n <- sum(stats::complete.cases(a, b))
  if (n < min_n) return(NA_real_)
  suppressWarnings(stats::cor(a, b, use = "complete.obs"))
}

# 3) test–retest correlations by country × task
trt <- retest_wide %>%
  dplyr::group_by(country, task) %>%
  dplyr::summarise(
    r_T12   = safe_cor(value_z_T1, value_z_T2),
    n_T12   = sum(stats::complete.cases(value_z_T1, value_z_T2)),
    gap_T12 = mean(age_gap_T12_y, na.rm = TRUE) * 12,  # months

    r_T23   = safe_cor(value_z_T2, value_z_T3),
    n_T23   = sum(stats::complete.cases(value_z_T2, value_z_T3)),
    gap_T23 = mean(age_gap_T23_y, na.rm = TRUE) * 12,  # months
    .groups = "drop"
  ) %>%
  dplyr::arrange(task, country)

trt
```

# Age associations {.appendix #render-test-re-test-plot}
```{r}
#| label: test-re-test-plot
#| fig-cap: "Executive Function associations across waves. Note: Standardised scores (z); colour indicates mean age across available waves"
#| include: true
#| fig-align: center
#| fig-width: 8
#| fig-height: 7
#| fig-pos: 'H'

# From retest_wide -> one row per child × task × pair (T1–T2 and T2–T3),
# then build a single row facet that only includes observed combos.

retest_long_pairs <- dplyr::bind_rows(
  retest_wide %>%
    dplyr::transmute(
      country, id, task, mean_age,
      pair = "T1–T2",
      x = value_z_T1, y = value_z_T2
    ),
  retest_wide %>%
    dplyr::transmute(
      country, id, task, mean_age,
      pair = "T2–T3",
      x = value_z_T2, y = value_z_T3
    )
) %>%
  dplyr::filter(!is.na(x) & !is.na(y)) %>%
  dplyr::mutate(
    country = factor(as.character(country), levels = c("AU","SA")),
    pair    = factor(pair, levels = c("T1–T2", "T2–T3")),
    row_facet = paste(country, pair, sep = "\n"),
    row_facet = factor(
      row_facet,
      levels = c(
        "AU\nT1–T2",
        "AU\nT2–T3",
        "SA\nT1–T2"
      )
    )
  )

# Panel stats (r + N), using the same "safe" logic as above
pair_stats <- retest_long_pairs %>%
  dplyr::group_by(country, task, pair, row_facet) %>%
  dplyr::summarise(
    n = sum(stats::complete.cases(x, y)),
    r = safe_cor(x, y, min_n = 3),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    label = ifelse(
      is.na(r),
      paste0("r = NA\nN = ", n),
      paste0("r = ", sprintf("%.2f", r), "\nN = ", n)
    )
  )

# Plot
p_retest_simple <- ggplot(retest_long_pairs, aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dotted", alpha = 0.6) +
  geom_point(aes(colour = mean_age), alpha = 0.5, size = 1.4) +
  geom_smooth(method = "lm", formula = y ~ x, se = TRUE) +
  geom_text(
    data = pair_stats,
    aes(label = label),
    x = -Inf, y = Inf,
    inherit.aes = FALSE,
    hjust = -0.05, vjust = 1.1, size = 3.5
  ) +
  facet_grid(row_facet ~ task) +
  labs(
    x = "Earlier wave (z)",
    y = "Later wave (z)",
    colour = "Mean age (years)"
  ) +
  theme(legend.position = "bottom")

p_retest_simple

```

# Executive Function across waves {.appendix #age-ef-wave}
```{r}
#| label: age-ef-wave
#| fig-cap: "Executive Function by age across waves (z-scored within EF task). Note: Points jittered + transparent; lines are linear fits with 95% CI"
#| include: true
#| fig-align: center
#| fig-width: 8
#| fig-height: 7
#| fig-pos: 'H'

# set up plot scales
.scale_colour_country <- function() {
  scale_colour_discrete()
}

# Age x EF x wave (standardized)
p_age_by_wave <- ggplot(
  ef_std %>%
    dplyr::filter(!is.na(age), !is.na(value_z)) %>%
    dplyr::mutate(
      country   = factor(as.character(country), levels = c("AU","SA")),
      timepoint = factor(as.character(timepoint), levels = c("T1","T2","T3"), ordered = TRUE)
    ),
  aes(x = age, y = value_z, colour = country)
) +
  geom_point(
    alpha = 0.15, size = 1,
    position = position_jitter(width = 0.03, height = 0.03)
  ) +
  geom_smooth(
    method = "lm", formula = y ~ x, se = TRUE, linewidth = 1
  ) +
  facet_grid(timepoint ~ task, scales = "fixed") +
  labs(
    x = "Age (years)",
    y = "EF (z-score within task)",
    colour = "Country"
  ) +
  .scale_colour_country() +
  theme(legend.position = "bottom")

p_age_by_wave
```

```{r}
#| label: restricted-sample
#| include: false

# restricted to at least 2 waves sample
# SA: EF observed at T1 and T2
# AU: strict (T1+T2+T3) or lenient (T1+T2)
#
# NOTE: ef_std should already be using canonical country codes (AU/SA) from the standardize chunk.
# We still normalise defensively here in case something upstream changes later.

# Wave-level EF presence flag: "any EF observed at this wave"
flags <- ef_std %>%
  dplyr::mutate(
    country = dplyr::case_when(
      as.character(country) %in% c("AU", "Australia")    ~ "AU",
      as.character(country) %in% c("SA", "South Africa") ~ "SA",
      TRUE ~ as.character(country)
    ),
    id       = as.character(id),
    timepoint = as.character(timepoint)
  ) %>%
  dplyr::group_by(country, id, timepoint) %>%
  dplyr::summarise(any_ef = any(!is.na(value_z)), .groups = "drop")

# SA keep: must have T1 & T2
sa_keep_ids <- flags %>%
  dplyr::filter(country == "SA", timepoint %in% c("T1","T2")) %>%
  dplyr::group_by(country, id) %>%
  dplyr::summarise(
    has_T1 = any(timepoint == "T1" & any_ef),
    has_T2 = any(timepoint == "T2" & any_ef),
    .groups = "drop"
  ) %>%
  dplyr::filter(has_T1 & has_T2) %>%
  dplyr::select(country, id)

# AU keep: strict vs lenient
au_keep_ids_strict <- flags %>%
  dplyr::filter(country == "AU", timepoint %in% c("T1","T2","T3")) %>%
  dplyr::group_by(country, id) %>%
  dplyr::summarise(
    has_T1 = any(timepoint == "T1" & any_ef),
    has_T2 = any(timepoint == "T2" & any_ef),
    has_T3 = any(timepoint == "T3" & any_ef),
    .groups = "drop"
  ) %>%
  dplyr::filter(has_T1 & has_T2 & has_T3) %>%
  dplyr::select(country, id)

au_keep_ids_t12 <- flags %>%
  dplyr::filter(country == "AU", timepoint %in% c("T1","T2")) %>%
  dplyr::group_by(country, id) %>%
  dplyr::summarise(
    has_T1 = any(timepoint == "T1" & any_ef),
    has_T2 = any(timepoint == "T2" & any_ef),
    .groups = "drop"
  ) %>%
  dplyr::filter(has_T1 & has_T2) %>%
  dplyr::select(country, id)

au_restriction <- "strict"  # "strict" or "t12"
au_keep_ids <- if (au_restriction == "strict") au_keep_ids_strict else au_keep_ids_t12

keep_ids_all <- dplyr::bind_rows(sa_keep_ids, au_keep_ids)

# Apply restriction to ef_std (keep AU/SA codes; do NOT recode to names)
ef_restricted <- ef_std %>%
  dplyr::mutate(
    country = dplyr::case_when(
      as.character(country) %in% c("AU", "Australia")    ~ "AU",
      as.character(country) %in% c("SA", "South Africa") ~ "SA",
      TRUE ~ as.character(country)
    ),
    id       = as.character(id),
    timepoint = factor(as.character(timepoint), levels = c("T1","T2","T3"), ordered = TRUE)
  ) %>%
  dplyr::inner_join(keep_ids_all, by = c("country","id"))

```

# Executive Function scores over time {.appendix #mean-trend}
```{r}
#| label: mean-trend
#| include: true
#| fig-align: center
#| fig-width: 8
#| fig-height: 5
#| fig-pos: 'H'
#| fig-cap: |
#|   **Mean EF scores over time (children with repeated EF data).**  
#|   *Note.* “EF observed” at a wave means at least one EF task score is non-missing. The analytic sample includes only children meeting the wave-coverage rule: SA = EF observed at both T1 and T2; AU = EF observed at T1–T3 (“strict”) or at T1 and T2 (“t12”)."

# Mean trend over time (standardised, restricted sample)
mean_df <- ef_restricted %>%
  dplyr::mutate(
    # task already exists in ef_std; keep it and just ensure levels are stable
    task = factor(as.character(task), levels = unname(ef_labels[nodes])),
    country = factor(as.character(country), levels = c("AU","SA")),
    timepoint = factor(as.character(timepoint), levels = c("T1","T2","T3"), ordered = TRUE)
  ) %>%
  dplyr::group_by(country, task, timepoint) %>%
  dplyr::summarise(
    n  = sum(!is.na(value_z)),
    m  = mean(value_z, na.rm = TRUE),
    se = sd(value_z, na.rm = TRUE) / sqrt(n),
    lo = m - 1.96 * se,
    hi = m + 1.96 * se,
    .groups = "drop"
  )

p_mean_trend <- ggplot(mean_df, aes(x = timepoint, y = m, group = 1)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2.2) +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = 0.10) +
  facet_grid(country ~ task) +
  labs(
    x = "Timepoint",
    y = "Mean EF (z-score)"
  ) +
  theme_bw(base_size = 11) +
  theme(
    legend.position = "none",
    panel.grid.minor = element_blank(),
    strip.background = element_blank()
  )

p_mean_trend
```

# Executive Function individual trajectories {.appendix #spaghetti-plot}
```{r}
#| label: spaghetti-plot
#| include: true
#| fig-align: center
#| fig-width: 8
#| fig-height: 5
#| fig-pos: 'H'
#| fig-cap: |
#|   **Individual EF trajectories over time (children with repeated EF data).**  
#|   *Note.* “EF observed” at a wave means at least one EF task score is non-missing. The analytic sample includes only children meeting the wave-coverage rule: SA = EF observed at both T1 and T2; AU = EF observed at T1–T3 (“strict”) or at T1 and T2 (“t12”). Mean ± 95% CI is overlaid. EF scores are z-scored within task (pooled).

# Align factor structure to the 'standardize' chunk:
# - country stays AU/SA (canonical codes)
# - task uses the pretty labels created in ef_std (already a factor)
# - timepoint uses T1/T2/T3 (ordered)

ef_restricted_lab <- ef_restricted %>%
  dplyr::mutate(
    country   = dplyr::case_when(
      as.character(country) %in% c("AU", "Australia")    ~ "AU",
      as.character(country) %in% c("SA", "South Africa") ~ "SA",
      TRUE ~ as.character(country)
    ),
    country   = factor(country, levels = c("AU","SA")),
    task      = factor(as.character(task), levels = unname(ef_labels[nodes])),
    timepoint = factor(as.character(timepoint), levels = c("T1","T2","T3"), ordered = TRUE),
    id        = as.character(id)
  )

mean_df_lab <- mean_df %>%
  dplyr::mutate(
    country   = dplyr::case_when(
      as.character(country) %in% c("AU", "Australia")    ~ "AU",
      as.character(country) %in% c("SA", "South Africa") ~ "SA",
      TRUE ~ as.character(country)
    ),
    country   = factor(country, levels = c("AU","SA")),
    task      = factor(as.character(task), levels = unname(ef_labels[nodes])),
    timepoint = factor(as.character(timepoint), levels = c("T1","T2","T3"), ordered = TRUE)
  )

p_spaghetti <- ggplot(ef_restricted_lab, aes(x = timepoint, y = value_z, group = id)) +
  geom_line(alpha = 0.08) +
  geom_point(alpha = 0.08, size = 0.7) +
  geom_line(
    data = mean_df_lab,
    aes(x = timepoint, y = m, group = 1),
    inherit.aes = FALSE,
    linewidth = 1.0
  ) +
  geom_point(
    data = mean_df_lab,
    aes(x = timepoint, y = m),
    inherit.aes = FALSE,
    size = 2.2
  ) +
  geom_errorbar(
    data = mean_df_lab,
    aes(x = timepoint, ymin = lo, ymax = hi),
    inherit.aes = FALSE,
    width = 0.10
  ) +
  facet_grid(country ~ task) +
  labs(
    x = "Timepoint",
    y = "EF (z-score)"
  ) +
  theme_bw(base_size = 11) +
  theme(
    legend.position = "none",
    panel.grid.minor = element_blank(),
    strip.background = element_blank()
  )

p_spaghetti
```

# Boxplot: Distribution of EF scores across waves {.appendix #fig-ef-boxplots-by-wave}
```{r}
#| label: fig-ef-boxplots-by-wave
#| fig-cap: "Executive function scores across waves in Australia and South Africa. Boxplots show the distribution of harmonised task scores at each wave, stratified by country."
#| fig-width: 12
#| fig-height: 5

p2 <- ggplot(ef_long_plot, aes(x = wave, y = value, fill = country)) +
  geom_boxplot() +
  facet_wrap(~ measure, scales = "free_y", ncol = 3) +
  theme_bw() +
  labs(
    x = "Wave",
    y = "Score",
    fill = "Country"
  )

p2
```

# RQ3 results reported on the Fisher z scale {.appendix #tbl-rq3-gt-edges-dual}
```{r}
#| label: tbl-rq3-gt-edges-dual
#| tbl-cap: "Between-cohort differences (edges only) at matched waves (AU − SA at T1/T2) and difference-in-differences for change from T1 to T2 (ΔAU − ΔSA). Columns show posterior median [95% CrI] on the raw partial-correlation scale (Δr) and Fisher-z scale (Δz = atanh(r)). ROPE probabilities are computed on Δr: $P(|\\Delta r| > 0.10)$."
#| include: true

gt_rq3_edges_dual <- rq3_edges_dual %>%
  gt::gt(rowname_col = "term", groupname_col = "panel") %>%
  gt::tab_header(title = gt::md("\\vspace{10pt}")) %>%
  gt::tab_stubhead(label = "Edge") %>%
  gt::cols_label(
    estimate_r = "Median [95% CrI]",
    estimate_z = "Median [95% CrI]",
    rope_p_r   = paste0("P(|Δr|>", rope_rq3, ")")
  ) %>%
  gt::tab_spanner(label = gt::md("Δr (raw partial correlation)"), columns = c(estimate_r, rope_p_r)) %>%
  gt::tab_spanner(label = gt::md("Δz (Fisher atanh scale)"), columns = c(estimate_z)) %>%
  gt::cols_align(align = "center", columns = c(estimate_r, rope_p_r, estimate_z)) %>%
  gt::sub_missing(columns = c(rope_p_r), missing_text = "") %>%
  gt::tab_options(
    table.font.size         = gt::px(11),
    row_group.font.weight   = "bold",
    heading.title.font.size = gt::px(1)
  )

gt_rq3_edges_dual
```