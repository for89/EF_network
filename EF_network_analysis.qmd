---
title: "Mapping the Structure of Executive Function in Early Childhood: A Network Analysis Approach" 
shorttitle: "Mapping Executive Function"

author:
- name: "Fionnuala O'Reilly" 
  orcid: 0000-0002-4355-9088 
  affiliations: 
    - ref: stanford
  email: foreilly@stanford.edu
  corresponding: true

- name: "Jelena Sucevic" 
  orcid: 0000-0001-5091-5434 
  affiliations: 
    - ref: oxford

- name: "Steven Howard" 
  orcid: 0000-0002-1258-3210 
  affiliations: 
    - ref: wollongong

- name: "Gaia Scerif" 
  orcid: 0000-0002-6371-8874 
  affiliations: 
    - ref: wollongong

affiliations: 
  - id: stanford 
    name: "Stanford University" 
  - id: oxford 
    name: "University of Oxford" 
  - id: wollongong 
    name: "University of Wollongong"

author-note: 
  disclosures: 
    financial-support: "This work was supported by X." 
    conflict-of-interest: "The author has no conflict of interest to declare."

abstract: TO BE ADDED.

keywords: ["executive function"] 
word-count: true

project:
  type: default
  
bibliography: library.bib

floatsintext: true
numbered-lines: true
# draft: false
mask: false

# figurelist: no
# tablelist: no
# footnotelist: no

format:
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
    include-in-header: preamble.tex
    fig-format: png
    # fig-pos: H        
    # tbl-pos: H

knitr:
  opts_chunk:
    ft.arraystretch: 1.25

execute:
  echo: false 
  message: false 
  warning: false 
  error: true 
  cache: true
---

```{r setup}
#| label: packages
#| include: false
#| cache: false

library(tidyverse)
library(here)
library(glue)
library(purrr)
library(viridis)
library(flextable)
library(lavaan)
library(broom.mixed)
library(lmerTest)
library(png)
library(emmeans)
library(dplyr)
library(ggplot2)
library(stringr)
library(psych) 
library(tibble)
library(haven)
library(BGGM)
library(networktools)  
library(qgraph)
library(haven)
library(readxl)
library(tidyr)

if (requireNamespace("conflicted", quietly = TRUE)) {
  conflicted::conflicts_prefer(
    dplyr::select,
    dplyr::filter,
    dplyr::lag,
    dplyr::rename,
    tidyr::extract
  )
  options(conflicted.policy = "strict") 
}

```

```{r}
#| label: load-data
#| include: false
#| cache: false

aus_data <- read_sav("REDACTED")
colnames(aus_data)
view(aus_data)

sa_data <- read_excel("/Users/foreilly/Library/CloudStorage/OneDrive-Nexus365/Network_analysis_2026/sa_data/SAGCRFStudy20202021_DATA_2023-12-11_1121_deidentified.xlsx")
colnames(sa_data)
view(sa_data)

```

# South African data

```{r}
#| label: sa-data-check
#| include: false
#| cache: false

table(sa_data$redcap_event_name) # count of entries for each time point
table(sa_data$child_id, sa_data$redcap_event_name) # do same child IDs appear twice?
sum(table(sa_data$child_id) > 1) # count of how many children with longitudinal data

# choose an ID (use child_id if it truly uniquely identifies children;
# otherwise caregiver_child_studyid is often the safer REDCap export key)
sa_ids <- sa_data %>%
  mutate(
    child = coalesce(as.character(child_id), as.character(caregiver_child_studyid))
  )

# 1) Map REDCap event names -> timepoint (T1 vs T2) based on your pattern
sa_tp <- sa_ids %>%
  mutate(
    timepoint = case_when(
      str_detect(redcap_event_name, "_arm_1b$") ~ "t2",  # e.g., data_collection_20_arm_1b
      str_detect(redcap_event_name, "_arm_1$")  ~ "t1",  # e.g., data_collection_20_arm_1
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(child), !is.na(timepoint)) %>%
  distinct(child, timepoint)  # removes duplicates if you have multiple rows per child/event

# 2) Make child-level flags: has T1? has T2?
child_flags <- sa_tp %>%
  mutate(present = TRUE) %>%
  pivot_wider(
    names_from  = timepoint,
    values_from = present,
    values_fill = FALSE
  ) %>%
  mutate(
    t1 = if (!"t1" %in% names(.)) FALSE else t1,
    t2 = if (!"t2" %in% names(.)) FALSE else t2
  )

# 3) Counts you want
counts <- child_flags %>%
  summarise(
    n_children = n(),
    n_t1       = sum(t1),
    n_t2       = sum(t2),
    n_both     = sum(t1 & t2),
    n_t1_only  = sum(t1 & !t2),
    n_t2_only  = sum(!t1 & t2)
  )
counts # n=138 longitudinal
```

```{r}
#| label: sa-ef-longitudinal
#| include: false
#| cache: false

# checking if the EF longitudinal data lines up with above (i.e. n=138)
ef_vars <- c("ef_inhibition", "ef_cogflex", "ef_workingmem")

ef_long_flags <- sa_data %>%
  mutate(
    child = coalesce(as.character(child_id), as.character(caregiver_child_studyid)),
    timepoint = case_when(
      str_detect(redcap_event_name, "_arm_1b$") ~ "t2",
      str_detect(redcap_event_name, "_arm_1$")  ~ "t1",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(child), !is.na(timepoint)) %>%
  group_by(child, timepoint) %>%
  summarise(
    # EF present if any EF variable is non-missing at that timepoint
    has_ef = any(if_any(all_of(ef_vars), ~ !is.na(.x))),
    .groups = "drop"
  ) %>%
  mutate(present = TRUE) %>%
  pivot_wider(
    names_from  = timepoint,
    values_from = c(present, has_ef),
    values_fill = list(present = FALSE, has_ef = FALSE)
  )

ef_counts <- ef_long_flags %>%
  summarise(
    n_children   = n(),
    n_ef_t1      = sum(has_ef_t1),
    n_ef_t2      = sum(has_ef_t2),
    n_ef_both    = sum(has_ef_t1 & has_ef_t2),
    n_ef_t1_only = sum(has_ef_t1 & !has_ef_t2),
    n_ef_t2_only = sum(!has_ef_t1 & has_ef_t2)
  )

ef_counts # n=109 with data on any of the three EF measures
```

```{r}
#| label: sa-ef-complete
#| include: false
#| cache: false

# have data on all EF measures
ef_vars <- c("ef_inhibition", "ef_cogflex", "ef_workingmem")

ef_complete_flags <- sa_data %>%
  mutate(
    child = coalesce(as.character(child_id), as.character(caregiver_child_studyid)),
    timepoint = case_when(
      str_detect(redcap_event_name, "_arm_1b$") ~ "t2",
      str_detect(redcap_event_name, "_arm_1$")  ~ "t1",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(child), !is.na(timepoint)) %>%
  group_by(child, timepoint) %>%
  summarise(
    # count how many EF vars have ANY non-missing value in this child×timepoint group
    n_present = sum(map_lgl(pick(all_of(ef_vars)), ~ any(!is.na(.x)))),
    .groups = "drop"
  ) %>%
  mutate(has_all3 = (n_present == length(ef_vars))) %>%
  pivot_wider(
    names_from = timepoint,
    values_from = c(has_all3, n_present),
    values_fill = list(has_all3 = FALSE, n_present = 0)
  )

# quick check: how many kids have 0/1/2/3 EF vars at each timepoint?
ef_complete_flags %>%
  count(n_present_t1, n_present_t2) %>%
  arrange(desc(n))

# Counts: complete EF at T1, complete EF at T2, and complete at BOTH
ef_complete_counts <- ef_complete_flags %>%
  summarise(
    n_children     = n(),
    n_all3_t1      = sum(has_all3_t1),
    n_all3_t2      = sum(has_all3_t2),
    n_all3_both    = sum(has_all3_t1 & has_all3_t2),
    n_all3_t1_only = sum(has_all3_t1 & !has_all3_t2),
    n_all3_t2_only = sum(!has_all3_t1 & has_all3_t2)
  )
ef_complete_counts # 100

```

```{r}
#| label: sa-ef-longitudinal-sample
#| include: false
#| cache: false

# children with all or some longitudinal data (n=100 with complete, n=9 with non-complete)
ef_longitudinal_ids <- ef_long_flags %>%
  filter(has_ef_t1 & has_ef_t2) %>%
  pull(child)

sa_ef_longitudinal <- sa_data %>%
  mutate(child = coalesce(as.character(child_id), as.character(caregiver_child_studyid))) %>%
  filter(child %in% ef_longitudinal_ids)

```

# Australian data

```{r}
#| label: aus-ef-longitudinal-sample
#| include: false
#| cache: false

table(table(aus_data$CID))

id_var <- if ("CID" %in% names(aus_data)) "CID" else "ServiceID"

t1_vars <- c("MrAnt_Pt_T1","GNG_IC_T1","CS_SwAcc_T1")
t2_vars <- c("MrAnt_Pt_T2","GNG_IC_T2","CS_SwAcc_T2")
t3_vars <- c("MrAnt_Pt_T3","GNG_IC_T3","CS_SwAcc_T3")

ef_any_counts <- aus_data %>%
  mutate(
    child = .data[[id_var]],
    ef_t1 = if_any(all_of(t1_vars), ~ !is.na(.x)),
    ef_t2 = if_any(all_of(t2_vars), ~ !is.na(.x)),
    ef_t3 = if_any(all_of(t3_vars), ~ !is.na(.x))
  ) %>%
  filter(!is.na(child)) %>%
  distinct(child, .keep_all = TRUE) %>%  # safety: one row per child
  summarise(
    n_children = n(),
    n_t1 = sum(ef_t1),
    n_t2 = sum(ef_t2),
    n_t3 = sum(ef_t3),
    n_2_timepoints = sum(ef_t1 & ef_t2),
    n_all3_timepoints = sum(ef_t1 & ef_t2 & ef_t3)
  )

ef_any_counts # 217 with two time points, 103 with all three time points

```

## Explore data

```{r}
#| label: aus-explore-data
#| include: true
#| cache: false

ef_vars <- c(
  "MrAnt_Pt_T1","GNG_IC_T1","CS_SwAcc_T1",
  "MrAnt_Pt_T2","GNG_IC_T2","CS_SwAcc_T2",
  "MrAnt_Pt_T3","GNG_IC_T3","CS_SwAcc_T3"
)

age_vars <- c("Age_T1", "Age_T2", "Age_T3")

# Missingness
miss_var <- aus_data |>
  summarise(across(all_of(ef_vars),
                   list(n_miss = ~sum(is.na(.)),
                        pct_miss = ~mean(is.na(.))*100,
                        n_nonmiss = ~sum(!is.na(.))),
                   .names = "{.col}__{.fn}")) |>
  pivot_longer(everything(),
               names_to = c("variable","metric"),
               names_sep = "__",
               values_to = "value") |>
  pivot_wider(names_from = metric, values_from = value) |>
  arrange(desc(pct_miss))

miss_var

# Descriptives
ef_desc <- psych::describe(aus_data[ef_vars]) |>
  as.data.frame() |>
  tibble::rownames_to_column("variable") |>
  transmute(
    variable, n, mean, sd, median, min, max,
    skew   = skew,
    kurt   = kurtosis,   # psych column name
    se
  ) |>
  arrange(variable)
ef_desc

# Descriptives table
# Long version of EF variables
ef_long <- aus_data %>%
  select(all_of(age_vars), all_of(ef_vars)) %>%
  pivot_longer(cols = all_of(ef_vars), names_to = "var", values_to = "value") %>%
  mutate(
    timepoint = stringr::str_extract(var, "T[123]"),
    measure = dplyr::case_when(
      stringr::str_starts(var, "MrAnt") ~ "Mr Ant (points)",
      stringr::str_starts(var, "GNG")   ~ "Go/No-Go (IC)",
      stringr::str_starts(var, "CS_")   ~ "Card Sort (switch acc)",
      TRUE ~ var
    ),
    age = dplyr::case_when(
      timepoint == "T1" ~ Age_T1,
      timepoint == "T2" ~ Age_T2,
      timepoint == "T3" ~ Age_T3,
      TRUE ~ NA_real_
    )
  )

# EF summary (per measure x timepoint)
ef_summary <- ef_long %>%
  group_by(measure, timepoint) %>%
  summarise(
    n_nonmiss = sum(!is.na(value)),
    miss_pct  = round(100 * mean(is.na(value)), 1),
    mean      = mean(value, na.rm = TRUE),
    sd        = sd(value, na.rm = TRUE),
    median    = median(value, na.rm = TRUE),
    q25       = quantile(value, 0.25, na.rm = TRUE),
    q75       = quantile(value, 0.75, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    mean_sd    = ifelse(n_nonmiss > 0, sprintf("%.2f (%.2f)", mean, sd), NA_character_),
    median_iqr = ifelse(n_nonmiss > 0, sprintf("%.2f [%.2f, %.2f]", median, q25, q75), NA_character_)
  ) %>%
  select(measure, timepoint, n_nonmiss, miss_pct, mean_sd, median_iqr) %>%
  pivot_wider(
    names_from = timepoint,
    values_from = c(n_nonmiss, miss_pct, mean_sd, median_iqr),
    names_glue = "{.value}_{timepoint}"
  )

# Age summary (one row, split by timepoint)
age_row <- aus_data %>%
  select(all_of(age_vars)) %>%
  pivot_longer(cols = all_of(age_vars), names_to = "age_var", values_to = "age") %>%
  mutate(
    timepoint = stringr::str_extract(age_var, "T[123]"),
    age = suppressWarnings(as.numeric(age))
  ) %>%
  group_by(timepoint) %>%
  summarise(
    n_nonmiss = sum(!is.na(age)),
    miss_pct  = round(100 * mean(is.na(age)), 1),
    mean      = mean(age, na.rm = TRUE),
    sd        = sd(age, na.rm = TRUE),
    median    = median(age, na.rm = TRUE),
    q25       = quantile(age, 0.25, na.rm = TRUE),
    q75       = quantile(age, 0.75, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    mean_sd    = ifelse(n_nonmiss > 0, sprintf("%.2f (%.2f)", mean, sd), NA_character_),
    median_iqr = ifelse(n_nonmiss > 0, sprintf("%.2f [%.2f, %.2f]", median, q25, q75), NA_character_)
  ) %>%
  select(timepoint, n_nonmiss, miss_pct, mean_sd, median_iqr) %>%
  pivot_wider(
    names_from  = timepoint,
    values_from = c(n_nonmiss, miss_pct, mean_sd, median_iqr),
    names_glue  = "{.value}_{timepoint}"
  ) %>%
  mutate(measure = "Age") %>%
  select(measure, everything())

# Build Age row explicitly (clearer than acrobatics)
age_row <- ef_long %>%
  distinct(Age_T1, Age_T2, Age_T3) %>%
  summarise(
    n_nonmiss_T1 = sum(!is.na(Age_T1)),
    miss_pct_T1  = round(100 * mean(is.na(Age_T1)), 1),
    mean_sd_T1   = sprintf("%.2f (%.2f)", mean(Age_T1, na.rm = TRUE), sd(Age_T1, na.rm = TRUE)),
    median_iqr_T1= sprintf("%.2f [%.2f, %.2f]", median(Age_T1, na.rm = TRUE),
                           quantile(Age_T1, .25, na.rm = TRUE), quantile(Age_T1, .75, na.rm = TRUE)),

    n_nonmiss_T2 = sum(!is.na(Age_T2)),
    miss_pct_T2  = round(100 * mean(is.na(Age_T2)), 1),
    mean_sd_T2   = sprintf("%.2f (%.2f)", mean(Age_T2, na.rm = TRUE), sd(Age_T2, na.rm = TRUE)),
    median_iqr_T2= sprintf("%.2f [%.2f, %.2f]", median(Age_T2, na.rm = TRUE),
                           quantile(Age_T2, .25, na.rm = TRUE), quantile(Age_T2, .75, na.rm = TRUE)),

    n_nonmiss_T3 = sum(!is.na(Age_T3)),
    miss_pct_T3  = round(100 * mean(is.na(Age_T3)), 1),
    mean_sd_T3   = sprintf("%.2f (%.2f)", mean(Age_T3, na.rm = TRUE), sd(Age_T3, na.rm = TRUE)),
    median_iqr_T3= sprintf("%.2f [%.2f, %.2f]", median(Age_T3, na.rm = TRUE),
                           quantile(Age_T3, .25, na.rm = TRUE), quantile(Age_T3, .75, na.rm = TRUE))
  ) %>%
  mutate(measure = "Age") %>%
  select(measure, everything())

# Final table
desc_table <- bind_rows(age_row, ef_summary) %>%
  select(
    Measure = measure,
    `N (T1)` = n_nonmiss_T1, `Missing % (T1)` = miss_pct_T1, `Mean (SD) (T1)` = mean_sd_T1, `Median [IQR] (T1)` = median_iqr_T1,
    `N (T2)` = n_nonmiss_T2, `Missing % (T2)` = miss_pct_T2, `Mean (SD) (T2)` = mean_sd_T2, `Median [IQR] (T2)` = median_iqr_T2,
    `N (T3)` = n_nonmiss_T3, `Missing % (T3)` = miss_pct_T3, `Mean (SD) (T3)` = mean_sd_T3, `Median [IQR] (T3)` = median_iqr_T3
  )

desc_table

```

### Developmental change in tasks across age

```{r age trends}
#| cache: false

ef_long <- aus_data %>%
  select(Age, all_of(ef_vars)) %>%
  pivot_longer(cols = all_of(ef_vars), names_to = "measure", values_to = "score") %>%
  # Split names like MrAnt_Pt_T1 -> task = MrAnt, metric = Pt, tp = T1
  extract(measure, into = c("task","metric","tp"), regex = "^([^_]+)_([^_]+)_(T\\d+)$", remove = FALSE) %>%
  mutate(
    task = recode(task,
                  "MrAnt" = "Memory Game (MrAnt)",
                  "GNG"   = "Go/No-Go (GNG)",
                  "CS"    = "Hearts & Flowers (CS)"),  # tweak labels as you like
    tp   = factor(tp, levels = c("T1","T2","T3"))
  )

p1 <- ggplot(ef_long, aes(x = Age, y = score, colour = tp)) +
  geom_point(alpha = 0.25, size = 1) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x, linewidth = 1) +
  facet_wrap(~ task, scales = "free_y") +
  labs(
    x = "Age (years)",
    y = "Score",
    colour = "Time point",
    title = "Developmental change in EF tasks across age",
    subtitle = "Each panel shows one task; LOESS trend per time point"
  ) +
  theme_minimal(base_size = 12)

p1

ef_long_z <- ef_long %>%
  group_by(measure) %>%
  mutate(score_z = as.numeric(scale(score))) %>%
  ungroup()

p2 <- ggplot(ef_long_z, aes(x = Age, y = score_z, colour = tp)) +
  geom_point(alpha = 0.25, size = 1) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x, linewidth = 1) +
  facet_wrap(~ task) +
  labs(
    x = "Age (years)",
    y = "Standardised score (z within measure)",
    colour = "Time point",
    title = "Age trends in EF (z-scored within variable)",
    subtitle = "Faceted by task; standardisation makes panels comparable"
  ) +
  theme_minimal(base_size = 12)

p2  

plot_ef_var <- function(var, df = aus_data, age_col = "Age") {
  stopifnot(var %in% ef_vars)
  tmp <- df %>%
    select(age = all_of(age_col), score = all_of(var)) %>%
    mutate(var = var)

  ggplot(tmp, aes(x = age, y = score)) +
    geom_point(alpha = 0.35, size = 1) +
    geom_smooth(se = FALSE, method = "loess", formula = y ~ x, linewidth = 1) +
    labs(
      x = "Age (years)",
      y = var,
      title = paste0("Age trend: ", var)
    ) +
    theme_minimal(base_size = 12)
}

colnames(aus_data)
plot_ef_var("MrAnt_Pt_T1")
plot_ef_var("MrAnt_Pt_T2")
plot_ef_var("MrAnt_Pt_T3")
plot_ef_var("GNG_IC_T1")
plot_ef_var("GNG_IC_T2")
plot_ef_var("GNG_IC_T3")
plot_ef_var("CS_SwAcc_T1")
plot_ef_var("CS_SwAcc_T2")
plot_ef_var("CS_SwAcc_T3")
```

### Within child trajectories (raw scores)

```{r within child trajectories}
#| cache: false

id_col <- "CID"   # change if your ID column is named differently

ef_long <- aus_data %>%
  select(all_of(id_col), Age, all_of(ef_vars)) %>%
  pivot_longer(cols = all_of(ef_vars), names_to = "measure", values_to = "score") %>%
  # Split e.g., "MrAnt_Pt_T1" -> task = MrAnt, metric = Pt, tp = T1
  extract(measure, into = c("task","metric","tp"),
          regex = "^([^_]+)_([^_]+)_(T\\d+)$", remove = FALSE) %>%
  mutate(
    tp     = factor(tp, levels = c("T1","T2","T3")),
    task_l = recode(task,
                    "MrAnt" = "Memory Game (MrAnt)",
                    "GNG"   = "Go/No-Go (GNG)",
                    "CS"    = "Hearts & Flowers (CS)")
  )

# Compute T2–T1, T3–T2, T3–T1 per child and per measure
change_wide <- ef_long %>%
  select(all_of(id_col), measure, tp, score) %>%
  pivot_wider(names_from = tp, values_from = score) %>%
  mutate(
    d12 = T2 - T1,
    d23 = T3 - T2,
    d13 = T3 - T1
  )

# Per-measure summaries: n pairs, mean change, SD, 95% CI
paired_change_summary <- change_wide %>%
  pivot_longer(c(d12, d23, d13), names_to = "contrast", values_to = "delta") %>%
  group_by(measure, contrast) %>%
  summarise(
    n_pairs = sum(!is.na(delta)),
    mean    = mean(delta, na.rm = TRUE),
    sd      = sd(delta,  na.rm = TRUE),
    se      = sd / sqrt(n_pairs),
    ci95_l  = mean - 1.96 * se,
    ci95_u  = mean + 1.96 * se,
    .groups = "drop"
  ) %>%
  arrange(measure, factor(contrast, levels = c("d12","d23","d13")))
paired_change_summary

# Spaghetti plot per task (raw scores)
ggplot(
  ef_long,
  aes(x = tp, y = score,
      group  = .data[[id_col]],
      colour = factor(.data[[id_col]]))
) +
  geom_line(alpha = 0.35, linewidth = 0.4) +
  geom_point(alpha = 0.6, size = 0.8) +
  facet_wrap(~ task_l, scales = "free_y") +
  guides(colour = "none") +
  labs(x = "Time point", y = "Raw score",
       title = "Within-child trajectories across time (raw scores)")
```
### EF change over time (raw scores)

```{r mean change over time within task, raw scores}
#| cache: false

summary_ci <- ef_long %>%
  group_by(task_l, tp) %>%
  summarise(
    n   = sum(!is.na(score)),
    mean = mean(score, na.rm = TRUE),
    sd   = sd(score,   na.rm = TRUE),
    se   = sd / sqrt(n),
    ci_l = mean - 1.96*se,
    ci_u = mean + 1.96*se,
    .groups = "drop"
  )

y_lims <- range(summary_ci$ci_l, summary_ci$ci_u, na.rm = TRUE)
pad    <- diff(y_lims) * 0.05
y_lims <- c(y_lims[1] - pad, y_lims[2] + pad)

p <- ggplot(summary_ci, aes(x = tp, y = mean, group = 1)) +
  geom_ribbon(aes(ymin = ci_l, ymax = ci_u), alpha = 0.15) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 1.8) +
  facet_wrap(~ task_l, scales = "fixed") +
  coord_cartesian(ylim = y_lims, expand = FALSE) +
  labs(
    x = "Time point",
    y = "Raw score",
    title = "EF change over time (means with 95% CIs)"
  )
print(p)
```
### Box plots (raw scores)

```{r boxplots}
ggplot(ef_long, aes(x = tp, y = score)) +
  geom_boxplot(outlier.alpha = 0.25, width = 0.6) +
  facet_wrap(~ task_l, scales = "free_y") +
  labs(x = "Time point", y = "Raw score",
       title = "EF distributions across time") +
  theme_minimal(base_size = 12)

```

### EF change over time standardised to each task’s T1 standard deviation

```{r mean change over time within task, standardised scores}
#| cache: false

# task-level T1 mean/SD
t1_stats <- ef_long %>%
  filter(tp == "T1") %>%
  group_by(task_l) %>%
  summarise(mu_T1 = mean(score, na.rm = TRUE),
            sd_T1 = sd(score, na.rm = TRUE),
            .groups = "drop")

ef_long_zT1 <- ef_long %>%
  left_join(t1_stats, by = "task_l") %>%
  mutate(score_zT1 = (score - mu_T1) / sd_T1)

# Means + 95% CIs on the z(T1) scale
summary_ci_z <- ef_long_zT1 %>%
  group_by(task_l, tp) %>%
  summarise(
    n = sum(!is.na(score_zT1)),
    mean = mean(score_zT1, na.rm = TRUE),
    sd   = sd(score_zT1,   na.rm = TRUE),
    se   = sd / sqrt(n),
    ci_l = mean - 1.96 * se,
    ci_u = mean + 1.96 * se,
    .groups = "drop"
  )

ggplot(summary_ci_z, aes(tp, mean, group = 1)) +
  geom_ribbon(aes(ymin = ci_l, ymax = ci_u), alpha = 0.15) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 1.8) +
  facet_wrap(~ task_l, scales = "fixed") +
  labs(x = "Time point", y = "Change in SD units (z vs T1)",
       title = "EF change over time (standardised to each task’s T1 SD)")
```

### Mixed effects model to test if change from T1 to T2 is statistically significant

```{r mixed effects}
#| cache: false

# Ensure time is ordered and add a "measure root" without the T1/T2/T3 suffix
ef_long2 <- ef_long %>%
  mutate(
    tp = factor(tp, levels = c("T1","T2","T3")),
    meas_root = str_remove(measure, "_T[123]$")
  )

fit_time_tests <- function(dat, id_col = "CID") {
  # Give lmer() a concrete ID column name
  dat2 <- dat %>% rename(.id = all_of(id_col))

  fit <- lmerTest::lmer(score ~ tp + (1 | .id), data = dat2, REML = FALSE)
  emm <- emmeans(fit, ~ tp)

  cont <- contrast(emm, method = list(
    "T2 - T1" = c(-1, 1, 0),
    "T3 - T1" = c(-1, 0, 1),
    "T3 - T2" = c( 0,-1, 1)
  ))

  cont_df <- as.data.frame(summary(cont, infer = TRUE)) %>%
    transmute(
      contrast, estimate, SE, df, t = t.ratio,
      p = `p.value`, lower.CL, upper.CL
    )

  an <- anova(fit)
  cont_df %>%
    mutate(
      anova_F  = unname(an["tp","F value"]),
      anova_df1 = unname(an["tp","NumDF"]),
      anova_df2 = unname(an["tp","DenDF"]),
      anova_p  = unname(an["tp","Pr(>F)"])
    )
}

# Run one model per measure root (e.g., "GNG_IC", "CS_SwAcc", "MrAnt_Pt")
results <- ef_long2 %>%
  group_by(meas_root) %>%
  group_modify(~ fit_time_tests(.x)) %>%
  ungroup() %>%
  group_by(contrast) %>%
  mutate(p_adj = p.adjust(p, method = "BH")) %>%
  ungroup()

results


# (optional) pretty names for each measure root
pretty_names <- c(
  "GNG_IC"   = "Go/No-Go (GNG)",
  "CS_SwAcc" = "Hearts & Flowers (CS)",
  "MrAnt_Pt" = "Memory Game (MrAnt)"
)

t12_tbl <- results %>%
  filter(contrast == "T2 - T1") %>%
  transmute(
    Task     = recode(meas_root, !!!pretty_names, .default = meas_root),
    Estimate = estimate,                                   # raw-score change
    `95% CI` = sprintf("[%.2f, %.2f]", lower.CL, upper.CL),
    p        = pvalue(p),                                  # unadjusted p
    `p (BH)` = pvalue(p_adj),                              # FDR-adjusted p
    `Omnibus F (time)` = sprintf("%.2f (df %d, %.1f), p=%s",
                                 anova_F, anova_df1, anova_df2, pvalue(anova_p))
  ) %>%
  arrange(Task)

knitr::kable(t12_tbl, digits = 2, col.names = c("Task", "Δ (T2−T1)", "95% CI", "p", "p (BH)", "Omnibus F (time)")) %>% kableExtra::kable_styling(full_width = FALSE)
```

Histograms indicated that all executive-function task scores were approximately symmetric and unimodal. Mean performance increased and variability decreased across time, consistent with developmental improvements. No evidence of severe skewness, kurtosis, or ceiling/floor effects was observed, so raw scores were retained for analysis.

## Network analysis (rough work)

```{r split by wave}
#| cache: false

ef_map <- list(
  T1 = c("MrAnt_Pt_T1","GNG_IC_T1","CS_SwAcc_T1"),
  T2 = c("MrAnt_Pt_T2","GNG_IC_T2","CS_SwAcc_T2"),
  T3 = c("MrAnt_Pt_T3","GNG_IC_T3","CS_SwAcc_T3")
)

extract_wave <- function(df, vars) {
  stopifnot(length(vars) == 3, all(vars %in% names(df)))
  out <- dplyr::select(df, dplyr::all_of(vars))
  colnames(out) <- c("mr_ant", "gng", "cs")
  out
}

# now this works
Y_t1 <- extract_wave(aus_data, ef_map$T1)
Y_t2 <- extract_wave(aus_data, ef_map$T2)
Y_t3 <- extract_wave(aus_data, ef_map$T3)

Z_t1 <- as.data.frame(scale(Y_t1))
Z_t2 <- as.data.frame(scale(Y_t2))
Z_t3 <- as.data.frame(scale(Y_t3))
```

```{r estimate BGGM networks per wave}
#| cache: false

set.seed(42)
# estimate() gives posterior for every partial correlation (edge)
fit_t1 <- BGGM::estimate(Z_t1, type = "continuous", iter = 10000, impute = TRUE)
fit_t2 <- BGGM::estimate(Z_t2, type = "continuous", iter = 10000, impute = TRUE)
fit_t3 <- BGGM::estimate(Z_t3, type = "continuous", iter = 10000, impute = TRUE)
```

```{r Extract posterior mean partial correlation matrices (pcor) and weighted adjacency (pcor with tiny edges set to 0, depending on class)}
pc_t1 <- BGGM::pcor_mat(fit_t1)
pc_t2 <- BGGM::pcor_mat(fit_t2)
pc_t3 <- BGGM::pcor_mat(fit_t3)
```

```{r expected influence and global strength}
# Expected Influence (EI)
ei_t1 <- networktools::expectedInf(pc_t1)$step1
ei_t2 <- networktools::expectedInf(pc_t2)$step1
ei_t3 <- networktools::expectedInf(pc_t3)$step1

# Strength centrality (sum of edges). Drop diagonals.
strength <- function(M){
  diag(M) <- 0
  rowSums(abs(M))
}
str_t1 <- strength(pc_t1)
str_t2 <- strength(pc_t2)
str_t3 <- strength(pc_t3)
```

```{r Global strength}
global_strength <- function(M){
  sum(abs(M[upper.tri(M)]))
}
gs_t1 <- global_strength(pc_t1)
gs_t2 <- global_strength(pc_t2)
gs_t3 <- global_strength(pc_t3)

print(gs_t1)
print(gs_t2)
print(gs_t3)
```

```{r pairwise Bayesian comparisons of networks}

cmp_t1_t2 <- BGGM::ggm_compare_estimate(Z_t1, Z_t2, type = "continuous", iter = 10000, impute = TRUE)
cmp_t1_t3 <- BGGM::ggm_compare_estimate(Z_t1, Z_t3, type = "continuous", iter = 10000, impute = TRUE)
cmp_t2_t3 <- BGGM::ggm_compare_estimate(Z_t2, Z_t3, type = "continuous", iter = 10000, impute = TRUE)

summary(cmp_t1_t2)  # posterior summaries of edge differences
summary(cmp_t2_t3)
plot(summary(cmp_t1_t2))   #visual of credible intervals
plot(summary(cmp_t2_t3)) # note label is wrong
```

```{r plots}
labs <- c("Mr Ant","Go/No-Go","Card Sort")
qgraph(pc_t1, layout = "spring", labels = labs, title = "T1 (BGGM posterior mean)")
qgraph(pc_t2, layout = "spring", labels = labs, title = "T2 (BGGM posterior mean)")
qgraph(pc_t3, layout = "spring", labels = labs, title = "T3 (BGGM posterior mean)")
```
























